{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A00785001/TC5035/blob/main/01_Pre_processing_MobileNet_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFaJ69v1F9yR"
      },
      "source": [
        "# ROS Bag Camera Data Extractor & MobileNet V2 Preprocessor\n",
        "Extract camera images from ROS bags and prepare them for MobileNet V2 feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPA2IPmPF9yT"
      },
      "source": [
        "## Section 1: Extract Images from ROS Bag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdDEaAL9F9yU"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install bagpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb__6dTzF9yV"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from bagpy import bagreader\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from glob import glob\n",
        "import json\n",
        "import csv\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"Libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fl8U00u0F9yW"
      },
      "outputs": [],
      "source": [
        "# Upload your ROS bag file (for Colab)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "bag_file = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded: {bag_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_7FRXgNF9yX"
      },
      "outputs": [],
      "source": [
        "# Read the bag file\n",
        "bag = bagreader(bag_file)\n",
        "print(f\"Opened bag file: {bag_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zB-RFm8xF9yX"
      },
      "outputs": [],
      "source": [
        "# List all topics in the bag\n",
        "print(\"Topics in bag:\")\n",
        "print(bag.topic_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNLpwwcAF9yX"
      },
      "outputs": [],
      "source": [
        "# Specify your camera topic\n",
        "camera_topic = \"/camera/image_raw\"\n",
        "print(f\"Using camera topic: {camera_topic}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRn1m7QIF9yY"
      },
      "outputs": [],
      "source": [
        "# Extract images from the topic\n",
        "print(f\"Extracting images from topic: {camera_topic}\")\n",
        "image_data = bag.message_by_topic(camera_topic)\n",
        "print(f\"Images extracted to: {image_data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jUvinki6F9yZ"
      },
      "outputs": [],
      "source": [
        "# Get the folder where images were extracted\n",
        "bag_name = os.path.splitext(bag_file)[0]\n",
        "image_folder = os.path.join(bag_name, camera_topic.replace('/', '-')[1:])\n",
        "\n",
        "# List all image files\n",
        "image_files = sorted(glob(os.path.join(image_folder, '*.jpg')) +\n",
        "                     glob(os.path.join(image_folder, '*.png')))\n",
        "\n",
        "print(f\"Found {len(image_files)} images\")\n",
        "print(f\"Image folder: {image_folder}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hJhwJmvF9ya"
      },
      "outputs": [],
      "source": [
        "# Display sample images\n",
        "sample_images = []\n",
        "for img_path in image_files[:6]:\n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    sample_images.append(img_rgb)\n",
        "\n",
        "# Plot sample images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "axes = axes.flatten()\n",
        "for i, img in enumerate(sample_images):\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Image {i+1}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "if sample_images:\n",
        "    print(f\"Original image shape: {sample_images[0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6oFiWE7F9ya"
      },
      "source": [
        "## Section 2: Process Images for MobileNet V2 Feature Extraction\n",
        "\n",
        "**MobileNet V2 Requirements:**\n",
        "- Input size: 224x224x3\n",
        "- Pixel scaling to [-1, 1] will be done during feature extraction\n",
        "- Here we only resize and save images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lKwgnp2F9yb"
      },
      "outputs": [],
      "source": [
        "# MobileNet V2 input parameters\n",
        "IMG_SIZE = 224\n",
        "TARGET_SIZE = (IMG_SIZE, IMG_SIZE)\n",
        "JPEG_QUALITY = 95\n",
        "\n",
        "print(f\"Target image size: {TARGET_SIZE}\")\n",
        "print(f\"JPEG quality: {JPEG_QUALITY}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2sff-8pGF9yb"
      },
      "outputs": [],
      "source": [
        "# Create output folder structure\n",
        "OUTPUT_DIR = \"processed_images\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Created output directory: {OUTPUT_DIR}/\")\n",
        "print(\"Images will be saved with metadata (CSV + JSON)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPWwh1ArF9yb"
      },
      "outputs": [],
      "source": [
        "# Extract timestamps from bagpy (if available)\n",
        "# Try to read timestamp data from CSV file that bagpy creates\n",
        "csv_file = image_data if isinstance(image_data, str) and image_data.endswith('.csv') else None\n",
        "timestamps = []\n",
        "\n",
        "if csv_file and os.path.exists(csv_file):\n",
        "    try:\n",
        "        import pandas as pd\n",
        "        df = pd.read_csv(csv_file)\n",
        "        if 'Time' in df.columns:\n",
        "            timestamps = df['Time'].tolist()\n",
        "            print(f\"Loaded {len(timestamps)} timestamps from bag\")\n",
        "    except:\n",
        "        print(\"Could not load timestamps from CSV\")\n",
        "\n",
        "# If no timestamps available, use sequential numbering\n",
        "if len(timestamps) != len(image_files):\n",
        "    print(\"Using sequential frame IDs instead of timestamps\")\n",
        "    timestamps = list(range(len(image_files)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q52mb7OCF9yb"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess and save images\n",
        "def preprocess_and_save_image(img_path, save_path, target_size=(224, 224), quality=95):\n",
        "    \"\"\"\n",
        "    Preprocess image for MobileNet V2:\n",
        "    1. Load image\n",
        "    2. Resize to 224x224\n",
        "    3. Save as JPEG\n",
        "\n",
        "    Returns: (success, original_width, original_height, file_size_kb)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Load image\n",
        "        img = Image.open(img_path)\n",
        "        original_size = img.size  # (width, height)\n",
        "\n",
        "        # Resize to target size\n",
        "        img_resized = img.resize(target_size, Image.LANCZOS)\n",
        "\n",
        "        # Save preprocessed image\n",
        "        img_resized.save(save_path, 'JPEG', quality=quality)\n",
        "\n",
        "        # Get file size\n",
        "        file_size_kb = os.path.getsize(save_path) / 1024\n",
        "\n",
        "        return True, original_size[0], original_size[1], file_size_kb\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {img_path}: {e}\")\n",
        "        return False, 0, 0, 0\n",
        "\n",
        "print(\"Preprocessing function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFQPpKK5F9yb"
      },
      "outputs": [],
      "source": [
        "# Process all images and collect metadata\n",
        "print(\"Processing images...\")\n",
        "\n",
        "metadata_list = []\n",
        "total_size_kb = 0\n",
        "failed_count = 0\n",
        "\n",
        "for i, img_path in enumerate(image_files):\n",
        "    # Generate output filename\n",
        "    output_filename = f\"img_{i:05d}.jpg\"\n",
        "    output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
        "\n",
        "    # Process and save image\n",
        "    success, orig_w, orig_h, file_size = preprocess_and_save_image(\n",
        "        img_path, output_path, TARGET_SIZE, JPEG_QUALITY\n",
        "    )\n",
        "\n",
        "    if success:\n",
        "        # Get timestamp info\n",
        "        timestamp = timestamps[i] if i < len(timestamps) else i\n",
        "\n",
        "        # Parse timestamp if it's a float (ROS timestamp)\n",
        "        if isinstance(timestamp, float):\n",
        "            timestamp_sec = int(timestamp)\n",
        "            timestamp_nsec = int((timestamp - timestamp_sec) * 1e9)\n",
        "        else:\n",
        "            timestamp_sec = timestamp\n",
        "            timestamp_nsec = 0\n",
        "\n",
        "        # Store metadata\n",
        "        metadata_list.append({\n",
        "            'filename': output_filename,\n",
        "            'timestamp': timestamp,\n",
        "            'timestamp_sec': timestamp_sec,\n",
        "            'timestamp_nsec': timestamp_nsec,\n",
        "            'frame_id': i,\n",
        "            'original_width': orig_w,\n",
        "            'original_height': orig_h,\n",
        "            'file_size_kb': round(file_size, 2)\n",
        "        })\n",
        "\n",
        "        total_size_kb += file_size\n",
        "    else:\n",
        "        failed_count += 1\n",
        "\n",
        "    # Progress update\n",
        "    if (i + 1) % 100 == 0:\n",
        "        print(f\"Processed {i + 1}/{len(image_files)} images\")\n",
        "\n",
        "print(f\"\\n✓ Completed: {len(metadata_list)} images processed\")\n",
        "print(f\"✗ Failed: {failed_count} images\")\n",
        "print(f\"Total dataset size: {total_size_kb/1024:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-0Iz7_KF9yc"
      },
      "outputs": [],
      "source": [
        "# Save CSV metadata (per-image data)\n",
        "csv_path = os.path.join(OUTPUT_DIR, 'metadata.csv')\n",
        "\n",
        "with open(csv_path, 'w', newline='') as csvfile:\n",
        "    fieldnames = ['filename', 'timestamp', 'timestamp_sec', 'timestamp_nsec',\n",
        "                  'frame_id', 'original_width', 'original_height', 'file_size_kb']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for row in metadata_list:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(f\"✓ CSV metadata saved: {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzm43HgJF9yc"
      },
      "outputs": [],
      "source": [
        "# Calculate statistics\n",
        "if metadata_list:\n",
        "    avg_file_size = sum(m['file_size_kb'] for m in metadata_list) / len(metadata_list)\n",
        "\n",
        "    # Calculate FPS if timestamps are available\n",
        "    if len(metadata_list) > 1 and isinstance(metadata_list[0]['timestamp'], float):\n",
        "        time_diff = metadata_list[-1]['timestamp'] - metadata_list[0]['timestamp']\n",
        "        fps_actual = len(metadata_list) / time_diff if time_diff > 0 else 0\n",
        "    else:\n",
        "        fps_actual = 0\n",
        "else:\n",
        "    avg_file_size = 0\n",
        "    fps_actual = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5pcR9VMF9yc"
      },
      "outputs": [],
      "source": [
        "# Create JSON metadata (dataset-level info)\n",
        "json_metadata = {\n",
        "    \"dataset_metadata\": {\n",
        "        \"creation_date\": datetime.now().isoformat(),\n",
        "        \"ros_bag_info\": {\n",
        "            \"source_file\": bag_file,\n",
        "            \"bag_duration_sec\": metadata_list[-1]['timestamp'] - metadata_list[0]['timestamp'] if len(metadata_list) > 1 and isinstance(metadata_list[0]['timestamp'], float) else 0,\n",
        "            \"bag_start_time\": metadata_list[0]['timestamp'] if metadata_list else 0,\n",
        "            \"bag_end_time\": metadata_list[-1]['timestamp'] if metadata_list else 0\n",
        "        },\n",
        "        \"camera_info\": {\n",
        "            \"topic\": camera_topic,\n",
        "            \"encoding\": \"bgr8\",\n",
        "            \"frame_rate_hz\": round(fps_actual, 2),\n",
        "            \"camera_model\": \"unknown\"\n",
        "        },\n",
        "        \"processing_info\": {\n",
        "            \"target_size\": [IMG_SIZE, IMG_SIZE],\n",
        "            \"resize_method\": \"LANCZOS\",\n",
        "            \"jpeg_quality\": JPEG_QUALITY,\n",
        "            \"total_images_processed\": len(metadata_list),\n",
        "            \"processing_script\": \"rosbag_camera_extractor_v1.ipynb\"\n",
        "        }\n",
        "    },\n",
        "    \"optional_camera_calibration\": {\n",
        "        \"camera_matrix\": None,\n",
        "        \"distortion_coefficients\": None,\n",
        "        \"calibration_available\": False\n",
        "    },\n",
        "    \"sensor_fusion_notes\": {\n",
        "        \"time_synchronization\": \"ROS timestamps preserved in CSV\",\n",
        "        \"coordinate_frame\": \"camera_optical_frame\",\n",
        "        \"notes\": \"Images ready for MobileNet V2 feature extraction. Apply preprocess_input() before inference.\"\n",
        "    },\n",
        "    \"statistics\": {\n",
        "        \"fps_actual\": round(fps_actual, 2),\n",
        "        \"dropped_frames\": failed_count,\n",
        "        \"avg_file_size_kb\": round(avg_file_size, 2),\n",
        "        \"total_dataset_size_mb\": round(total_size_kb / 1024, 2)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save JSON metadata\n",
        "json_path = os.path.join(OUTPUT_DIR, 'dataset_info.json')\n",
        "with open(json_path, 'w') as jsonfile:\n",
        "    json.dump(json_metadata, jsonfile, indent=2)\n",
        "\n",
        "print(f\"✓ JSON metadata saved: {json_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-O1j5iRF9yc"
      },
      "outputs": [],
      "source": [
        "# Display summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATASET PROCESSING COMPLETE\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Output directory: {OUTPUT_DIR}/\")\n",
        "print(f\"Total images: {len(metadata_list)}\")\n",
        "print(f\"Image size: {IMG_SIZE}x{IMG_SIZE}\")\n",
        "print(f\"Dataset size: {total_size_kb/1024:.2f} MB\")\n",
        "print(f\"Average FPS: {fps_actual:.2f}\" if fps_actual > 0 else \"FPS: N/A\")\n",
        "print(f\"\\nMetadata files:\")\n",
        "print(f\"  - {csv_path}\")\n",
        "print(f\"  - {json_path}\")\n",
        "print(\"\\n\" + \"=\"*50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTQZeGF9F9yc"
      },
      "outputs": [],
      "source": [
        "# Display sample processed images\n",
        "sample_processed = []\n",
        "output_images = sorted(glob(os.path.join(OUTPUT_DIR, '*.jpg')))[:6]\n",
        "\n",
        "for img_path in output_images:\n",
        "    img = Image.open(img_path)\n",
        "    sample_processed.append(np.array(img))\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
        "axes = axes.flatten()\n",
        "for i, img in enumerate(sample_processed):\n",
        "    axes[i].imshow(img)\n",
        "    axes[i].set_title(f\"Processed - {img.shape}\")\n",
        "    axes[i].axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u31NZhA7F9yc"
      },
      "source": [
        "## Next Steps: Feature Extraction with MobileNet V2\n",
        "\n",
        "Your images are now ready for MobileNet V2 feature extraction. When you're ready to extract features:\n",
        "\n",
        "```python\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import pandas as pd\n",
        "\n",
        "# Load MobileNet V2 (without top classification layer)\n",
        "model = MobileNetV2(weights='imagenet', include_top=False, pooling='avg')\n",
        "\n",
        "# Load metadata\n",
        "df = pd.read_csv('processed_images/metadata.csv')\n",
        "\n",
        "# Extract features for each image\n",
        "features_list = []\n",
        "for idx, row in df.iterrows():\n",
        "    img_path = f\"processed_images/{row['filename']}\"\n",
        "    \n",
        "    # Load and preprocess\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img)\n",
        "    img_preprocessed = preprocess_input(img_array)  # Scale to [-1, 1]\n",
        "    \n",
        "    # Extract features\n",
        "    features = model.predict(np.expand_dims(img_preprocessed, axis=0))\n",
        "    features_list.append(features[0])\n",
        "\n",
        "# features_list now contains feature vectors for sensor fusion\n",
        "```\n",
        "\n",
        "**Note:** The `preprocess_input()` function applies the [-1, 1] scaling required by MobileNet V2."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
