{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A00785001/TC5035/blob/main/01_rosbag_lidar_pre_process.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6EH3D7caFS7"
      },
      "source": [
        "# ROS Bag LiDAR Data Reader & 1D CNN Preprocessor\n",
        "Extract and process LiDAR data for Geometric Branch (1D CNN) feature extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc73f01yaFS8"
      },
      "source": [
        "## Section 1: Read and Visualize LiDAR Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAnyoCFUaFS8"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet --upgrade jinja2>=3.1.2 markupsafe>=2.1.0\n",
        "!pip install --quiet bagpy pandas numpy matplotlib seaborn\n",
        "\n",
        "print(\"✓ All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HBGmKTnaFS-"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "from bagpy import bagreader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import seaborn as sns\n",
        "import os\n",
        "from glob import glob\n",
        "import json\n",
        "import csv\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "\n",
        "# Filter warnings for invalid LiDAR values (expected behavior)\n",
        "warnings.filterwarnings('ignore', message='invalid value encountered')\n",
        "\n",
        "print(\"Libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xI2I1-jFaFS_"
      },
      "outputs": [],
      "source": [
        "# Upload your ROS bag file (for Colab)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "bag_file = list(uploaded.keys())[0]\n",
        "print(f\"Uploaded: {bag_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4-V8PtMLaFS_"
      },
      "outputs": [],
      "source": [
        "# Read the bag file\n",
        "bag = bagreader(bag_file)\n",
        "print(f\"Opened bag file: {bag_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8IaOFjaaFS_"
      },
      "outputs": [],
      "source": [
        "# List all topics in the bag\n",
        "print(\"Topics in bag:\")\n",
        "print(bag.topic_table)\n",
        "print(\"\\nLook for LiDAR topics like: /scan, /lidar/scan, /laser_scan, etc.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zIOzUw_aFS_"
      },
      "outputs": [],
      "source": [
        "# Specify your LiDAR topic (common for Waveshare Jetbot with RPLidar)\n",
        "lidar_topic = \"/scan\"  # Modify if your topic is different\n",
        "print(f\"Using LiDAR topic: {lidar_topic}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znIZD4XTaFTA"
      },
      "outputs": [],
      "source": [
        "# Extract LiDAR data from the topic\n",
        "print(f\"Extracting LiDAR data from topic: {lidar_topic}\")\n",
        "lidar_csv_path = bag.message_by_topic(lidar_topic)\n",
        "print(f\"LiDAR data extracted to: {lidar_csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvpQMvK9aFTA"
      },
      "outputs": [],
      "source": [
        "# Load LiDAR data from CSV\n",
        "print(\"Loading LiDAR data...\")\n",
        "lidar_df = pd.read_csv(lidar_csv_path)\n",
        "\n",
        "print(f\"\\nLoaded {len(lidar_df)} LiDAR messages\")\n",
        "print(f\"\\nDataFrame shape: {lidar_df.shape}\")\n",
        "print(f\"\\nColumn names:\")\n",
        "print(lidar_df.columns.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nEW3lrCRaFTA"
      },
      "outputs": [],
      "source": [
        "# Display first few rows\n",
        "print(\"First few rows of LiDAR data:\")\n",
        "lidar_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQwHBtaraFTA"
      },
      "outputs": [],
      "source": [
        "# Display basic statistics (filtering invalid values)\n",
        "print(\"LiDAR data statistics (valid readings only):\")\n",
        "numeric_cols = lidar_df.select_dtypes(include=[np.number]).columns\n",
        "clean_df = lidar_df[numeric_cols].replace([np.inf, -np.inf], np.nan)\n",
        "clean_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB-kAZLYaFTA"
      },
      "outputs": [],
      "source": [
        "# Parse LaserScan data\n",
        "def parse_array_string(array_str):\n",
        "    \"\"\"\n",
        "    Parse array string from bagpy CSV into numpy array\n",
        "    Example: '[1.2, 3.4, 5.6]' -> np.array([1.2, 3.4, 5.6])\n",
        "    \"\"\"\n",
        "    if pd.isna(array_str) or array_str == '':\n",
        "        return np.array([])\n",
        "\n",
        "    array_str = str(array_str).strip('[]')\n",
        "    if array_str == '':\n",
        "        return np.array([])\n",
        "\n",
        "    try:\n",
        "        values = [float(x.strip()) for x in array_str.split(',') if x.strip()]\n",
        "        return np.array(values)\n",
        "    except:\n",
        "        return np.array([])\n",
        "\n",
        "print(\"Array parsing function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmAZR8X8aFTA"
      },
      "outputs": [],
      "source": [
        "# Extract scan parameters from first message\n",
        "first_scan = lidar_df.iloc[0]\n",
        "\n",
        "print(\"LaserScan Parameters:\")\n",
        "print(f\"  angle_min: {first_scan['angle_min']:.4f} rad ({np.rad2deg(first_scan['angle_min']):.1f}°)\")\n",
        "print(f\"  angle_max: {first_scan['angle_max']:.4f} rad ({np.rad2deg(first_scan['angle_max']):.1f}°)\")\n",
        "print(f\"  angle_increment: {first_scan['angle_increment']:.6f} rad ({np.rad2deg(first_scan['angle_increment']):.2f}°)\")\n",
        "print(f\"  time_increment: {first_scan['time_increment']:.6f} sec\")\n",
        "print(f\"  scan_time: {first_scan['scan_time']:.4f} sec\")\n",
        "print(f\"  range_min: {first_scan['range_min']:.4f} m\")\n",
        "print(f\"  range_max: {first_scan['range_max']:.4f} m\")\n",
        "\n",
        "# Parse ranges from first scan\n",
        "ranges_sample = parse_array_string(first_scan['ranges'])\n",
        "print(f\"\\n  Number of range readings per scan: {len(ranges_sample)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quZj26LyaFTA"
      },
      "outputs": [],
      "source": [
        "# Function to convert LaserScan to Cartesian coordinates\n",
        "def laserscan_to_cartesian(ranges, angle_min, angle_increment):\n",
        "    \"\"\"\n",
        "    Convert LaserScan ranges to Cartesian (x, y) coordinates\n",
        "    \"\"\"\n",
        "    angles = angle_min + np.arange(len(ranges)) * angle_increment\n",
        "    valid_mask = np.isfinite(ranges) & (ranges > 0)\n",
        "\n",
        "    valid_ranges = ranges[valid_mask]\n",
        "    valid_angles = angles[valid_mask]\n",
        "\n",
        "    x = valid_ranges * np.cos(valid_angles)\n",
        "    y = valid_ranges * np.sin(valid_angles)\n",
        "\n",
        "    return x, y, valid_angles, valid_ranges\n",
        "\n",
        "print(\"Cartesian conversion function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbq1ZL6KaFTA"
      },
      "outputs": [],
      "source": [
        "# Visualize a single LiDAR scan\n",
        "scan_idx = 0\n",
        "scan = lidar_df.iloc[scan_idx]\n",
        "\n",
        "ranges = parse_array_string(scan['ranges'])\n",
        "x, y, angles, valid_ranges = laserscan_to_cartesian(\n",
        "    ranges, scan['angle_min'], scan['angle_increment']\n",
        ")\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Polar plot\n",
        "ax1 = plt.subplot(121, projection='polar')\n",
        "ax1.scatter(angles, valid_ranges, s=5, c=valid_ranges, cmap='viridis')\n",
        "ax1.set_title(f'LiDAR Scan #{scan_idx} - Polar View', fontsize=14)\n",
        "ax1.set_theta_zero_location('N')\n",
        "ax1.set_ylim(0, scan['range_max'])\n",
        "\n",
        "# Cartesian plot\n",
        "ax2 = plt.subplot(122)\n",
        "scatter = ax2.scatter(x, y, s=10, c=valid_ranges, cmap='viridis')\n",
        "ax2.plot(0, 0, 'r*', markersize=15, label='Robot')\n",
        "ax2.set_xlabel('X (meters)', fontsize=12)\n",
        "ax2.set_ylabel('Y (meters)', fontsize=12)\n",
        "ax2.set_title(f'LiDAR Scan #{scan_idx} - Cartesian View', fontsize=14)\n",
        "ax2.axis('equal')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.legend()\n",
        "plt.colorbar(scatter, ax=ax2, label='Range (m)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Scan timestamp: {scan['Time']}\")\n",
        "print(f\"Valid points: {len(valid_ranges)} / {len(ranges)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShWP_xI1aFTB"
      },
      "outputs": [],
      "source": [
        "# Visualize multiple scans\n",
        "num_scans_to_plot = min(6, len(lidar_df))\n",
        "scan_indices = np.linspace(0, len(lidar_df)-1, num_scans_to_plot, dtype=int)\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, scan_idx in enumerate(scan_indices):\n",
        "    scan = lidar_df.iloc[scan_idx]\n",
        "    ranges = parse_array_string(scan['ranges'])\n",
        "    x, y, angles, valid_ranges = laserscan_to_cartesian(\n",
        "        ranges, scan['angle_min'], scan['angle_increment']\n",
        "    )\n",
        "\n",
        "    ax = axes[i]\n",
        "    scatter = ax.scatter(x, y, s=5, c=valid_ranges, cmap='viridis', vmin=0, vmax=scan['range_max'])\n",
        "    ax.plot(0, 0, 'r*', markersize=10)\n",
        "    ax.set_xlabel('X (m)')\n",
        "    ax.set_ylabel('Y (m)')\n",
        "    ax.set_title(f'Scan #{scan_idx} - t={scan[\"Time\"]:.2f}s')\n",
        "    ax.axis('equal')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olaUY710aFTB"
      },
      "outputs": [],
      "source": [
        "# Analyze range statistics across all scans\n",
        "print(\"Analyzing range statistics across all scans...\")\n",
        "\n",
        "all_ranges = []\n",
        "for idx in range(len(lidar_df)):\n",
        "    ranges = parse_array_string(lidar_df.iloc[idx]['ranges'])\n",
        "    valid_ranges = ranges[np.isfinite(ranges) & (ranges > 0)]\n",
        "    all_ranges.extend(valid_ranges)\n",
        "\n",
        "all_ranges = np.array(all_ranges)\n",
        "\n",
        "print(f\"\\nTotal valid range measurements: {len(all_ranges):,}\")\n",
        "print(f\"Min range: {all_ranges.min():.4f} m\")\n",
        "print(f\"Max range: {all_ranges.max():.4f} m\")\n",
        "print(f\"Mean range: {all_ranges.mean():.4f} m\")\n",
        "print(f\"Median range: {np.median(all_ranges):.4f} m\")\n",
        "print(f\"Std dev: {all_ranges.std():.4f} m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YakTqpI1aFTB"
      },
      "outputs": [],
      "source": [
        "# Plot range distribution\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].hist(all_ranges, bins=50, edgecolor='black', alpha=0.7)\n",
        "axes[0].set_xlabel('Range (meters)', fontsize=12)\n",
        "axes[0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0].set_title('Distribution of LiDAR Range Measurements', fontsize=14)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].boxplot(all_ranges, vert=True)\n",
        "axes[1].set_ylabel('Range (meters)', fontsize=12)\n",
        "axes[1].set_title('LiDAR Range Box Plot', fontsize=14)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmxyEFieaFTB"
      },
      "outputs": [],
      "source": [
        "# Create summary statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LIDAR DATA SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Source bag: {bag_file}\")\n",
        "print(f\"LiDAR topic: {lidar_topic}\")\n",
        "print(f\"Total scans: {len(lidar_df)}\")\n",
        "print(f\"\\nScan parameters:\")\n",
        "print(f\"  Angular range: {np.rad2deg(first_scan['angle_min']):.1f}° to {np.rad2deg(first_scan['angle_max']):.1f}°\")\n",
        "print(f\"  Angular resolution: {np.rad2deg(first_scan['angle_increment']):.2f}°\")\n",
        "print(f\"  Range: {first_scan['range_min']:.2f}m to {first_scan['range_max']:.2f}m\")\n",
        "print(f\"  Points per scan: {len(ranges_sample)}\")\n",
        "print(f\"  Scan rate: {1.0/first_scan['scan_time']:.1f} Hz\")\n",
        "print(f\"\\nData quality:\")\n",
        "print(f\"  Total measurements: {len(all_ranges):,}\")\n",
        "print(f\"  Average valid points per scan: {len(all_ranges)/len(lidar_df):.1f}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6sCGz4uaFTB"
      },
      "source": [
        "## Section 2: Process LiDAR for 1D CNN (Geometric Branch)\n",
        "\n",
        "### Purpose\n",
        "This section prepares LiDAR scans for geometric feature extraction using a custom 1D CNN. The goal is to clean, normalize, and format 360-degree distance measurements for the Geometric Branch of the sensor fusion pipeline.\n",
        "\n",
        "### What This Section Does\n",
        "1. **Cleans** invalid readings (inf/nan) by replacing with max_range\n",
        "2. **Resamples** to exactly 360 points (if needed)\n",
        "3. **Normalizes** ranges to [0, 1] for CNN training stability\n",
        "4. **Saves** as CSV files (one scan per file)\n",
        "5. **Preserves** ROS timestamps for temporal alignment with camera\n",
        "6. **Generates** metadata for tracking and reproducibility\n",
        "\n",
        "### Processing Pipeline\n",
        "```\n",
        "ROS Bag Scans → Parse Ranges → Clean (inf→max_range) → Normalize [0,1] → Save CSV\n",
        "```\n",
        "\n",
        "### Output Structure\n",
        "```\n",
        "processed_lidar/\n",
        "├── scan_00000.csv         # Single row: 360 normalized values\n",
        "├── scan_00001.csv\n",
        "├── scan_00002.csv\n",
        "├── ...\n",
        "├── metadata.csv           # Per-scan data (timestamps, statistics)\n",
        "└── dataset_info.json      # Dataset-level metadata\n",
        "```\n",
        "\n",
        "### File Formats\n",
        "\n",
        "**Scan CSVs (scan_*.csv):**\n",
        "- Format: CSV with **no header**, single row\n",
        "- Shape: 1 row × 360 columns\n",
        "- Values: Normalized ranges in [0, 1]\n",
        "- Example: `0.234,0.456,0.789,...` (360 values)\n",
        "- Load with: `pd.read_csv('scan_00000.csv', header=None).values[0]`\n",
        "\n",
        "**metadata.csv:**\n",
        "| Column | Type | Description |\n",
        "|--------|------|-------------|\n",
        "| filename | str | Scan filename (scan_XXXXX.csv) |\n",
        "| timestamp | float | ROS timestamp (seconds) |\n",
        "| timestamp_sec | int | Timestamp seconds part |\n",
        "| timestamp_nsec | int | Timestamp nanoseconds part |\n",
        "| frame_id | int | Sequential frame number |\n",
        "| num_points | int | Number of points (always 360) |\n",
        "| valid_points | int | Original valid points before cleaning |\n",
        "| avg_range | float | Average range (meters, before normalization) |\n",
        "| min_range | float | Minimum range (meters) |\n",
        "| max_range | float | Maximum range (meters) |\n",
        "\n",
        "**dataset_info.json:**\n",
        "- ROS bag information (source, duration, timestamps)\n",
        "- LiDAR specifications (model, topic, angular resolution, range limits)\n",
        "- Processing parameters (invalid handling, normalization method)\n",
        "- Geometric branch pipeline info (input shape, expected output)\n",
        "- Dataset statistics (scan rate, average valid points)\n",
        "\n",
        "### Data Cleaning Rationale\n",
        "\n",
        "**Why replace inf/nan with max_range?**\n",
        "- `inf` means \"beyond sensor range\" → semantically equals max_range\n",
        "- `nan` means \"no valid reading\" → treat as max_range (no obstacle)\n",
        "- Preserves information: \"far away\" vs \"error at 0m\"\n",
        "- CNN-friendly: no special handling for inf/nan needed\n",
        "\n",
        "**Why normalize to [0, 1]?**\n",
        "- Standard practice for neural network inputs\n",
        "- Training stability and convergence\n",
        "- Model becomes sensor-agnostic (different LiDARs have different max_range)\n",
        "- Value of 1.0 = max_range, 0.0 = at sensor\n",
        "\n",
        "### Geometric Branch Pipeline\n",
        "\n",
        "**Target Architecture:**\n",
        "- Input: 360 distance values (normalized)\n",
        "- Model: 1D CNN with 4 Conv1D layers + Global Average Pooling\n",
        "- Parameters: ~350K\n",
        "- Output: 256D raw geometric descriptor\n",
        "- Post-processing: L2 normalization\n",
        "- Final output: 256D normalized feature vector\n",
        "- Inference: ~20-30ms on TensorRT FP16\n",
        "\n",
        "### Important Notes\n",
        "- **No feature extraction yet**: This notebook only preprocesses data. Feature extraction happens in a separate notebook.\n",
        "- **Timestamps critical**: Enable alignment with camera features for sensor fusion.\n",
        "- **No labels yet**: Data is unlabeled; loop closure labels assigned after feature extraction.\n",
        "- **Normalized output**: Values in [0, 1] ready for 1D CNN input.\n",
        "\n",
        "### Next Step: Feature Extraction\n",
        "After running this section, scans are ready for 1D CNN feature extraction. The feature extraction notebook will:\n",
        "1. Load these normalized CSVs\n",
        "2. Pass through 1D CNN (4 Conv1D + GAP)\n",
        "3. Output 256D geometric descriptors\n",
        "4. Apply L2 normalization\n",
        "5. Save features for sensor fusion\n",
        "\n",
        "### Usage Example (for next pipeline stage)\n",
        "```python\n",
        "# Load a processed scan\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "scan = pd.read_csv('processed_lidar/scan_00000.csv', header=None).values[0]\n",
        "# Shape: (360,), Range: [0, 1]\n",
        "\n",
        "# Convert to tensor for PyTorch\n",
        "scan_tensor = torch.tensor(scan, dtype=torch.float32).unsqueeze(0).unsqueeze(0)\n",
        "# Shape: (1, 1, 360) for Conv1D input\n",
        "\n",
        "# Pass through 1D CNN (in feature extraction notebook)\n",
        "# features = model(scan_tensor)  # Output: (1, 256)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tcFKU9naFTB"
      },
      "outputs": [],
      "source": [
        "# Set processing parameters\n",
        "RANGE_MIN = first_scan['range_min']\n",
        "RANGE_MAX = first_scan['range_max']\n",
        "TARGET_LENGTH = 360  # Expected by 1D CNN\n",
        "\n",
        "print(f\"Processing parameters:\")\n",
        "print(f\"  Range min: {RANGE_MIN:.2f} m\")\n",
        "print(f\"  Range max: {RANGE_MAX:.2f} m\")\n",
        "print(f\"  Target length: {TARGET_LENGTH} points\")\n",
        "print(f\"  Output format: CSV\")\n",
        "print(f\"  Normalization: [0, 1]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0ghMZj9aFTB"
      },
      "outputs": [],
      "source": [
        "# Create output folder\n",
        "OUTPUT_DIR = \"processed_lidar\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"Created output directory: {OUTPUT_DIR}/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHjzf_bMaFTB"
      },
      "outputs": [],
      "source": [
        "# Function to process LiDAR scan\n",
        "def process_lidar_scan(ranges, range_max, target_length=360):\n",
        "    \"\"\"\n",
        "    Process LiDAR scan for 1D CNN:\n",
        "    1. Replace inf/nan with max_range (semantically correct)\n",
        "    2. Resample to target_length if needed\n",
        "    3. Normalize to [0, 1]\n",
        "\n",
        "    Returns: processed_ranges (normalized), num_valid_points, statistics\n",
        "    \"\"\"\n",
        "    # Count original valid points\n",
        "    original_valid = np.sum(np.isfinite(ranges) & (ranges > 0))\n",
        "\n",
        "    # Replace inf with max_range (beyond range = max_range)\n",
        "    ranges_clean = np.where(np.isinf(ranges), range_max, ranges)\n",
        "\n",
        "    # Replace nan with max_range (no reading = max_range)\n",
        "    ranges_clean = np.where(np.isnan(ranges_clean), range_max, ranges_clean)\n",
        "\n",
        "    # Resample to target length if needed\n",
        "    if len(ranges_clean) != target_length:\n",
        "        indices = np.linspace(0, len(ranges_clean)-1, target_length)\n",
        "        ranges_clean = np.interp(indices, np.arange(len(ranges_clean)), ranges_clean)\n",
        "\n",
        "    # Calculate statistics before normalization\n",
        "    stats = {\n",
        "        'min': float(np.min(ranges_clean)),\n",
        "        'max': float(np.max(ranges_clean)),\n",
        "        'mean': float(np.mean(ranges_clean)),\n",
        "        'median': float(np.median(ranges_clean))\n",
        "    }\n",
        "\n",
        "    # Normalize to [0, 1]\n",
        "    ranges_normalized = ranges_clean / range_max\n",
        "\n",
        "    return ranges_normalized, original_valid, stats\n",
        "\n",
        "print(\"Processing function ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v5GEZd17aFTB"
      },
      "outputs": [],
      "source": [
        "# Process all scans\n",
        "print(\"Processing LiDAR scans...\")\n",
        "\n",
        "metadata_list = []\n",
        "processed_count = 0\n",
        "failed_count = 0\n",
        "\n",
        "for idx in range(len(lidar_df)):\n",
        "    try:\n",
        "        scan = lidar_df.iloc[idx]\n",
        "\n",
        "        # Parse ranges\n",
        "        ranges = parse_array_string(scan['ranges'])\n",
        "\n",
        "        if len(ranges) == 0:\n",
        "            print(f\"Warning: Empty scan at index {idx}\")\n",
        "            failed_count += 1\n",
        "            continue\n",
        "\n",
        "        # Process scan\n",
        "        ranges_processed, valid_points, stats = process_lidar_scan(\n",
        "            ranges, RANGE_MAX, TARGET_LENGTH\n",
        "        )\n",
        "\n",
        "        # Save as CSV (one row with 360 values)\n",
        "        output_filename = f\"scan_{idx:05d}.csv\"\n",
        "        output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
        "\n",
        "        # Save the normalized ranges as a single row\n",
        "        pd.DataFrame([ranges_processed]).to_csv(output_path, index=False, header=False)\n",
        "\n",
        "        # Get timestamp info\n",
        "        timestamp = scan['Time']\n",
        "        timestamp_sec = int(timestamp)\n",
        "        timestamp_nsec = int((timestamp - timestamp_sec) * 1e9)\n",
        "\n",
        "        # Store metadata\n",
        "        metadata_list.append({\n",
        "            'filename': output_filename,\n",
        "            'timestamp': timestamp,\n",
        "            'timestamp_sec': timestamp_sec,\n",
        "            'timestamp_nsec': timestamp_nsec,\n",
        "            'frame_id': idx,\n",
        "            'num_points': TARGET_LENGTH,\n",
        "            'valid_points': valid_points,\n",
        "            'avg_range': round(stats['mean'], 4),\n",
        "            'min_range': round(stats['min'], 4),\n",
        "            'max_range': round(stats['max'], 4)\n",
        "        })\n",
        "\n",
        "        processed_count += 1\n",
        "\n",
        "        if (idx + 1) % 100 == 0:\n",
        "            print(f\"Processed {idx + 1}/{len(lidar_df)} scans\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing scan {idx}: {e}\")\n",
        "        failed_count += 1\n",
        "\n",
        "print(f\"\\n✓ Completed: {processed_count} scans processed\")\n",
        "print(f\"✗ Failed: {failed_count} scans\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5hLFMqsaFTC"
      },
      "outputs": [],
      "source": [
        "# Save metadata CSV\n",
        "csv_path = os.path.join(OUTPUT_DIR, 'metadata.csv')\n",
        "\n",
        "with open(csv_path, 'w', newline='') as csvfile:\n",
        "    fieldnames = ['filename', 'timestamp', 'timestamp_sec', 'timestamp_nsec',\n",
        "                  'frame_id', 'num_points', 'valid_points', 'avg_range', 'min_range', 'max_range']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for row in metadata_list:\n",
        "        writer.writerow(row)\n",
        "\n",
        "print(f\"✓ CSV metadata saved: {csv_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoC65sJpaFTC"
      },
      "outputs": [],
      "source": [
        "# Calculate statistics\n",
        "if metadata_list:\n",
        "    avg_valid_points = np.mean([m['valid_points'] for m in metadata_list])\n",
        "    avg_range = np.mean([m['avg_range'] for m in metadata_list])\n",
        "\n",
        "    # Calculate scan rate\n",
        "    if len(metadata_list) > 1:\n",
        "        time_diff = metadata_list[-1]['timestamp'] - metadata_list[0]['timestamp']\n",
        "        scan_rate = len(metadata_list) / time_diff if time_diff > 0 else 0\n",
        "    else:\n",
        "        scan_rate = 0\n",
        "else:\n",
        "    avg_valid_points = 0\n",
        "    avg_range = 0\n",
        "    scan_rate = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W11JR4F2aFTC"
      },
      "outputs": [],
      "source": [
        "# Create JSON metadata\n",
        "json_metadata = {\n",
        "    \"dataset_metadata\": {\n",
        "        \"creation_date\": datetime.now().isoformat(),\n",
        "        \"ros_bag_info\": {\n",
        "            \"source_file\": bag_file,\n",
        "            \"bag_duration_sec\": metadata_list[-1]['timestamp'] - metadata_list[0]['timestamp'] if len(metadata_list) > 1 else 0,\n",
        "            \"bag_start_time\": metadata_list[0]['timestamp'] if metadata_list else 0,\n",
        "            \"bag_end_time\": metadata_list[-1]['timestamp'] if metadata_list else 0\n",
        "        },\n",
        "        \"lidar_info\": {\n",
        "            \"model\": \"RPLidar (detected from data)\",\n",
        "            \"topic\": lidar_topic,\n",
        "            \"angle_min_deg\": round(np.rad2deg(first_scan['angle_min']), 2),\n",
        "            \"angle_max_deg\": round(np.rad2deg(first_scan['angle_max']), 2),\n",
        "            \"angle_resolution_deg\": round(np.rad2deg(first_scan['angle_increment']), 2),\n",
        "            \"scan_rate_hz\": round(scan_rate, 2),\n",
        "            \"range_min_m\": float(RANGE_MIN),\n",
        "            \"range_max_m\": float(RANGE_MAX)\n",
        "        },\n",
        "        \"processing_info\": {\n",
        "            \"target_length\": TARGET_LENGTH,\n",
        "            \"output_format\": \"csv\",\n",
        "            \"invalid_handling\": \"inf/nan -> max_range\",\n",
        "            \"normalization\": \"[0, 1] range\",\n",
        "            \"normalization_factor\": float(RANGE_MAX),\n",
        "            \"total_scans_processed\": processed_count,\n",
        "            \"processing_script\": \"rosbag_lidar_processor_v1.ipynb\"\n",
        "        }\n",
        "    },\n",
        "    \"geometric_branch_pipeline\": {\n",
        "        \"input_shape\": [TARGET_LENGTH],\n",
        "        \"input_range\": [0, 1],\n",
        "        \"model_type\": \"1D CNN (4 Conv1D + GAP)\",\n",
        "        \"output_features\": 256,\n",
        "        \"normalization\": \"L2\",\n",
        "        \"notes\": \"Ready for loop closure detection via geometric descriptors\"\n",
        "    },\n",
        "    \"statistics\": {\n",
        "        \"scan_rate_hz\": round(scan_rate, 2),\n",
        "        \"avg_valid_points_per_scan\": round(avg_valid_points, 1),\n",
        "        \"avg_range_m\": round(avg_range, 2),\n",
        "        \"total_scans\": processed_count,\n",
        "        \"failed_scans\": failed_count\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save JSON metadata\n",
        "json_path = os.path.join(OUTPUT_DIR, 'dataset_info.json')\n",
        "with open(json_path, 'w') as jsonfile:\n",
        "    json.dump(json_metadata, jsonfile, indent=2)\n",
        "\n",
        "print(f\"✓ JSON metadata saved: {json_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRrthi1laFTC"
      },
      "outputs": [],
      "source": [
        "# Display processing summary\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"LIDAR PROCESSING COMPLETE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Output directory: {OUTPUT_DIR}/\")\n",
        "print(f\"Total scans processed: {processed_count}\")\n",
        "print(f\"Points per scan: {TARGET_LENGTH}\")\n",
        "print(f\"Value range: [0, 1] (normalized)\")\n",
        "print(f\"Average scan rate: {scan_rate:.2f} Hz\")\n",
        "print(f\"\\nMetadata files:\")\n",
        "print(f\"  - {csv_path}\")\n",
        "print(f\"  - {json_path}\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xTrOIkMZaFTC"
      },
      "outputs": [],
      "source": [
        "# Verify processed data\n",
        "print(\"\\nVerifying processed scans...\")\n",
        "\n",
        "# Load a sample processed scan\n",
        "sample_file = os.path.join(OUTPUT_DIR, metadata_list[0]['filename'])\n",
        "sample_scan = pd.read_csv(sample_file, header=None).values[0]\n",
        "\n",
        "print(f\"Sample scan shape: {sample_scan.shape}\")\n",
        "print(f\"Value range: [{sample_scan.min():.4f}, {sample_scan.max():.4f}]\")\n",
        "print(f\"Mean value: {sample_scan.mean():.4f}\")\n",
        "print(f\"\\nFirst 10 values: {sample_scan[:10]}\")\n",
        "\n",
        "# Visualize processed scan\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Line plot\n",
        "ax1.plot(sample_scan, linewidth=0.5)\n",
        "ax1.set_xlabel('Point Index', fontsize=12)\n",
        "ax1.set_ylabel('Normalized Range [0, 1]', fontsize=12)\n",
        "ax1.set_title('Processed LiDAR Scan (Normalized)', fontsize=14)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Polar plot\n",
        "ax2 = plt.subplot(122, projection='polar')\n",
        "angles = np.linspace(0, 2*np.pi, TARGET_LENGTH, endpoint=False)\n",
        "ax2.plot(angles, sample_scan, linewidth=0.5)\n",
        "ax2.set_title('Polar View (Normalized)', fontsize=14)\n",
        "ax2.set_ylim(0, 1)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bekyKphfaFTC"
      },
      "source": [
        "## Next Steps: 1D CNN Feature Extraction\n",
        "\n",
        "Processed scans are ready for the Geometric Branch pipeline:\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Load metadata\n",
        "metadata = pd.read_csv('processed_lidar/metadata.csv')\n",
        "\n",
        "# Load a scan\n",
        "scan = pd.read_csv(f\"processed_lidar/{metadata.iloc[0]['filename']}\", header=None).values[0]\n",
        "\n",
        "# Convert to tensor (shape: [1, 360])\n",
        "scan_tensor = torch.tensor(scan, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "# Pass through 1D CNN (your model)\n",
        "# features = model(scan_tensor)  # Output: [1, 256] raw features\n",
        "# features_normalized = F.normalize(features, p=2, dim=1)  # L2 normalized\n",
        "```\n",
        "\n",
        "**Data Format:**\n",
        "- Each CSV: 360 normalized range values (single row)\n",
        "- Range: [0, 1] where 1.0 = max_range\n",
        "- Ready for Conv1D input: (batch, channels=1, length=360)\n",
        "- Timestamps preserved for sensor fusion alignment"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}