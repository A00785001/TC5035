{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A00785001/TC5035/blob/main/001-EDA-Image_Branch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgIYXrjmumyz"
      },
      "source": [
        "# Exploratory Data Analysis - Image Branch\n",
        "Extract and analyze data from ROS bags with image EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKrksA-lIk9i"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 1. Initialization and Setup</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBQiCupLumy0"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet rosbags opencv-python pillow numpy matplotlib tqdm seaborn pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahHvN_bEumy1"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import json\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import io\n",
        "\n",
        "print(\"Libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrvgY5gk-xnC"
      },
      "outputs": [],
      "source": [
        "from rosbags.rosbag1 import Reader\n",
        "from rosbags.typesys import Stores, get_typestore\n",
        "import os\n",
        "from pathlib import Path\n",
        "print(\"Libraries loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_x4Qx0Oeumy2"
      },
      "outputs": [],
      "source": [
        "# Initialize typestore for ROS1 message deserialization\n",
        "typestore = get_typestore(Stores.ROS1_NOETIC)\n",
        "print(\"Typestore initialized for ROS1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruqjo9QVIk9k"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 2. Storage Mounting</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4A4E6Bwumy3"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gc_txcDtIk9k"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 3. ROS Bag Load</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ym09k1qwvnNB"
      },
      "outputs": [],
      "source": [
        "# Specify the path to the sessions folder\n",
        "data_path = \"/content/drive/MyDrive/DATA/Artificial_Intelligence/MNA-V/Subjects/TC5035-Proyecto_Integrador/TC5035.data/jetbot/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDG2Pve9vx_k"
      },
      "outputs": [],
      "source": [
        "# Specify the session\n",
        "session = '20251016_133216'\n",
        "print(f\"Using session: {session}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mV8nBLXqumy4"
      },
      "outputs": [],
      "source": [
        "working_folder = data_path + 'session_' + session\n",
        "bag_name = 'session_data.bag'\n",
        "\n",
        "# Change to the specified subfolder\n",
        "os.chdir(working_folder)\n",
        "print(f\"Changed directory to: {os.getcwd()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ao2LOd4v_hu8"
      },
      "outputs": [],
      "source": [
        "bag_file = working_folder + '/' + bag_name\n",
        "print(f\"Bag file name: {bag_name}\")\n",
        "\n",
        "# Set bag_path for the rest of the notebook\n",
        "bag_path = bag_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3QoTWqrumy5"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 4. ROS Bag Basic EDA</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlJ6IqErumy5"
      },
      "source": [
        "### 1. Basic Bag Information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gzgll0Seumy5"
      },
      "outputs": [],
      "source": [
        "# Open the bag and get basic information\n",
        "print(\"=\" * 60)\n",
        "print(\"BASIC BAG INFORMATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with Reader(bag_path) as reader:\n",
        "    # Get basic statistics\n",
        "    duration = reader.duration * 1e-9  # Convert to seconds\n",
        "    duration_sec = duration\n",
        "    total_messages = reader.message_count\n",
        "\n",
        "    # Get file size\n",
        "    file_size_bytes = os.path.getsize(bag_path)\n",
        "    file_size_mb = file_size_bytes / (1024 * 1024)\n",
        "\n",
        "    # Calculate average message rate\n",
        "    avg_message_rate = total_messages / duration if duration > 0 else 0\n",
        "\n",
        "    print(f\"\\nüìÅ File: {bag_name}\")\n",
        "    print(f\"üíæ Size: {file_size_mb:.2f} MB\")\n",
        "    print(f\"‚è±Ô∏è  Duration: {duration:.2f} seconds ({duration/60:.2f} minutes)\")\n",
        "    print(f\"üì¨ Total Messages: {total_messages:,}\")\n",
        "    print(f\"üìä Average Rate: {avg_message_rate:.2f} msg/sec\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1ydJGRHumy6"
      },
      "source": [
        "### 2. Topic Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFMEMKgIumy6"
      },
      "outputs": [],
      "source": [
        "# Analyze topics and connections\n",
        "print(\"=\" * 60)\n",
        "print(\"TOPIC ANALYSIS (ROS1 BAG)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "import struct\n",
        "\n",
        "def parse_tf_binary(rawdata):\n",
        "    \"\"\"Parse TF message from raw bytes\"\"\"\n",
        "    transforms = set()\n",
        "    for start_offset in [0, 4, 8, 12, 16]:\n",
        "        try:\n",
        "            offset = start_offset\n",
        "            array_len = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "            if array_len > 100 or array_len == 0:\n",
        "                continue\n",
        "            offset += 4\n",
        "\n",
        "            for _ in range(min(array_len, 5)):\n",
        "                offset += 12  # Skip seq + stamp\n",
        "                str_len = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "                if str_len > 100 or str_len == 0:\n",
        "                    break\n",
        "                offset += 4\n",
        "                parent = rawdata[offset:offset+str_len].decode('utf-8', errors='ignore').strip('\\\\x00').strip('/')\n",
        "                offset += str_len\n",
        "\n",
        "                str_len = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "                if str_len > 100 or str_len == 0:\n",
        "                    break\n",
        "                offset += 4\n",
        "                child = rawdata[offset:offset+str_len].decode('utf-8', errors='ignore').strip('\\\\x00').strip('/')\n",
        "                offset += str_len + 56  # Skip transform data\n",
        "\n",
        "                if parent and child and len(parent) < 50 and len(child) < 50:\n",
        "                    transforms.add(f\"{parent}‚Üí{child}\")\n",
        "            if transforms:\n",
        "                return transforms\n",
        "        except:\n",
        "            continue\n",
        "    return transforms\n",
        "\n",
        "# Get basic topic information with connection indices\n",
        "with Reader(bag_path) as reader:\n",
        "    topics_data = []\n",
        "    connection_map = {}  # Store connection index mapping\n",
        "\n",
        "    for conn_idx, connection in enumerate(reader.connections):\n",
        "        topics_data.append({\n",
        "            'Topic': connection.topic,\n",
        "            'Message Type': connection.msgtype,\n",
        "            'Count': connection.msgcount,\n",
        "            'Connection_Index': conn_idx,\n",
        "            'Description': \"\"\n",
        "        })\n",
        "        # Map for later use\n",
        "        connection_map[conn_idx] = {'topic': connection.topic, 'msgtype': connection.msgtype, 'msgcount': connection.msgcount}\n",
        "\n",
        "    df_topics = pd.DataFrame(topics_data)\n",
        "\n",
        "# Analyze TF connections\n",
        "print(\"\\\\nüîç Analyzing TF connections...\")\n",
        "with Reader(bag_path) as reader:\n",
        "    tf_connection_data = {}\n",
        "\n",
        "    for conn_idx, conn in enumerate(reader.connections):\n",
        "        if conn.topic in ['/tf', '/tf_static']:\n",
        "            tf_connection_data[conn_idx] = {'transforms': set(), 'samples': 0}\n",
        "\n",
        "    for connection, timestamp, rawdata in reader.messages():\n",
        "        if connection.topic in ['/tf', '/tf_static']:\n",
        "            conn_idx = None\n",
        "            for idx, conn in enumerate(reader.connections):\n",
        "                if (conn.topic == connection.topic and\n",
        "                    conn.msgtype == connection.msgtype and\n",
        "                    conn.msgcount == connection.msgcount):\n",
        "                    conn_idx = idx\n",
        "                    break\n",
        "\n",
        "            if conn_idx is not None and conn_idx in tf_connection_data:\n",
        "                if tf_connection_data[conn_idx]['samples'] < 10:\n",
        "                    try:\n",
        "                        msg = typestore.deserialize_ros1(rawdata, connection.msgtype)\n",
        "                        for tf in msg.transforms:\n",
        "                            parent = tf.header.frame_id.strip('/')\n",
        "                            child = tf.child_frame_id.strip('/')\n",
        "                            tf_connection_data[conn_idx]['transforms'].add(f\"{parent}‚Üí{child}\")\n",
        "                    except:\n",
        "                        binary_transforms = parse_tf_binary(rawdata)\n",
        "                        if binary_transforms:\n",
        "                            tf_connection_data[conn_idx]['transforms'].update(binary_transforms)\n",
        "                    tf_connection_data[conn_idx]['samples'] += 1\n",
        "\n",
        "# Classify TF connections\n",
        "for idx, row in df_topics.iterrows():\n",
        "    if row['Topic'] in ['/tf', '/tf_static']:\n",
        "        conn_idx = row['Connection_Index']\n",
        "\n",
        "        if conn_idx in tf_connection_data:\n",
        "            transforms = tf_connection_data[conn_idx]['transforms']\n",
        "\n",
        "            if transforms:\n",
        "                transforms_str = ', '.join(sorted(transforms)[:5])\n",
        "                if len(transforms) > 5:\n",
        "                    transforms_str += f\" (+{len(transforms)-5} more)\"\n",
        "\n",
        "                transforms_lower = ' '.join(transforms).lower()\n",
        "\n",
        "                if 'map' in transforms_lower and 'odom' in transforms_lower:\n",
        "                    classification = \"SLAM\"\n",
        "                elif 'odom' in transforms_lower and 'base' in transforms_lower:\n",
        "                    classification = \"Odometry\"\n",
        "                elif 'imu' in transforms_lower or 'laser' in transforms_lower or 'camera' in transforms_lower:\n",
        "                    classification = \"Static\"\n",
        "                else:\n",
        "                    classification = \"Other\"\n",
        "\n",
        "                df_topics.at[idx, 'Description'] = f\"{classification}: {transforms_str}\"\n",
        "            else:\n",
        "                freq = row['Count'] / duration_sec\n",
        "                if freq > 40:\n",
        "                    classification = \"SLAM\"\n",
        "                elif freq > 30:\n",
        "                    classification = \"Odometry\"\n",
        "                elif freq > 15:\n",
        "                    classification = \"Static\"\n",
        "                else:\n",
        "                    classification = \"Other\"\n",
        "                df_topics.at[idx, 'Description'] = f\"{classification} (by frequency)\"\n",
        "\n",
        "# Display\n",
        "df_topics_display = df_topics.drop('Connection_Index', axis=1)\n",
        "df_topics_display = df_topics_display.sort_values('Count', ascending=False)\n",
        "df_topics_display['Frequency (Hz)'] = df_topics_display['Count'] / duration_sec\n",
        "\n",
        "print(f\"\\\\nüìä Total Connections: {len(df_topics_display)}\")\n",
        "print(f\"üìä Unique Topics: {df_topics_display['Topic'].nunique()}\")\n",
        "print(f\"\\\\n{df_topics_display.to_string(index=False)}\")\n",
        "\n",
        "df_topics_display.to_csv('topic_statistics.csv', index=False)\n",
        "print(f\"\\\\n‚úÖ Topic statistics saved to: topic_statistics.csv\")\n",
        "\n",
        "unique_topics = df_topics_display['Topic'].tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rZr6g6F93l_"
      },
      "source": [
        "### 3. Message Frequency Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qrxfvlO93l_"
      },
      "outputs": [],
      "source": [
        "# Analyze message frequency distribution\n",
        "print(\"=\" * 60)\n",
        "print(\"MESSAGE FREQUENCY DISTRIBUTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with Reader(bag_path) as reader:\n",
        "    connection_timestamps = defaultdict(list)  # Track by connection index\n",
        "    topic_timestamps = defaultdict(list)  # Also track by topic for backward compatibility\n",
        "\n",
        "    print(\"\\\\nCollecting timestamps...\")\n",
        "    for connection, timestamp, rawdata in tqdm(reader.messages(), total=reader.message_count):\n",
        "        topic = connection.topic\n",
        "        timestamp_sec = timestamp * 1e-9\n",
        "\n",
        "        # Add to topic_timestamps\n",
        "        topic_timestamps[topic].append(timestamp_sec)\n",
        "\n",
        "        # Find connection index for detailed tracking\n",
        "        conn_idx = None\n",
        "        for idx, conn in enumerate(reader.connections):\n",
        "            if (conn.topic == connection.topic and\n",
        "                conn.msgtype == connection.msgtype and\n",
        "                conn.msgcount == connection.msgcount):\n",
        "                conn_idx = idx\n",
        "                break\n",
        "\n",
        "        if conn_idx is not None:\n",
        "            connection_timestamps[conn_idx].append(timestamp_sec)\n",
        "\n",
        "    print(\"\\\\nüìà Inter-Message Interval Statistics (by connection):\")\n",
        "    print(f\"{'Topic':<40} {'Description':<30} {'Mean (ms)':<12} {'Std (ms)':<12}\")\n",
        "    print(\"-\" * 94)\n",
        "\n",
        "    for conn_idx in sorted(connection_timestamps.keys()):\n",
        "        timestamps = connection_timestamps[conn_idx]\n",
        "        if len(timestamps) > 1:\n",
        "            intervals = np.diff(timestamps) * 1000\n",
        "\n",
        "            # Get topic info from df_topics\n",
        "            topic_row = df_topics[df_topics['Connection_Index'] == conn_idx].iloc[0]\n",
        "            topic_name = topic_row['Topic']\n",
        "            description = topic_row['Description'][:28] if topic_row['Description'] else ''\n",
        "\n",
        "            print(f\"{topic_name:<40} {description:<30} {np.mean(intervals):<12.2f} {np.std(intervals):<12.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00sOQJiZ93mA"
      },
      "source": [
        "### 4. Message Size Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iK-5nzV393mA"
      },
      "outputs": [],
      "source": [
        "# Analyze message sizes per connection\n",
        "print(\"=\" * 60)\n",
        "print(\"MESSAGE SIZE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "with Reader(bag_path) as reader:\n",
        "    connection_sizes = defaultdict(list)\n",
        "\n",
        "    print(\"\\\\nCollecting message sizes...\")\n",
        "    for connection, timestamp, rawdata in tqdm(reader.messages(), total=reader.message_count):\n",
        "        # Find connection index\n",
        "        conn_idx = None\n",
        "        for idx, conn in enumerate(reader.connections):\n",
        "            if (conn.topic == connection.topic and\n",
        "                conn.msgtype == connection.msgtype and\n",
        "                conn.msgcount == connection.msgcount):\n",
        "                conn_idx = idx\n",
        "                break\n",
        "\n",
        "        if conn_idx is not None:\n",
        "            connection_sizes[conn_idx].append(len(rawdata))\n",
        "\n",
        "    # Calculate statistics\n",
        "    size_stats = []\n",
        "    for conn_idx, sizes in connection_sizes.items():\n",
        "        sizes_array = np.array(sizes)\n",
        "        topic_row = df_topics[df_topics['Connection_Index'] == conn_idx].iloc[0]\n",
        "\n",
        "        size_stats.append({\n",
        "            'Topic': topic_row['Topic'],\n",
        "            'Description': topic_row['Description'][:40] if topic_row['Description'] else '',\n",
        "            'Avg Size (bytes)': np.mean(sizes_array),\n",
        "            'Total Size (MB)': np.sum(sizes_array) / (1024 * 1024)\n",
        "        })\n",
        "\n",
        "    df_sizes = pd.DataFrame(size_stats)\n",
        "    df_sizes = df_sizes.sort_values('Total Size (MB)', ascending=False)\n",
        "\n",
        "    print(\"\\\\nüìè Message Size Statistics:\")\n",
        "    print(df_sizes.to_string(index=False))\n",
        "\n",
        "    df_sizes.to_csv('message_size_statistics.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkDwnVqnIk9m"
      },
      "source": [
        "### 5. ROS Bag Basic EDA Summary Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1xLnpEYIk9m"
      },
      "outputs": [],
      "source": [
        "# Generate ROS Bag Basic EDA summary report\n",
        "print(\"=\" * 60)\n",
        "print(\"ROS BAG BASIC EDA - SUMMARY REPORT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "rosbag_summary = f\"\"\"\n",
        "üìä ROS BAG BASIC EDA SUMMARY\n",
        "{'='*60}\n",
        "\n",
        "FILE INFORMATION:\n",
        "  ‚Ä¢ File: {bag_name}\n",
        "  ‚Ä¢ Size: {file_size_mb:.2f} MB\n",
        "  ‚Ä¢ Duration: {duration_sec:.2f} seconds ({duration_sec/60:.2f} minutes)\n",
        "\n",
        "MESSAGE STATISTICS:\n",
        "  ‚Ä¢ Total Messages: {total_messages:,}\n",
        "  ‚Ä¢ Unique Topics: {len(unique_topics)}\n",
        "  ‚Ä¢ Message Types: {df_topics['Message Type'].nunique()}\n",
        "  ‚Ä¢ Average Rate: {avg_message_rate:.2f} msg/sec\n",
        "\n",
        "DATA QUALITY:\n",
        "  ‚Ä¢ Average Data Rate: {file_size_mb / (duration_sec/60):.2f} MB/min\n",
        "\n",
        "TOP 3 TOPICS BY SIZE:\n",
        "\"\"\"\n",
        "\n",
        "for idx, row in df_sizes.head(3).iterrows():\n",
        "    rosbag_summary += f\"  {idx+1}. {row['Topic']}: {row['Total Size (MB)']:.2f} MB\\n\"\n",
        "\n",
        "print(rosbag_summary)\n",
        "\n",
        "# Save report\n",
        "with open('rosbag_basic_eda_summary.txt', 'w') as f:\n",
        "    f.write(rosbag_summary)\n",
        "\n",
        "print(\"\\n‚úÖ ROS Bag Basic EDA summary saved to: rosbag_basic_eda_summary.txt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3nVzETSIk9m"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 5. Camera Topic Basic EDA</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5ci5loZIk9m"
      },
      "source": [
        "### Hardware Documentation: JetBot Camera System\n",
        "\n",
        "---\n",
        "\n",
        "## üì∑ Hardware Specifications\n",
        "\n",
        "**Camera Sensor: Sony IMX219**\n",
        "\n",
        "- **Native Resolution:** 8MP (3280 √ó 2464 pixels)\n",
        "- **Typical Operating Modes:**\n",
        "  - 640 √ó 480 pixels (VGA, 4:3)\n",
        "  - 1280 √ó 720 pixels (HD, 16:9)\n",
        "- **Field of View:** 160¬∞ (wide angle)\n",
        "- **Interface:** CSI (Camera Serial Interface)\n",
        "- **Frame Rate:** Up to 30 FPS (depends on resolution and configuration)\n",
        "\n",
        "---\n",
        "\n",
        "## üì° ROS Topics Published\n",
        "\n",
        "The JetBot camera system typically publishes three topics:\n",
        "\n",
        "### 1. `/csi_cam_0/image_raw` (Uncompressed Images)\n",
        "\n",
        "**Message Type:** `sensor_msgs/Image`\n",
        "\n",
        "**Content:** Raw uncompressed pixel data\n",
        "\n",
        "**Message Fields:**\n",
        "- `header` - Timestamp and frame ID\n",
        "- `height` - Image height (480 or 720)\n",
        "- `width` - Image width (640 or 1280)\n",
        "- `encoding` - Pixel format (`\"bgr8\"` or `\"rgb8\"`)\n",
        "- `step` - Row stride in bytes\n",
        "- `data` - Raw pixel array\n",
        "\n",
        "**Data Size:**\n",
        "- 640√ó480: ~921 KB per frame\n",
        "- 1280√ó720: ~2.76 MB per frame\n",
        "\n",
        "**Note:** Often disabled by default to save bandwidth\n",
        "\n",
        "---\n",
        "\n",
        "### 2. `/csi_cam_0/image_raw/compressed` (Compressed Images)\n",
        "\n",
        "**Message Type:** `sensor_msgs/CompressedImage`\n",
        "\n",
        "**Content:** JPEG-compressed images\n",
        "\n",
        "**Message Fields:**\n",
        "- `header` - Timestamp and frame ID\n",
        "- `format` - Compression type (`\"jpeg\"`)\n",
        "- `data` - Compressed image bytes\n",
        "\n",
        "**Data Size:**\n",
        "- Simple scenes: 20-40 KB per frame\n",
        "- Complex scenes: 40-80 KB per frame\n",
        "- **Compression ratio:** 10-40√ó smaller than raw\n",
        "\n",
        "**Default Topic:** This is the primary topic used in most JetBot applications\n",
        "\n",
        "---\n",
        "\n",
        "### 3. `/csi_cam_0/camera_info` (Camera Calibration)\n",
        "\n",
        "**Message Type:** `sensor_msgs/CameraInfo`\n",
        "\n",
        "**Content:** Camera calibration parameters and metadata\n",
        "\n",
        "**Message Fields:**\n",
        "\n",
        "**Image Dimensions:**\n",
        "- `width` - Image width in pixels\n",
        "- `height` - Image height in pixels\n",
        "\n",
        "**Intrinsic Calibration:**\n",
        "- `K` - 3√ó3 camera matrix\n",
        "  - `K[0,0]` = fx (focal length X)\n",
        "  - `K[1,1]` = fy (focal length Y)\n",
        "  - `K[0,2]` = cx (principal point X, ~width/2)\n",
        "  - `K[1,2]` = cy (principal point Y, ~height/2)\n",
        "\n",
        "**Distortion:**\n",
        "- `distortion_model` - Usually `\"plumb_bob\"`\n",
        "- `D` - Distortion coefficients [k1, k2, p1, p2, k3]\n",
        "  - k1, k2, k3: Radial distortion\n",
        "  - p1, p2: Tangential distortion\n",
        "\n",
        "**Projection:**\n",
        "- `R` - 3√ó3 rectification matrix (identity for monocular)\n",
        "- `P` - 3√ó4 projection matrix for 3D‚Üí2D mapping\n",
        "\n",
        "**Region of Interest:**\n",
        "- `roi` - Subset of image for processing (all zeros = full image)\n",
        "\n",
        "**Binning:**\n",
        "- `binning_x`, `binning_y` - Pixel binning (usually 0)\n",
        "\n",
        "**Expected Values (640√ó480 mode):**\n",
        "```\n",
        "width: 640, height: 480\n",
        "fx, fy: 600-900 pixels\n",
        "cx: ~320, cy: ~240\n",
        "distortion_model: \"plumb_bob\"\n",
        "```\n",
        "\n",
        "**Calibration Status:**\n",
        "- **Calibrated:** K matrix has non-zero values\n",
        "- **Uncalibrated:** K, D, R, P may be zeros\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioGG2hNeIk9m"
      },
      "source": [
        "### Camera Info Topic Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QN8PkGmbIk9m"
      },
      "outputs": [],
      "source": [
        "# Inspect camera_info topic - Optimized with Binary Parsing Fallback\n",
        "print(\"=\" * 60)\n",
        "print(\"CAMERA INFO TOPIC INSPECTION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "camera_info_topic = '/csi_cam_0/camera_info'\n",
        "\n",
        "def display_camera_info(cam_data, parsing_method=\"Standard\"):\n",
        "    \"\"\"Display camera info in a consistent format\"\"\"\n",
        "    print(f\"\\nüì∑ CAMERA CALIBRATION INFO ({parsing_method} Parsing):\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"\\nImage Dimensions:\")\n",
        "    print(f\"  ‚Ä¢ Width: {cam_data['width']} pixels\")\n",
        "    print(f\"  ‚Ä¢ Height: {cam_data['height']} pixels\")\n",
        "    print(f\"  ‚Ä¢ Aspect Ratio: {cam_data['width']/cam_data['height']:.2f}\")\n",
        "\n",
        "    print(f\"\\nDistortion Model: {cam_data['distortion_model']}\")\n",
        "\n",
        "    print(f\"\\nCamera Matrix (K):\")\n",
        "    print(cam_data['K'])\n",
        "    print(f\"  ‚Ä¢ Focal Length X (fx): {cam_data['K'][0,0]:.2f}\")\n",
        "    print(f\"  ‚Ä¢ Focal Length Y (fy): {cam_data['K'][1,1]:.2f}\")\n",
        "    print(f\"  ‚Ä¢ Principal Point X (cx): {cam_data['K'][0,2]:.2f}\")\n",
        "    print(f\"  ‚Ä¢ Principal Point Y (cy): {cam_data['K'][1,2]:.2f}\")\n",
        "\n",
        "    print(f\"\\nDistortion Coefficients (D):\")\n",
        "    if len(cam_data['D']) > 0:\n",
        "        print(f\"  {list(cam_data['D'])}\")\n",
        "    else:\n",
        "        print(f\"  None\")\n",
        "\n",
        "    print(f\"\\nRectification Matrix (R):\")\n",
        "    print(cam_data['R'])\n",
        "\n",
        "    print(f\"\\nProjection Matrix (P):\")\n",
        "    print(cam_data['P'])\n",
        "\n",
        "    print(f\"\\nRegion of Interest (ROI):\")\n",
        "    print(f\"  ‚Ä¢ X offset: {cam_data['roi']['x']}\")\n",
        "    print(f\"  ‚Ä¢ Y offset: {cam_data['roi']['y']}\")\n",
        "    print(f\"  ‚Ä¢ Width: {cam_data['roi']['width']}\")\n",
        "    print(f\"  ‚Ä¢ Height: {cam_data['roi']['height']}\")\n",
        "    print(f\"  ‚Ä¢ Do rectify: {cam_data['roi']['do_rectify']}\")\n",
        "\n",
        "def parse_camerainfo_binary(rawdata):\n",
        "    \"\"\"Parse CameraInfo from raw bytes when standard deserialization fails\"\"\"\n",
        "    import struct\n",
        "\n",
        "    offset = 4  # Skip CDR header\n",
        "\n",
        "    # Parse header fields (seq, timestamp, frame_id) - skip for now\n",
        "    offset += 12  # seq(4) + secs(4) + nsecs(4)\n",
        "    str_len = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "    offset += 4 + str_len  # frame_id\n",
        "\n",
        "    # Image dimensions\n",
        "    height = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "    width = struct.unpack('<I', rawdata[offset+4:offset+8])[0]\n",
        "    offset += 8\n",
        "\n",
        "    # Distortion model\n",
        "    str_len = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "    distortion_model = rawdata[offset+4:offset+4+str_len].decode('utf-8', errors='ignore').rstrip('\\x00')\n",
        "    offset += 4 + str_len\n",
        "\n",
        "    # D array\n",
        "    d_count = struct.unpack('<I', rawdata[offset:offset+4])[0]\n",
        "    offset += 4\n",
        "    d_values = struct.unpack(f'<{d_count}d', rawdata[offset:offset+d_count*8])\n",
        "    offset += d_count * 8\n",
        "\n",
        "    # K, R, P matrices\n",
        "    k_matrix = np.array(struct.unpack('<9d', rawdata[offset:offset+72])).reshape(3, 3)\n",
        "    offset += 72\n",
        "    r_matrix = np.array(struct.unpack('<9d', rawdata[offset:offset+72])).reshape(3, 3)\n",
        "    offset += 72\n",
        "    p_matrix = np.array(struct.unpack('<12d', rawdata[offset:offset+96])).reshape(3, 4)\n",
        "    offset += 96\n",
        "\n",
        "    # Binning and ROI\n",
        "    binning_x, binning_y = struct.unpack('<II', rawdata[offset:offset+8])\n",
        "    offset += 8\n",
        "    roi_x, roi_y, roi_h, roi_w = struct.unpack('<IIII', rawdata[offset:offset+16])\n",
        "    offset += 16\n",
        "    roi_do_rectify = struct.unpack('<?', rawdata[offset:offset+1])[0]\n",
        "\n",
        "    return {\n",
        "        'width': width, 'height': height,\n",
        "        'distortion_model': distortion_model,\n",
        "        'D': d_values, 'K': k_matrix, 'R': r_matrix, 'P': p_matrix,\n",
        "        'roi': {'x': roi_x, 'y': roi_y, 'width': roi_w, 'height': roi_h, 'do_rectify': roi_do_rectify}\n",
        "    }\n",
        "\n",
        "# Main parsing logic\n",
        "with Reader(bag_path) as reader:\n",
        "    topics = [conn.topic for conn in reader.connections]\n",
        "\n",
        "    if camera_info_topic in topics:\n",
        "        print(f\"\\n‚úì Found topic: {camera_info_topic}\\n\")\n",
        "\n",
        "        for connection, timestamp, rawdata in reader.messages():\n",
        "            if connection.topic == camera_info_topic:\n",
        "                try:\n",
        "                    # Try standard deserialization first\n",
        "                    msg = typestore.deserialize_ros1(rawdata, connection.msgtype)\n",
        "\n",
        "                    cam_data = {\n",
        "                        'width': msg.width, 'height': msg.height,\n",
        "                        'distortion_model': msg.distortion_model,\n",
        "                        'D': msg.D,\n",
        "                        'K': np.array(msg.K).reshape(3, 3),\n",
        "                        'R': np.array(msg.R).reshape(3, 3),\n",
        "                        'P': np.array(msg.P).reshape(3, 4),\n",
        "                        'roi': {'x': msg.roi.x_offset, 'y': msg.roi.y_offset,\n",
        "                               'width': msg.roi.width, 'height': msg.roi.height,\n",
        "                               'do_rectify': msg.roi.do_rectify}\n",
        "                    }\n",
        "                    display_camera_info(cam_data, \"Standard\")\n",
        "                    break\n",
        "\n",
        "                except (UnicodeDecodeError, Exception) as e:\n",
        "                    # Fallback to binary parsing\n",
        "                    try:\n",
        "                        print(\"‚ö†Ô∏è  Standard deserialization failed, using binary parsing...\\n\")\n",
        "                        cam_data = parse_camerainfo_binary(rawdata)\n",
        "                        display_camera_info(cam_data, \"Binary\")\n",
        "                        print(f\"\\n‚úÖ Successfully parsed camera info!\")\n",
        "                        break\n",
        "                    except Exception as e2:\n",
        "                        print(f\"‚ùå Both parsing methods failed: {type(e2).__name__}\")\n",
        "                        print(f\"\\nBasic topic info:\")\n",
        "                        print(f\"  ‚Ä¢ Topic: {camera_info_topic}\")\n",
        "                        print(f\"  ‚Ä¢ Message type: {connection.msgtype}\")\n",
        "                        print(f\"  ‚Ä¢ Message count: {connection.msgcount}\")\n",
        "                        print(f\"\\nüí° Camera dimensions will be extracted from images in the next section.\")\n",
        "                        break\n",
        "    else:\n",
        "        print(f\"\\n‚ö†Ô∏è  Topic {camera_info_topic} not found in bag file\")\n",
        "        print(f\"\\nAvailable topics:\")\n",
        "        for topic in sorted(topics):\n",
        "            print(f\"  ‚Ä¢ {topic}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPtCVOkrIk9m"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 5. Camera Topic Basic EDA</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ekGz4v6Ik9m"
      },
      "source": [
        "### 1. Camera Topic Timing Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PaxUYWOjIk9m"
      },
      "outputs": [],
      "source": [
        "# Detailed analysis of camera topic timing\n",
        "camera_topic = '/csi_cam_0/image_raw/compressed'\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"CAMERA TOPIC TIMING ANALYSIS: {camera_topic}\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if camera_topic in topic_timestamps:\n",
        "    timestamps = np.array(topic_timestamps[camera_topic])\n",
        "    time_diffs = np.diff(timestamps)\n",
        "    framerates = 1.0 / time_diffs\n",
        "\n",
        "    print(f\"\\nüì∏ Frame Statistics:\")\n",
        "    print(f\"   Total frames: {len(timestamps)}\")\n",
        "    print(f\"   Duration: {timestamps[-1] - timestamps[0]:.2f} seconds\")\n",
        "    print(f\"   Average FPS: {np.mean(framerates):.2f}\")\n",
        "    print(f\"   FPS std dev: {np.std(framerates):.2f}\")\n",
        "    print(f\"   Min FPS: {np.min(framerates):.2f}\")\n",
        "    print(f\"   Max FPS: {np.max(framerates):.2f}\")\n",
        "\n",
        "    # Detect large gaps\n",
        "    gap_threshold = np.mean(time_diffs) + 2 * np.std(time_diffs)\n",
        "    large_gaps = np.where(time_diffs > gap_threshold)[0]\n",
        "\n",
        "    print(f\"\\n‚ö†Ô∏è  Gap Analysis:\")\n",
        "    print(f\"   Gap threshold: {gap_threshold:.4f} seconds\")\n",
        "    print(f\"   Number of large gaps: {len(large_gaps)}\")\n",
        "    if len(large_gaps) > 0:\n",
        "        print(f\"   Largest gap: {np.max(time_diffs):.4f} seconds at index {np.argmax(time_diffs)}\")\n",
        "\n",
        "    # Plot timing analysis\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 8))\n",
        "\n",
        "    # Plot 1: Frame rate over time\n",
        "    ax1.plot(timestamps[1:], framerates, linewidth=1, color='blue', alpha=0.7)\n",
        "    ax1.axhline(y=np.mean(framerates), color='green', linestyle='--', alpha=0.5, label=f'Mean FPS: {np.mean(framerates):.2f}')\n",
        "    ax1.set_xlabel('Time (seconds)')\n",
        "    ax1.set_ylabel('Frame Rate (FPS)')\n",
        "    ax1.set_title('Camera Frame Rate Over Time')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Inter-frame intervals with gap detection\n",
        "    ax2.plot(timestamps[1:], time_diffs * 1000, linewidth=1, color='orange', alpha=0.7)\n",
        "    ax2.axhline(y=gap_threshold * 1000, color='red', linestyle='--', alpha=0.5, label=f'Gap threshold: {gap_threshold*1000:.2f}ms')\n",
        "    ax2.axhline(y=np.mean(time_diffs) * 1000, color='green', linestyle='--', alpha=0.5, label=f'Mean interval: {np.mean(time_diffs)*1000:.2f}ms')\n",
        "\n",
        "    # Mark large gaps\n",
        "    if len(large_gaps) > 0:\n",
        "        ax2.scatter(timestamps[large_gaps+1], time_diffs[large_gaps] * 1000, color='red', s=50, zorder=5, label='Large gaps')\n",
        "\n",
        "    ax2.set_xlabel('Time (seconds)')\n",
        "    ax2.set_ylabel('Inter-frame Interval (ms)')\n",
        "    ax2.set_title('Inter-frame Timing Intervals')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('camera_timing_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Camera timing plot saved to: camera_timing_analysis.png\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Camera topic {camera_topic} not found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DACA9S9vIk9n"
      },
      "source": [
        "### 2. Camera Topic Basic EDA Summary Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vM8mFvqIk9n"
      },
      "outputs": [],
      "source": [
        "# Generate Camera Topic Basic EDA summary report\n",
        "print(\"=\" * 60)\n",
        "print(\"CAMERA TOPIC BASIC EDA - SUMMARY REPORT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if camera_topic in topic_timestamps:\n",
        "    camera_summary = f\"\"\"\n",
        "üì∏ CAMERA TOPIC BASIC EDA SUMMARY\n",
        "{'='*60}\n",
        "\n",
        "TOPIC INFORMATION:\n",
        "  ‚Ä¢ Topic: {camera_topic}\n",
        "  ‚Ä¢ Total Messages: {len(timestamps)}\n",
        "  ‚Ä¢ Duration: {timestamps[-1] - timestamps[0]:.2f} seconds\n",
        "\n",
        "TIMING ANALYSIS:\n",
        "  ‚Ä¢ Average FPS: {np.mean(framerates):.2f}\n",
        "  ‚Ä¢ FPS Std Dev: {np.std(framerates):.2f}\n",
        "  ‚Ä¢ Min FPS: {np.min(framerates):.2f}\n",
        "  ‚Ä¢ Max FPS: {np.max(framerates):.2f}\n",
        "\n",
        "GAP ANALYSIS:\n",
        "  ‚Ä¢ Gap Threshold: {gap_threshold:.4f} seconds\n",
        "  ‚Ä¢ Large Gaps Detected: {len(large_gaps)}\n",
        "  ‚Ä¢ Largest Gap: {np.max(time_diffs):.4f} seconds\n",
        "\n",
        "OUTPUT FILES:\n",
        "  ‚Ä¢ camera_timing_analysis.png\n",
        "\"\"\"\n",
        "\n",
        "    print(camera_summary)\n",
        "\n",
        "    # Save report\n",
        "    with open('camera_topic_basic_eda_summary.txt', 'w') as f:\n",
        "        f.write(camera_summary)\n",
        "\n",
        "    print(\"\\n‚úÖ Camera Topic Basic EDA summary saved to: camera_topic_basic_eda_summary.txt\")\n",
        "else:\n",
        "    print(f\"\\n‚ö†Ô∏è  Camera topic {camera_topic} not found in bag file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncRzAOt9Ik9n"
      },
      "source": [
        "## <font color='#2E86AB'>‚ñº 6. Camera Image EDA</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkzK-oxdIk9n"
      },
      "source": [
        "### 1. Extract and Display Sample Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_WAURCJIk9n"
      },
      "outputs": [],
      "source": [
        "# Extract images from camera topic\n",
        "print(\"=\" * 60)\n",
        "print(\"EXTRACTING CAMERA IMAGES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "camera_topic = '/csi_cam_0/image_raw/compressed'\n",
        "images = []\n",
        "image_timestamps = []\n",
        "\n",
        "with Reader(bag_path) as reader:\n",
        "    print(f\"\\nExtracting images from: {camera_topic}\")\n",
        "\n",
        "    for connection, timestamp, rawdata in tqdm(reader.messages()):\n",
        "        if connection.topic == camera_topic:\n",
        "            try:\n",
        "                # Try to deserialize the message\n",
        "                msg = typestore.deserialize_ros1(rawdata, connection.msgtype)\n",
        "\n",
        "                # Decode compressed image\n",
        "                np_arr = np.frombuffer(msg.Data, np.uint8)\n",
        "                img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "                if img is not None:\n",
        "                    images.append(img)\n",
        "                    image_timestamps.append(timestamp * 1e-9)\n",
        "            except (UnicodeDecodeError, Exception):\n",
        "                # If deserialization fails, try extracting raw image data\n",
        "                try:\n",
        "                    # Look for JPEG start marker\n",
        "                    data = bytes(rawdata)\n",
        "                    jpeg_start = data.find(b'\\xff\\xd8\\xff')\n",
        "\n",
        "                    if jpeg_start != -1:\n",
        "                        image_data = data[jpeg_start:]\n",
        "                        np_arr = np.frombuffer(image_data, np.uint8)\n",
        "                        img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)\n",
        "\n",
        "                        if img is not None:\n",
        "                            images.append(img)\n",
        "                            image_timestamps.append(timestamp * 1e-9)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "print(f\"\\n‚úÖ Extracted {len(images)} images\")\n",
        "\n",
        "# Display sample images\n",
        "if len(images) > 0:\n",
        "    num_samples = min(6, len(images))\n",
        "    sample_indices = np.linspace(0, len(images)-1, num_samples, dtype=int)\n",
        "\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "    axes = axes.ravel()\n",
        "\n",
        "    for i, idx in enumerate(sample_indices):\n",
        "        img_rgb = cv2.cvtColor(images[idx], cv2.COLOR_BGR2RGB)\n",
        "        axes[i].imshow(img_rgb)\n",
        "        axes[i].set_title(f\"Frame {idx} (t={image_timestamps[idx]:.2f}s)\")\n",
        "        axes[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('sample_images.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Sample images saved to: sample_images.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOjOxo2_Ik9n"
      },
      "source": [
        "### 2. Image Properties Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSUWOzPLIk9n"
      },
      "outputs": [],
      "source": [
        "# Analyze image properties\n",
        "print(\"=\" * 60)\n",
        "print(\"IMAGE PROPERTIES ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(images) > 0:\n",
        "    # Get dimensions\n",
        "    heights = [img.shape[0] for img in images]\n",
        "    widths = [img.shape[1] for img in images]\n",
        "    channels = [img.shape[2] for img in images]\n",
        "\n",
        "    print(f\"\\nüìê Image Dimensions:\")\n",
        "    print(f\"   Width: {widths[0]} pixels (consistent: {len(set(widths)) == 1})\")\n",
        "    print(f\"   Height: {heights[0]} pixels (consistent: {len(set(heights)) == 1})\")\n",
        "    print(f\"   Channels: {channels[0]} (consistent: {len(set(channels)) == 1})\")\n",
        "    print(f\"   Aspect Ratio: {widths[0]/heights[0]:.2f}\")\n",
        "\n",
        "    # Calculate average file sizes from already extracted images\n",
        "    compressed_sizes = []\n",
        "    with Reader(bag_path) as reader:\n",
        "        for connection, timestamp, rawdata in reader.messages():\n",
        "            if connection.topic == camera_topic:\n",
        "                try:\n",
        "                    msg = typestore.deserialize_ros1(rawdata, connection.msgtype)\n",
        "                    compressed_sizes.append(len(msg.Data))\n",
        "                except:\n",
        "                    # If deserialization fails, estimate from rawdata size\n",
        "                    # Compressed image data is typically most of the message\n",
        "                    compressed_sizes.append(len(rawdata) - 100)  # Rough estimate minus header\n",
        "\n",
        "    if len(compressed_sizes) > 0:\n",
        "        print(f\"\\nüíæ Compression Analysis:\")\n",
        "        print(f\"   Average compressed size: {np.mean(compressed_sizes)/1024:.2f} KB\")\n",
        "        print(f\"   Min compressed size: {np.min(compressed_sizes)/1024:.2f} KB\")\n",
        "        print(f\"   Max compressed size: {np.max(compressed_sizes)/1024:.2f} KB\")\n",
        "        print(f\"   Std dev: {np.std(compressed_sizes)/1024:.2f} KB\")\n",
        "\n",
        "        # Uncompressed size\n",
        "        uncompressed_size = widths[0] * heights[0] * channels[0]\n",
        "        compression_ratio = uncompressed_size / np.mean(compressed_sizes)\n",
        "        print(f\"   Uncompressed size: {uncompressed_size/1024:.2f} KB\")\n",
        "        print(f\"   Compression ratio: {compression_ratio:.2f}x\")\n",
        "    else:\n",
        "        print(f\"\\nüíæ Compression Analysis: Could not extract size data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4W3DUFcVIk9n"
      },
      "source": [
        "### 3. Brightness and Exposure Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VPl593vIk9n"
      },
      "outputs": [],
      "source": [
        "# Analyze brightness and exposure\n",
        "print(\"=\" * 60)\n",
        "print(\"BRIGHTNESS AND EXPOSURE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(images) > 0:\n",
        "    brightness_values = []\n",
        "\n",
        "    for img in images:\n",
        "        # Convert to grayscale and calculate mean brightness\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        brightness = np.mean(gray)\n",
        "        brightness_values.append(brightness)\n",
        "\n",
        "    brightness_values = np.array(brightness_values)\n",
        "\n",
        "    print(f\"\\nüí° Brightness Statistics (0-255 scale):\")\n",
        "    print(f\"   Mean brightness: {np.mean(brightness_values):.2f}\")\n",
        "    print(f\"   Std dev: {np.std(brightness_values):.2f}\")\n",
        "    print(f\"   Min brightness: {np.min(brightness_values):.2f}\")\n",
        "    print(f\"   Max brightness: {np.max(brightness_values):.2f}\")\n",
        "\n",
        "    # Detect over/underexposed frames\n",
        "    overexposed = np.sum(brightness_values > 200)\n",
        "    underexposed = np.sum(brightness_values < 50)\n",
        "\n",
        "    print(f\"\\n‚ö†Ô∏è  Exposure Issues:\")\n",
        "    print(f\"   Potentially overexposed frames (>200): {overexposed} ({100*overexposed/len(images):.1f}%)\")\n",
        "    print(f\"   Potentially underexposed frames (<50): {underexposed} ({100*underexposed/len(images):.1f}%)\")\n",
        "\n",
        "    # Plot brightness over time\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(image_timestamps, brightness_values, linewidth=1)\n",
        "    plt.axhline(y=200, color='r', linestyle='--', alpha=0.5, label='Overexposed threshold')\n",
        "    plt.axhline(y=50, color='b', linestyle='--', alpha=0.5, label='Underexposed threshold')\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Mean Brightness (0-255)')\n",
        "    plt.title('Brightness Over Time')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig('brightness_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Brightness plot saved to: brightness_analysis.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCgXV-v3Ik9o"
      },
      "source": [
        "### 4. Color Distribution Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uMLl4zcIk9o"
      },
      "outputs": [],
      "source": [
        "# Analyze color distribution\n",
        "print(\"=\" * 60)\n",
        "print(\"COLOR DISTRIBUTION ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(images) > 0:\n",
        "    # Sample a subset of images for detailed analysis\n",
        "    sample_size = min(20, len(images))\n",
        "    sample_indices = np.linspace(0, len(images)-1, sample_size, dtype=int)\n",
        "\n",
        "    # Calculate average color channels\n",
        "    avg_blue = []\n",
        "    avg_green = []\n",
        "    avg_red = []\n",
        "\n",
        "    for idx in sample_indices:\n",
        "        img = images[idx]\n",
        "        avg_blue.append(np.mean(img[:,:,0]))\n",
        "        avg_green.append(np.mean(img[:,:,1]))\n",
        "        avg_red.append(np.mean(img[:,:,2]))\n",
        "\n",
        "    print(f\"\\nüé® Average Color Channel Values (0-255):\")\n",
        "    print(f\"   Blue:  {np.mean(avg_blue):.2f} ¬± {np.std(avg_blue):.2f}\")\n",
        "    print(f\"   Green: {np.mean(avg_green):.2f} ¬± {np.std(avg_green):.2f}\")\n",
        "    print(f\"   Red:   {np.mean(avg_red):.2f} ¬± {np.std(avg_red):.2f}\")\n",
        "\n",
        "    # Plot color histograms for a sample image\n",
        "    mid_idx = len(images) // 2\n",
        "    sample_img = images[mid_idx]\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    # Display sample image\n",
        "    ax1.imshow(cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB))\n",
        "    ax1.set_title(f'Sample Image (Frame {mid_idx})')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    # Plot histograms\n",
        "    colors = ('b', 'g', 'r')\n",
        "    for i, color in enumerate(colors):\n",
        "        hist = cv2.calcHist([sample_img], [i], None, [256], [0, 256])\n",
        "        ax2.plot(hist, color=color, label=f'{color.upper()} channel')\n",
        "\n",
        "    ax2.set_xlabel('Pixel Value')\n",
        "    ax2.set_ylabel('Frequency')\n",
        "    ax2.set_title('Color Distribution')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('color_distribution.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Color distribution plot saved to: color_distribution.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkkfjXS_Ik9o"
      },
      "source": [
        "### 5. Motion and Frame Difference Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9q8QruWRIk9o"
      },
      "outputs": [],
      "source": [
        "# Analyze motion between frames\n",
        "print(\"=\" * 60)\n",
        "print(\"MOTION AND FRAME DIFFERENCE ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(images) > 1:\n",
        "    frame_differences = []\n",
        "\n",
        "    print(\"\\nCalculating frame differences...\")\n",
        "    for i in tqdm(range(len(images)-1)):\n",
        "        # Convert to grayscale\n",
        "        gray1 = cv2.cvtColor(images[i], cv2.COLOR_BGR2GRAY)\n",
        "        gray2 = cv2.cvtColor(images[i+1], cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Calculate absolute difference\n",
        "        diff = cv2.absdiff(gray1, gray2)\n",
        "        mean_diff = np.mean(diff)\n",
        "        frame_differences.append(mean_diff)\n",
        "\n",
        "    frame_differences = np.array(frame_differences)\n",
        "\n",
        "    print(f\"\\nüé¨ Motion Statistics:\")\n",
        "    print(f\"   Mean frame difference: {np.mean(frame_differences):.2f}\")\n",
        "    print(f\"   Std dev: {np.std(frame_differences):.2f}\")\n",
        "    print(f\"   Min difference: {np.min(frame_differences):.2f}\")\n",
        "    print(f\"   Max difference: {np.max(frame_differences):.2f}\")\n",
        "\n",
        "    # Detect high motion frames\n",
        "    motion_threshold = np.mean(frame_differences) + 2 * np.std(frame_differences)\n",
        "    high_motion_frames = np.where(frame_differences > motion_threshold)[0]\n",
        "\n",
        "    print(f\"\\nüèÉ High Motion Detection:\")\n",
        "    print(f\"   Motion threshold: {motion_threshold:.2f}\")\n",
        "    print(f\"   High motion frames: {len(high_motion_frames)} ({100*len(high_motion_frames)/(len(images)-1):.1f}%)\")\n",
        "\n",
        "    # Plot frame differences over time\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.plot(image_timestamps[1:], frame_differences, linewidth=1)\n",
        "    plt.axhline(y=motion_threshold, color='r', linestyle='--', alpha=0.5, label='High motion threshold')\n",
        "    plt.xlabel('Time (seconds)')\n",
        "    plt.ylabel('Mean Frame Difference')\n",
        "    plt.title('Motion Intensity Over Time')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig('motion_analysis.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Motion analysis plot saved to: motion_analysis.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOX1NnM7Ik9o"
      },
      "source": [
        "### 6. Image Quality Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZoBc_SaIk9o"
      },
      "outputs": [],
      "source": [
        "# Calculate image quality metrics\n",
        "print(\"=\" * 60)\n",
        "print(\"IMAGE QUALITY METRICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(images) > 0:\n",
        "    # Sample images for quality analysis\n",
        "    sample_size = min(20, len(images))\n",
        "    sample_indices = np.linspace(0, len(images)-1, sample_size, dtype=int)\n",
        "\n",
        "    sharpness_scores = []\n",
        "    contrast_scores = []\n",
        "\n",
        "    print(\"\\nCalculating quality metrics...\")\n",
        "    for idx in tqdm(sample_indices):\n",
        "        img = images[idx]\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Sharpness (using Laplacian variance)\n",
        "        laplacian = cv2.Laplacian(gray, cv2.CV_64F)\n",
        "        sharpness = laplacian.var()\n",
        "        sharpness_scores.append(sharpness)\n",
        "\n",
        "        # Contrast (RMS contrast)\n",
        "        contrast = gray.std()\n",
        "        contrast_scores.append(contrast)\n",
        "\n",
        "    print(f\"\\nüìä Quality Metrics:\")\n",
        "    print(f\"   Sharpness (Laplacian variance):\")\n",
        "    print(f\"      Mean: {np.mean(sharpness_scores):.2f}\")\n",
        "    print(f\"      Std dev: {np.std(sharpness_scores):.2f}\")\n",
        "    print(f\"      Range: [{np.min(sharpness_scores):.2f}, {np.max(sharpness_scores):.2f}]\")\n",
        "\n",
        "    print(f\"\\n   Contrast (RMS):\")\n",
        "    print(f\"      Mean: {np.mean(contrast_scores):.2f}\")\n",
        "    print(f\"      Std dev: {np.std(contrast_scores):.2f}\")\n",
        "    print(f\"      Range: [{np.min(contrast_scores):.2f}, {np.max(contrast_scores):.2f}]\")\n",
        "\n",
        "    # Plot quality metrics\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
        "\n",
        "    ax1.plot(sample_indices, sharpness_scores, 'o-')\n",
        "    ax1.set_xlabel('Frame Index')\n",
        "    ax1.set_ylabel('Sharpness Score')\n",
        "    ax1.set_title('Image Sharpness Over Frames')\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    ax2.plot(sample_indices, contrast_scores, 'o-', color='orange')\n",
        "    ax2.set_xlabel('Frame Index')\n",
        "    ax2.set_ylabel('Contrast Score')\n",
        "    ax2.set_title('Image Contrast Over Frames')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('quality_metrics.png', dpi=150, bbox_inches='tight')\n",
        "    plt.show()\n",
        "    print(\"\\n‚úÖ Quality metrics plot saved to: quality_metrics.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSdSmag7Ik9o"
      },
      "source": [
        "### 7. Camera Image EDA Summary Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzMdlo6IIk9o"
      },
      "outputs": [],
      "source": [
        "# Generate comprehensive image EDA summary\n",
        "print(\"=\" * 60)\n",
        "print(\"CAMERA IMAGE EDA - SUMMARY REPORT\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if len(images) > 0:\n",
        "    image_summary = f\"\"\"\n",
        "üì∏ CAMERA IMAGE EDA SUMMARY\n",
        "{'='*60}\n",
        "\n",
        "BASIC INFORMATION:\n",
        "  ‚Ä¢ Topic: {camera_topic}\n",
        "  ‚Ä¢ Total Frames: {len(images)}\n",
        "  ‚Ä¢ Duration: {image_timestamps[-1] - image_timestamps[0]:.2f} seconds\n",
        "  ‚Ä¢ Average FPS: {len(images)/(image_timestamps[-1] - image_timestamps[0]):.2f}\n",
        "\n",
        "IMAGE PROPERTIES:\n",
        "  ‚Ä¢ Resolution: {widths[0]}x{heights[0]} pixels\n",
        "  ‚Ä¢ Aspect Ratio: {widths[0]/heights[0]:.2f}\n",
        "  ‚Ä¢ Color Channels: {channels[0]}\n",
        "  ‚Ä¢ Average Compressed Size: {np.mean(compressed_sizes)/1024:.2f} KB\n",
        "  ‚Ä¢ Compression Ratio: {compression_ratio:.2f}x\n",
        "\n",
        "BRIGHTNESS ANALYSIS:\n",
        "  ‚Ä¢ Mean Brightness: {np.mean(brightness_values):.2f} / 255\n",
        "  ‚Ä¢ Brightness Std Dev: {np.std(brightness_values):.2f}\n",
        "  ‚Ä¢ Overexposed Frames: {overexposed} ({100*overexposed/len(images):.1f}%)\n",
        "  ‚Ä¢ Underexposed Frames: {underexposed} ({100*underexposed/len(images):.1f}%)\n",
        "\n",
        "COLOR DISTRIBUTION:\n",
        "  ‚Ä¢ Average Blue: {np.mean(avg_blue):.2f}\n",
        "  ‚Ä¢ Average Green: {np.mean(avg_green):.2f}\n",
        "  ‚Ä¢ Average Red: {np.mean(avg_red):.2f}\n",
        "\n",
        "MOTION ANALYSIS:\n",
        "  ‚Ä¢ Mean Frame Difference: {np.mean(frame_differences):.2f}\n",
        "  ‚Ä¢ High Motion Frames: {len(high_motion_frames)} ({100*len(high_motion_frames)/(len(images)-1):.1f}%)\n",
        "\n",
        "QUALITY METRICS:\n",
        "  ‚Ä¢ Average Sharpness: {np.mean(sharpness_scores):.2f}\n",
        "  ‚Ä¢ Average Contrast: {np.mean(contrast_scores):.2f}\n",
        "\n",
        "OUTPUT FILES:\n",
        "  ‚Ä¢ sample_images.png\n",
        "  ‚Ä¢ brightness_analysis.png\n",
        "  ‚Ä¢ color_distribution.png\n",
        "  ‚Ä¢ motion_analysis.png\n",
        "  ‚Ä¢ quality_metrics.png\n",
        "\"\"\"\n",
        "\n",
        "    print(image_summary)\n",
        "\n",
        "    # Save summary report\n",
        "    with open('image_eda_summary.txt', 'w') as f:\n",
        "        f.write(image_summary)\n",
        "\n",
        "    print(\"\\n‚úÖ Image EDA summary saved to: image_eda_summary.txt\")\n",
        "else:\n",
        "    print(\"\\n‚ö†Ô∏è  No images found for analysis\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}