{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A00785001/TC5035/blob/main/004_Loop_Closure_Dataset_Generation_v7_0_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "main_title"
      },
      "source": [
        "# Loop Closure Dataset Generation: Time Alignment, Pairing & Labeling\n",
        "## Phase 1.5: Supervised Learning Dataset Preparation for Jetson Nano Training Pipeline\n",
        "\n",
        "**Version:** 6.10  \n",
        "**Pipeline Phase:** Feature Extraction ‚Üí **[THIS NOTEBOOK]** ‚Üí Fusion MLP Training ‚Üí Deployment  \n",
        "**Target Hardware:** Waveshare Jetbot AI Pro Kit (Jetson Nano)  \n",
        "**SLAM System:** Google Cartographer (2D)  \n",
        "**Training Platform:** Vertex AI\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "documentation_section"
      },
      "source": [
        "## NOTEBOOK DOCUMENTATION\n",
        "\n",
        "### Purpose\n",
        "\n",
        "This notebook transforms independently extracted multi-modal features (camera + LiDAR) into a supervised learning dataset for training a loop closure detection classifier. It bridges the gap between feature extraction and neural network training by performing temporal alignment, intelligent pairing, and ground truth labeling.\n",
        "\n",
        "---\n",
        "\n",
        "### Workflow Overview\n",
        "\n",
        "**Phase 1A:** ROS Bag Validation (optional validation)\n",
        "**Phase 1B:** Feature File Validation (HDF5 features)\n",
        "**Phase 1C:** Pbstream Extraction\n",
        "- Extract trajectory nodes with timestamps and poses\n",
        "- Extract INTER_SUBMAP constraints (loop closures)\n",
        "- Generate pairwise distance/time table for all nodes\n",
        "- Temporal alignment: Match features to trajectory nodes\n",
        "\n",
        "**Phase 2:** Dataset Generation\n",
        "- Data profiling and automatic threshold suggestion\n",
        "- Generate positive pairs (loop closures from distance + time filters)\n",
        "- Generate easy negative pairs (spatially distant)\n",
        "- Generate hard negative pairs (perceptually similar but distant)\n",
        "\n",
        "**Phase 3:** Dataset Splitting & Validation\n",
        "**Phase 4:** Save Dataset & Generate Report\n",
        "\n",
        "---\n",
        "\n",
        "### Folder Structure\n",
        "\n",
        "**Expected Directory Layout:**\n",
        "\n",
        "```\n",
        "session_YYYYMMDD_HHMMSS/          (base working folder - your session)\n",
        "‚îú‚îÄ‚îÄ map.pbstream                  ‚Üê INPUT: Cartographer pbstream file (REQUIRED)\n",
        "‚îú‚îÄ‚îÄ session_data.bag              ‚Üê INPUT: ROS bag file (optional validation)\n",
        "‚îú‚îÄ‚îÄ features/                     ‚Üê INPUT: Directory from feature extraction\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ features.h5               ‚Üê INPUT: Extracted features (HDF5)\n",
        "‚îî‚îÄ‚îÄ dataset/                      ‚Üê OUTPUT: Created by this notebook\n",
        "    ‚îú‚îÄ‚îÄ loop_closure_dataset.pkl  ‚Üê OUTPUT: Training dataset\n",
        "    ‚îú‚îÄ‚îÄ dataset_diagnostics.png   ‚Üê OUTPUT: Visualization plots\n",
        "    ‚îî‚îÄ‚îÄ dataset_generation_report.txt ‚Üê OUTPUT: Summary report\n",
        "```\n",
        "\n",
        "**Note:** The `.pbstream` file is REQUIRED. Replace `session_YYYYMMDD_HHMMSS` with your actual session folder name.\n",
        "\n",
        "---\n",
        "\n",
        "### Required Inputs\n",
        "\n",
        "#### 1. Pbstream File (REQUIRED)\n",
        "\n",
        "**File:** `map.pbstream` (Cartographer SLAM state)\n",
        "\n",
        "**Contents:**\n",
        "- Trajectory nodes with full 6-DOF poses and timestamps\n",
        "- INTER_SUBMAP constraints (loop closures detected by SLAM)\n",
        "- Complete SLAM graph state\n",
        "\n",
        "#### 2. Extracted Features (HDF5 Format)\n",
        "\n",
        "**File:** `features/features.h5` (generated from feature extraction pipeline)\n",
        "\n",
        "**Structure:**\n",
        "```\n",
        "features.h5\n",
        "‚îú‚îÄ‚îÄ camera/\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ features [N_cam, 1280]       # MobileNetV2 embeddings (L2 normalized, float32)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ timestamps_sec [N_cam]       # ROS timestamp seconds (int64)\n",
        "‚îÇ   ‚îú‚îÄ‚îÄ timestamps_nsec [N_cam]      # ROS timestamp nanoseconds (int32)\n",
        "‚îÇ   ‚îî‚îÄ‚îÄ filenames [N_cam]            # Source image filenames (strings)\n",
        "‚îî‚îÄ‚îÄ lidar/\n",
        "    ‚îú‚îÄ‚îÄ features [N_lid, 256]        # 1D CNN descriptors (L2 normalized, float32)\n",
        "    ‚îú‚îÄ‚îÄ timestamps_sec [N_lid]       # ROS timestamp seconds (int64)\n",
        "    ‚îú‚îÄ‚îÄ timestamps_nsec [N_lid]      # ROS timestamp nanoseconds (int32)\n",
        "    ‚îî‚îÄ‚îÄ filenames [N_lid]            # Source scan filenames (strings)\n",
        "```\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "how_notebook_works"
      },
      "source": [
        "---\n",
        "\n",
        "## üß† HOW THIS NOTEBOOK WORKS: COMPREHENSIVE EXPLANATION\n",
        "\n",
        "### The Problem We're Solving\n",
        "\n",
        "**Loop closure detection** is critical for mobile robot SLAM. When a robot revisits a location, the system must recognize this \"loop closure\" to correct accumulated drift. This notebook creates a **supervised learning dataset** to train a neural network for loop closure detection using multi-modal sensor data.\n",
        "\n",
        "**The Challenge:** Three independent data streams must be combined:\n",
        "- Camera features (1280D MobileNetV2) at ~0.22 Hz\n",
        "- LiDAR features (256D 1D-CNN) at ~0.7 Hz  \n",
        "- SLAM ground truth (Cartographer trajectory + constraints)\n",
        "\n",
        "These have **different rates**, **independent timestamps**, and **no pre-sync**.\n",
        "\n",
        "---\n",
        "\n",
        "### Why This Approach?\n",
        "\n",
        "#### **1. Why INTER_SUBMAP Constraints?**\n",
        "\n",
        "Cartographer's pose graph has two constraint types:\n",
        "- **INTRA_SUBMAP**: Sequential (node j inserted into submap i)\n",
        "- **INTER_SUBMAP**: Loop closures (node j NOT in submap i = robot returned)\n",
        "\n",
        "**INTER_SUBMAP = gold standard** because:\n",
        "- Cartographer solved loop closure via scan matching\n",
        "- Passed rigorous geometric validation\n",
        "- Verified spatial alignment (<2m, similar orientation)\n",
        "- Residual provides confidence metric\n",
        "\n",
        "#### **2. Why KD-Trees for Temporal Alignment?**\n",
        "\n",
        "**Sensors operate independently:**\n",
        "- Camera: ~4.5s intervals\n",
        "- LiDAR: ~1.4s intervals\n",
        "- Trajectory nodes: ~0.9 Hz\n",
        "\n",
        "**KD-Tree solution:** O(log N) nearest-neighbor in time domain\n",
        "```\n",
        "For node at time T:\n",
        "  ‚Üí Find camera where |t_cam - T| < 0.5s\n",
        "  ‚Üí Find LiDAR where |t_lid - T| < 0.5s\n",
        "  ‚Üí Combine into multi-modal feature\n",
        "```\n",
        "\n",
        "**¬±500ms threshold** balances:\n",
        "- Robot motion (~0.5m in 500ms)\n",
        "- Sensor rate limits\n",
        "- Pose uncertainty\n",
        "\n",
        "#### **3. Why Three Pair Types?**\n",
        "\n",
        "**Positive (30%)** - True loop closures from INTER_SUBMAP\n",
        "- Teaches \"same place\" recognition\n",
        "\n",
        "**Easy Negative (35%)** - Distance >5m + temporal gap >5s\n",
        "- Teaches basic discrimination\n",
        "- Temporal gap prevents consecutive-but-far frames\n",
        "\n",
        "**Hard Negative (35%)** - High similarity (>0.7) BUT distant (>3m)\n",
        "- Handles perceptual aliasing (corridors, symmetry)\n",
        "- Most challenging cases\n",
        "\n",
        "**Balanced 30/35/35** prevents:\n",
        "- Trivial solutions (\"always no\")\n",
        "- Easy case overfitting\n",
        "- Perceptual aliasing failure\n",
        "\n",
        "---\n",
        "\n",
        "### Step-by-Step Workflow\n",
        "\n",
        "#### **PHASE 0: Data Validation**\n",
        "\n",
        "**HDF5 Analysis (1.1.5):** Feature stats, temporal coherence, quality checks\n",
        "**Bag Analysis (1.2.5):** Trajectory distribution, INTER constraints, overlap\n",
        "\n",
        "#### **PHASE 1: Feature-Trajectory Alignment**\n",
        "\n",
        "**Step 1.1: Load Features**\n",
        "```\n",
        "camera_features: [N, 1280] L2-normalized\n",
        "lidar_features: [N, 256] L2-normalized\n",
        "timestamps: sec (int64) + nsec (int32)\n",
        "```\n",
        "\n",
        "**Step 1.2: Parse Trajectory Nodes**\n",
        "```\n",
        "From /trajectory_node_list (MarkerArray):\n",
        "  node_id, timestamp, pose (x,y,z, qx,qy,qz,qw)\n",
        "```\n",
        "\n",
        "**Step 1.2.6: Parse INTER_SUBMAP Constraints**\n",
        "```\n",
        "From /constraint_list (MarkerArray):\n",
        "  Filter: \"Inter constraints\" namespace only\n",
        "  Match: constraint endpoints ‚Üí trajectory nodes\n",
        "  Validate: distance <2m, angle <90¬∞, residual <0.5m\n",
        "```\n",
        "\n",
        "**Step 1.3: Temporal Alignment**\n",
        "```\n",
        "For each trajectory node at time T:\n",
        "  cam_idx = nearest(camera_times, T) if |diff| < 0.5s\n",
        "  lid_idx = nearest(lidar_times, T) if |diff| < 0.5s\n",
        "  \n",
        "  If both found:\n",
        "    combined_feature = [cam_feat, lid_feat]  # [1536D]\n",
        "    valid_nodes.append(node)\n",
        "```\n",
        "\n",
        "#### **PHASE 2: Intelligent Pairing**\n",
        "\n",
        "**Step 2.1: Positive Pairs**\n",
        "```\n",
        "For (node_i, node_j) in INTER_SUBMAP_constraints:\n",
        "  If both have combined_feature:\n",
        "    pair = {features: [feat_i, feat_j], label: 1}\n",
        "```\n",
        "\n",
        "**Step 2.2: Easy Negatives**\n",
        "```\n",
        "Random sample nodes:\n",
        "  Accept if: distance >5m AND time_gap >5s\n",
        "```\n",
        "\n",
        "**Step 2.3: Hard Negatives**\n",
        "```\n",
        "KD-Tree in feature space:\n",
        "  Find similar features (cosine >0.7)\n",
        "  Accept if: spatially distant (>3m)\n",
        "```\n",
        "\n",
        "#### **PHASE 3: Finalization**\n",
        "\n",
        "- Combine + shuffle all pairs\n",
        "- Stratified train/val/test split (60/20/20)\n",
        "- Validation checks + statistics\n",
        "- Save PKL + diagnostics + report\n",
        "\n",
        "---\n",
        "\n",
        "### üõ°Ô∏è Key Design Decisions\n",
        "\n",
        "**¬±500ms threshold:**\n",
        "- Too tight (<100ms): 60-80% data loss\n",
        "- Too loose (>1s): Robot moves >1m, high uncertainty\n",
        "- Sweet spot (500ms): <0.5m motion, 70-80% alignment\n",
        "\n",
        "**Float64 for timestamps:**\n",
        "- Precision loss: ~250ns\n",
        "- Threshold: 500,000,000ns\n",
        "- Ratio: 5e-7 (negligible!)\n",
        "- Store both: split (exact) + float (algorithms)\n",
        "\n",
        "**Residual <0.5m filter:**\n",
        "- High residual = weak constraint\n",
        "- Filters false positives\n",
        "- Keeps only high-quality ground truth\n",
        "\n",
        "**35/35 easy/hard split:**\n",
        "- Only easy: fails on aliasing\n",
        "- Only hard: won't converge\n",
        "- Balanced: stable training + generalization\n",
        "\n",
        "**L2 normalization required:**\n",
        "- Enables cosine similarity = dot product\n",
        "- Network learns directions not magnitudes\n",
        "- KD-tree works in normalized space\n",
        "\n",
        "---\n",
        "\n",
        "### ‚ö†Ô∏è Common Issues\n",
        "\n",
        "**\"No INTER_SUBMAP constraints\"**\n",
        "- Robot never looped back\n",
        "- Solution: Re-record with intentional loops\n",
        "\n",
        "**\"Low alignment <50%\"**\n",
        "- Clock skew or wrong timestamps\n",
        "- Solution: Verify bag recording, check timestamps\n",
        "\n",
        "**\"Features not normalized\"**\n",
        "- Extraction pipeline error\n",
        "- Solution: Re-extract with normalization\n",
        "\n",
        "**\"Insufficient positives\"**\n",
        "- Too few validated constraints\n",
        "- Solution: Relax thresholds or re-record\n",
        "\n",
        "---\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "**Output:** `loop_closure_dataset.pkl`\n",
        "```\n",
        "{'train': {features: [N,2,1536], labels: [N]},\n",
        " 'val': {...},\n",
        " 'test': {...},\n",
        " 'config': {...},\n",
        " 'statistics': {...}}\n",
        "```\n",
        "\n",
        "**1. Train Fusion MLP (Vertex AI)**\n",
        "- Input: [2, 1536] paired features\n",
        "- Architecture: MLP with dropout\n",
        "- Output: Binary classifier\n",
        "\n",
        "**2. Evaluate**\n",
        "- Precision/Recall/F1\n",
        "- ROC curves\n",
        "- Per-type accuracy\n",
        "\n",
        "**3. Deploy to Jetson Nano**\n",
        "- TensorRT optimization\n",
        "- Real-time inference (<50ms)\n",
        "- Integrate with Cartographer\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pip_install_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f036116a-2c6a-480b-e6cb-3821f04dbbce"
      },
      "source": [
        "# Install required packages\n",
        "!pip install -q rosbags h5py scikit-learn matplotlib\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/137.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m753.1/753.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h‚úÖ All packages installed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_1"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 1: SETUP\n",
        "\n",
        "Imports, configuration, thresholds.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports"
      },
      "source": [
        "## 1.1 IMPORTS AND DEPENDENCIES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "import_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0dff2d2-2384-47af-fc16-e0a8c3793849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful\n",
            "   NumPy version: 2.0.2\n",
            "   Python version: 3.12.12\n"
          ]
        }
      ],
      "source": [
        "# System and file I/O\n",
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "# Numerical computing\n",
        "import numpy as np\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.spatial.transform import Rotation\n",
        "# Data handling\n",
        "import h5py\n",
        "# ROS bag processing\n",
        "from rosbags.rosbag1 import Reader\n",
        "from rosbags.typesys import get_typestore, Stores\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Circle\n",
        "import seaborn as sns\n",
        "# Progress tracking\n",
        "from tqdm.auto import tqdm\n",
        "# Random state for reproducibility\n",
        "import random\n",
        "print(\"‚úÖ All imports successful\")\n",
        "print(f\"   NumPy version: {np.__version__}\")\n",
        "print(f\"   Python version: {sys.version.split()[0]}\")import struct\n",
        "import zlib\n",
        "from google.protobuf.internal.decoder import _DecodeVarint32, _DecodeVarint\n",
        "from google.colab import drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "working_directory"
      },
      "source": [
        "## 1.2 WORKING DIRECTORY CONFIGURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "workdir_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e613e34-d012-4608-e109-08be7cbd2419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÇ Working directory: /content/drive/MyDrive/DATA/Artificial_Intelligence/MNA-V/Subjects/TC5035-Proyecto_Integrador/TC5035.data/jetbot/session_20251022_155137\n",
            "   Session ID: session_20251022_155137\n"
          ]
        }
      ],
      "source": [
        "# Configure session folder\n",
        "SESSION_ID = 'session_20251022_155137'  # ‚Üê CHANGE THIS to your session folder name\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Google Colab: Assume data is in Drive\n",
        "    BASE_PATH = f'/content/drive/MyDrive/DATA/Artificial_Intelligence/MNA-V/Subjects/TC5035-Proyecto_Integrador/TC5035.data/jetbot/{SESSION_ID}'\n",
        "else:\n",
        "    # Local: Use current directory or specify path\n",
        "    BASE_PATH = f'./{SESSION_ID}'  # Or specify full path: '/path/to/data/{SESSION_ID}'\n",
        "\n",
        "# Change to working directory\n",
        "os.chdir(BASE_PATH)\n",
        "print(f\"\\n Working directory: {os.getcwd()}\")\n",
        "print(f\"   Session ID: {SESSION_ID}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "configuration",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c47d0ff9-ccf0-44ab-ea29-f1ef848e05ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FILE PATHS CONFIGURATION\n",
            "======================================================================\n",
            "\n",
            "üìÅ Input Configuration:\n",
            "  Features directory: features\n",
            "  Features file: features/features.h5\n",
            "  ROS bag file: session_data.bag\n",
            "  Pbstream file (optional): session_data.pbstream\n",
            "\n",
            "üìÅ Output Configuration:\n",
            "  Output directory: dataset\n",
            "  Dataset file: dataset/loop_closure_dataset.pkl\n",
            "  Diagnostics plot: dataset/dataset_diagnostics.png\n",
            "  Report file: dataset/dataset_generation_report.txt\n",
            "\n",
            "üîç Verifying input files...\n",
            "  ‚úì Features file found: features/features.h5\n",
            "  ‚úì ROS bag file found: session_data.bag\n",
            "  ‚Ñπ Pbstream file not found (optional): session_data.pbstream\n",
            "======================================================================\n",
            "\n",
            "‚öôÔ∏è Algorithm Parameters:\n",
            "  Time alignment: ¬±0.5s\n",
            "  Positive threshold: <2.0m\n",
            "  Easy negative: >5.0m\n",
            "  Hard negative: >3.0m, similarity >0.7\n",
            "  Constraint validation: residual <0.5m, angle <1.57 rad\n",
            "  Dataset ratios: 30% pos / 35% easy neg / 35% hard neg\n",
            "  Split ratios: 60% train / 20% val / 20% test\n"
          ]
        }
      ],
      "source": [
        "# File Paths Configuration\n",
        "print(\"=\" * 70)\n",
        "print(\"FILE PATHS CONFIGURATION\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Input directories and files (relative to working folder)\n",
        "FEATURES_DIR = 'features'\n",
        "FEATURES_FILE = os.path.join(FEATURES_DIR, 'features.h5')\n",
        "BAG_FILE = 'session_data.bag'  # In base working folder\n",
        "PBSTREAM_FILE = 'session_data.pbstream'  # Optional, in base working folder\n",
        "\n",
        "# Output directory for dataset\n",
        "OUTPUT_DIR = 'dataset'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Output files\n",
        "DATASET_FILE = os.path.join(OUTPUT_DIR, 'loop_closure_dataset.pkl')\n",
        "DIAGNOSTICS_FILE = os.path.join(OUTPUT_DIR, 'dataset_diagnostics.png')\n",
        "REPORT_FILE = os.path.join(OUTPUT_DIR, 'dataset_generation_report.txt')\n",
        "\n",
        "print(\"\\n Input Configuration:\")\n",
        "print(f\"  Features directory: {FEATURES_DIR}\")\n",
        "print(f\"  Features file: {FEATURES_FILE}\")\n",
        "print(f\"  ROS bag file: {BAG_FILE}\")\n",
        "print(f\"  Pbstream file (optional): {PBSTREAM_FILE}\")\n",
        "\n",
        "print(\"\\n Output Configuration:\")\n",
        "print(f\"  Output directory: {OUTPUT_DIR}\")\n",
        "print(f\"  Dataset file: {DATASET_FILE}\")\n",
        "print(f\"  Diagnostics plot: {DIAGNOSTICS_FILE}\")\n",
        "print(f\"  Report file: {REPORT_FILE}\")\n",
        "\n",
        "# Verify input files exist\n",
        "print(\"\\n Verifying input files...\")\n",
        "if os.path.exists(FEATURES_FILE):\n",
        "    print(f\"  ‚úì Features file found: {FEATURES_FILE}\")\n",
        "else:\n",
        "    print(f\"  ‚ùå Features file NOT found: {FEATURES_FILE}\")\n",
        "    raise FileNotFoundError(f\"Required file not found: {FEATURES_FILE}\")\n",
        "\n",
        "if os.path.exists(BAG_FILE):\n",
        "    print(f\"  ‚úì ROS bag file found: {BAG_FILE}\")\n",
        "else:\n",
        "    print(f\"  ‚ùå ROS bag file NOT found: {BAG_FILE}\")\n",
        "    raise FileNotFoundError(f\"Required file not found: {BAG_FILE}\")\n",
        "\n",
        "if os.path.exists(PBSTREAM_FILE):\n",
        "    print(f\"  ‚úì Pbstream file found: {PBSTREAM_FILE}\")\n",
        "else:\n",
        "    print(f\"  ‚Ñπ Pbstream file not found (optional): {PBSTREAM_FILE}\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Time alignment parameters\n",
        "MAX_TIME_OFFSET = 0.5  # seconds - maximum time difference for feature-node matching\n",
        "MIN_TEMPORAL_GAP = 5.0  # seconds - minimum time between frames for negative pairs\n",
        "\n",
        "# Spatial thresholds\n",
        "POSITIVE_DISTANCE_THRESHOLD = 0.3  # meters - UPDATED for 3m x 2m environment\n",
        "EASY_NEGATIVE_MIN_DISTANCE = 1.0  # meters - UPDATED for small indoor space\n",
        "HARD_NEGATIVE_MIN_DISTANCE = 3.0  # meters - minimum distance for hard negatives\n",
        "\n",
        "POSITIVE_TIME_GAP = 10.0  # seconds - minimum time between loop closure pairs\n",
        "# Cartographer validation thresholds\n",
        "MAX_CONSTRAINT_RESIDUAL = 0.5  # meters - maximum constraint error for validation\n",
        "MAX_ANGULAR_DISTANCE = np.pi / 2  # radians - maximum angular difference for loop closure\n",
        "\n",
        "# Pairing strategy targets\n",
        "POSITIVE_RATIO = 0.30  # 30% positive pairs\n",
        "EASY_NEGATIVE_RATIO = 0.35  # 35% easy negatives\n",
        "HARD_NEGATIVE_RATIO = 0.35  # 35% hard negatives\n",
        "\n",
        "# Hard negative mining\n",
        "HARD_NEGATIVE_SIMILARITY_THRESHOLD = 0.7  # cosine similarity threshold for perceptual aliasing\n",
        "\n",
        "# Split ratios (stratified random)\n",
        "TRAIN_RATIO = 0.60\n",
        "VAL_RATIO = 0.20\n",
        "TEST_RATIO = 0.20\n",
        "\n",
        "print(\"\\n‚öôÔ∏è Algorithm Parameters:\")\n",
        "print(f\"  Time alignment: ¬±{MAX_TIME_OFFSET}s\")\n",
        "print(f\"  Positive threshold: <{POSITIVE_DISTANCE_THRESHOLD}m\")\n",
        "print(f\"  Easy negative: >{EASY_NEGATIVE_MIN_DISTANCE}m\")\n",
        "print(f\"  Hard negative: >{HARD_NEGATIVE_MIN_DISTANCE}m, similarity >{HARD_NEGATIVE_SIMILARITY_THRESHOLD}\")\n",
        "print(f\"  Constraint validation: residual <{MAX_CONSTRAINT_RESIDUAL}m, angle <{MAX_ANGULAR_DISTANCE:.2f} rad\")\n",
        "print(f\"  Dataset ratios: {POSITIVE_RATIO:.0%} pos / {EASY_NEGATIVE_RATIO:.0%} easy neg / {HARD_NEGATIVE_RATIO:.0%} hard neg\")\n",
        "print(f\"  Split ratios: {TRAIN_RATIO:.0%} train / {VAL_RATIO:.0%} val / {TEST_RATIO:.0%} test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_2"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 2: STORAGE MOUNTING\n",
        "\n",
        "Google Drive mount.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "google_drive_mount"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive for Colab environment\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úì Google Drive mounted\")\n",
        "except:\n",
        "    print(\"‚ÑπÔ∏è  Not in Colab environment, skipping Drive mount\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "env_cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f94ad88-81e3-482b-a612-789b4c34852f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîµ Running in Google Colab\n",
            "Mounted at /content/drive\n",
            "‚úÖ Google Drive mounted\n",
            "\n",
            "üé≤ Random seed set to: 42\n"
          ]
        }
      ],
      "source": [
        "# Detect environment\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\" Running in Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\" Running in local environment\")\n",
        "\n",
        "# Mount Google Drive if in Colab\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive mounted\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "print(f\"\\n Random seed set to: {RANDOM_SEED}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_3"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 3: PBSTREAM LOADING & EXTRACTION\n",
        "\n",
        "Trajectory, constraints, pairwise data.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAxbkXIBFzjC"
      },
      "source": [
        "## 3.1 SECTION DOCUMENTATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbstream_extraction_header"
      },
      "source": [
        "### 1C.1 Pbstream Extraction Functions\n",
        "\n",
        "These functions parse the Cartographer `.pbstream` file (protobuf format) to extract:\n",
        "- Trajectory nodes with timestamps and poses\n",
        "- INTER_SUBMAP constraints (loop closures)\n",
        "- Pairwise node distances and time differences\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcaHp_oXAEHo"
      },
      "source": [
        "---\n",
        "\n",
        "# üìö Cartographer PBSTREAM Format Documentation\n",
        "\n",
        "## üèóÔ∏è File Structure\n",
        "\n",
        "```\n",
        "PBSTREAM FILE\n",
        "‚îú‚îÄ [8-byte header]\n",
        "‚îî‚îÄ [Messages]* (repeated)\n",
        "   ‚îú‚îÄ 8 bytes: message length (uint64, little-endian)\n",
        "   ‚îî‚îÄ N bytes: gzip-compressed protobuf message\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üìã Message Types\n",
        "\n",
        "### 1. POSE_GRAPH (Field 1)\n",
        "Complete optimized graph structure containing all trajectories, nodes, submaps, and loop closure constraints after SLAM optimization.\n",
        "\n",
        "**Typical Count:** 1-2 messages (usually at end of file)\n",
        "\n",
        "### 2. ALL_TRAJECTORY_BUILDER_OPTIONS (Field 2)\n",
        "SLAM algorithm configuration parameters and tuning settings.\n",
        "\n",
        "**Typical Count:** 1 message (at start of file)\n",
        "\n",
        "### 3. SUBMAP (Field 3)\n",
        "2D/3D probability grids representing mapped areas. Each submap is a tile of the complete map.\n",
        "\n",
        "### 4. NODE (Field 4) ‚≠ê PRIMARY DATA\n",
        "Trajectory nodes containing robot pose, timestamp, and sensor data at each mapping step.\n",
        "\n",
        "### 5. TRAJECTORY_DATA (Field 5)\n",
        "Metadata about trajectories (IDs, relationships between multiple trajectories).\n",
        "\n",
        "### 6. IMU_DATA (Field 6)\n",
        "IMU sensor readings (accelerometer, gyroscope) if IMU was used during mapping.\n",
        "\n",
        "---\n",
        "\n",
        "## üéØ NODE Structure (Field 4) - DETAILED\n",
        "\n",
        "This is the **primary data structure** containing pose and sensor information.\n",
        "\n",
        "```\n",
        "NODE (Field 4)\n",
        "‚îú‚îÄ Field 1: Node metadata (usually empty, 0-2 bytes)\n",
        "‚îî‚îÄ Field 5: POSE DATA\n",
        "   ‚îú‚îÄ Field 1: TIMESTAMP (int64 varint)\n",
        "   ‚îÇ   ‚îî‚îÄ Format: 100-nanosecond ticks since Windows epoch (1601-01-01)\n",
        "   ‚îÇ   ‚îî‚îÄ Conversion: (timestamp - 621355968000000000) / 10000000 = Unix seconds\n",
        "   ‚îÇ\n",
        "   ‚îú‚îÄ Field 2: Metadata (9-18 bytes, varies by node)\n",
        "   ‚îú‚îÄ Field 3: POINT CLOUD DATA (600-950 bytes, raw LIDAR scan)\n",
        "   ‚îú‚îÄ Field 4: (empty)\n",
        "   ‚îú‚îÄ Field 5: (empty)\n",
        "   ‚îÇ\n",
        "   ‚îî‚îÄ Field 7: POSE (TRANSFORM)\n",
        "      ‚îú‚îÄ Field 1: TRANSLATION\n",
        "      ‚îÇ  ‚îú‚îÄ Field 1: x (double) - meters\n",
        "      ‚îÇ  ‚îú‚îÄ Field 2: y (double) - meters\n",
        "      ‚îÇ  ‚îî‚îÄ Field 3: z (double) - meters\n",
        "      ‚îÇ\n",
        "      ‚îî‚îÄ Field 2: ROTATION (quaternion)\n",
        "         ‚îú‚îÄ Field 1: x (double)\n",
        "         ‚îú‚îÄ Field 2: y (double)\n",
        "         ‚îú‚îÄ Field 3: z (double)\n",
        "         ‚îî‚îÄ Field 4: w (double) - normalized\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üîß Protobuf Wire Types\n",
        "\n",
        "| Wire Type | Name | Description |\n",
        "|-----------|------|-------------|\n",
        "| 0 | VARINT | Variable-length integer (int32, int64, uint32, uint64, bool, enum) |\n",
        "| 1 | 64BIT | Fixed 8 bytes (double, fixed64, sfixed64) |\n",
        "| 2 | LENGTH_DELIM | Length-prefixed (string, bytes, nested messages, packed repeated) |\n",
        "| 5 | 32BIT | Fixed 4 bytes (float, fixed32, sfixed32) |\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Important Notes\n",
        "\n",
        "- **Timestamp Format:** Cartographer uses \"Universal Time\" (100-nanosecond ticks since Windows epoch)\n",
        "- **Coordinate System:** Right-handed with Z-up (typical for 2D: z=0)\n",
        "- **Quaternions:** Stored as (x, y, z, w) and are normalized (magnitude = 1.0)\n",
        "- **Compression:** All messages are gzip-compressed with window bits = 16 + MAX_WBITS\n",
        "- **Endianness:** Little-endian for all multi-byte values\n",
        "- **Field Numbers:** In protobuf, field numbers 1-15 use 1 byte, 16+ use 2+ bytes\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCDs9aB68h4n"
      },
      "source": [
        "## 3.2 Helper Functions (ORIGINAL - DO NOT MODIFY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2_kgpTGmByqb"
      },
      "outputs": [],
      "source": [
        "def extract_xy(field5_data):\n",
        "    pos = 0\n",
        "    x = y = None\n",
        "    while pos < len(field5_data):\n",
        "        try:\n",
        "            tag, pos = _DecodeVarint32(field5_data, pos)\n",
        "            fn = tag >> 3\n",
        "            wt = tag & 0x7\n",
        "            if fn == 7 and wt == 2:\n",
        "                length, pos = _DecodeVarint32(field5_data, pos)\n",
        "                f7_data = field5_data[pos:pos + length]\n",
        "                f7_pos = 0\n",
        "                while f7_pos < len(f7_data):\n",
        "                    try:\n",
        "                        f7_tag, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                        f7_fn = f7_tag >> 3\n",
        "                        f7_wt = f7_tag & 0x7\n",
        "                        if f7_fn == 1 and f7_wt == 2:\n",
        "                            tl, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                            td = f7_data[f7_pos:f7_pos + tl]\n",
        "                            tp = 0\n",
        "                            while tp < len(td):\n",
        "                                try:\n",
        "                                    tt, tp = _DecodeVarint32(td, tp)\n",
        "                                    tf = tt >> 3\n",
        "                                    tw = tt & 0x7\n",
        "                                    if tw == 1 and tp + 8 <= len(td):\n",
        "                                        val = struct.unpack('<d', td[tp:tp+8])[0]\n",
        "                                        if tf == 1:\n",
        "                                            x = val\n",
        "                                        elif tf == 2:\n",
        "                                            y = val\n",
        "                                        tp += 8\n",
        "                                    else:\n",
        "                                        break\n",
        "                                except:\n",
        "                                    break\n",
        "                            f7_pos += tl\n",
        "                            break\n",
        "                        elif f7_wt == 2:\n",
        "                            l2, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                            f7_pos += l2\n",
        "                        else:\n",
        "                            break\n",
        "                    except:\n",
        "                        break\n",
        "                pos += length\n",
        "                break\n",
        "            elif wt == 0:\n",
        "                _, pos = _DecodeVarint32(field5_data, pos)\n",
        "            elif wt == 1:\n",
        "                pos += 8\n",
        "            elif wt == 2:\n",
        "                l, pos = _DecodeVarint32(field5_data, pos)\n",
        "                pos += l\n",
        "            elif wt == 5:\n",
        "                pos += 4\n",
        "            else:\n",
        "                break\n",
        "        except:\n",
        "            break\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def extract_timestamp(node_data):\n",
        "    \"\"\"Extract timestamp from Field 1 (node ID message)\"\"\"\n",
        "    pos = 0\n",
        "    while pos < len(node_data):\n",
        "        try:\n",
        "            tag, pos = _DecodeVarint32(node_data, pos)\n",
        "            fn = tag >> 3\n",
        "            wt = tag & 0x7\n",
        "\n",
        "            # Timestamp is inside Field 5 (pose), not Field 1!\n",
        "            if fn == 5 and wt == 2:\n",
        "                length, pos = _DecodeVarint32(node_data, pos)\n",
        "                field1_data = node_data[pos:pos + length]\n",
        "                f1_pos = 0\n",
        "                while f1_pos < len(field1_data):\n",
        "                    try:\n",
        "                        f1_tag, f1_pos = _DecodeVarint32(field1_data, f1_pos)\n",
        "                        f1_fn = f1_tag >> 3\n",
        "                        f1_wt = f1_tag & 0x7\n",
        "                        if f1_fn == 1 and f1_wt == 0:  # Timestamp\n",
        "                            timestamp, f1_pos = _DecodeVarint(field1_data, f1_pos)\n",
        "                            return timestamp\n",
        "                        elif f1_wt == 0:\n",
        "                            _, f1_pos = _DecodeVarint32(field1_data, f1_pos)\n",
        "                        elif f1_wt == 1:\n",
        "                            f1_pos += 8\n",
        "                        elif f1_wt == 2:\n",
        "                            l, f1_pos = _DecodeVarint32(field1_data, f1_pos)\n",
        "                            f1_pos += l\n",
        "                        elif f1_wt == 5:\n",
        "                            f1_pos += 4\n",
        "                        else:\n",
        "                            break\n",
        "                    except:\n",
        "                        break\n",
        "                return None\n",
        "            elif wt == 0:\n",
        "                _, pos = _DecodeVarint32(node_data, pos)\n",
        "            elif wt == 1:\n",
        "                pos += 8\n",
        "            elif wt == 2:\n",
        "                l, pos = _DecodeVarint32(node_data, pos)\n",
        "                pos += l\n",
        "            elif wt == 5:\n",
        "                pos += 4\n",
        "            else:\n",
        "                break\n",
        "        except:\n",
        "            break\n",
        "    return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8G7_eZdv8h4n"
      },
      "source": [
        "\n",
        "# 3.3 FILE VALIDATION\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khHFHZc88h4o",
        "outputId": "cdac7b32-d295-4708-8faf-6906ffba4949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç VALIDATING PBSTREAM FILE...\n",
            "\n",
            "File size: 2,800,733 bytes (2.67 MB)\n",
            "Header: db 01 f5 5b 7b 1f 1d 7b\n",
            "\n",
            "‚úÖ Message counts:\n",
            "   POSE_GRAPH           (Field 1): 2\n",
            "   BUILDER_OPTIONS      (Field 2): 1\n",
            "   SUBMAP               (Field 3): 36\n",
            "   NODE                 (Field 4): 1,256\n",
            "\n",
            "‚úÖ Timestamp example (first node):\n",
            "   Raw ticks (Year 1 epoch): 638967723732811315\n",
            "   Unix timestamp: 1761175573 seconds\n",
            "   Nanoseconds in second: 281131500 ns\n",
            "   Date/time: 2025-10-22 23:26:13.281\n",
            "\n",
            "‚úÖ File structure: Valid\n"
          ]
        }
      ],
      "source": [
        "PBSTREAM_FILE = os.path.join(BASE_PATH, \"map.pbstream\")\n",
        "print(f\"Pbstream file: {PBSTREAM_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SkqfEHN8h4o"
      },
      "outputs": [],
      "source": [
        "def extract_full_pose(field5_data):\n",
        "    \"\"\"Extract full pose: x, y, z, quat_x, quat_y, quat_z, quat_w, timestamp\"\"\"\n",
        "    pos = 0\n",
        "    x = y = z = qx = qy = qz = qw = timestamp = None\n",
        "\n",
        "    while pos < len(field5_data):\n",
        "        try:\n",
        "            tag, pos = _DecodeVarint32(field5_data, pos)\n",
        "            fn = tag >> 3\n",
        "            wt = tag & 0x7\n",
        "\n",
        "            if fn == 1 and wt == 0:  # Timestamp\n",
        "                timestamp, pos = _DecodeVarint(field5_data, pos)\n",
        "\n",
        "            elif fn == 7 and wt == 2:  # Pose\n",
        "                length, pos = _DecodeVarint32(field5_data, pos)\n",
        "                f7_data = field5_data[pos:pos + length]\n",
        "                f7_pos = 0\n",
        "\n",
        "                while f7_pos < len(f7_data):\n",
        "                    try:\n",
        "                        f7_tag, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                        f7_fn = f7_tag >> 3\n",
        "                        f7_wt = f7_tag & 0x7\n",
        "\n",
        "                        if f7_fn == 1 and f7_wt == 2:  # Translation\n",
        "                            tl, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                            td = f7_data[f7_pos:f7_pos + tl]\n",
        "                            tp = 0\n",
        "                            while tp < len(td):\n",
        "                                try:\n",
        "                                    tt, tp = _DecodeVarint32(td, tp)\n",
        "                                    tf = tt >> 3\n",
        "                                    tw = tt & 0x7\n",
        "                                    if tw == 1 and tp + 8 <= len(td):\n",
        "                                        val = struct.unpack('<d', td[tp:tp+8])[0]\n",
        "                                        if tf == 1: x = val\n",
        "                                        elif tf == 2: y = val\n",
        "                                        elif tf == 3: z = val\n",
        "                                        tp += 8\n",
        "                                    else:\n",
        "                                        break\n",
        "                                except:\n",
        "                                    break\n",
        "                            f7_pos += tl\n",
        "\n",
        "                        elif f7_fn == 2 and f7_wt == 2:  # Rotation\n",
        "                            rl, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                            rd = f7_data[f7_pos:f7_pos + rl]\n",
        "                            rp = 0\n",
        "                            while rp < len(rd):\n",
        "                                try:\n",
        "                                    rt, rp = _DecodeVarint32(rd, rp)\n",
        "                                    rf = rt >> 3\n",
        "                                    rw = rt & 0x7\n",
        "                                    if rw == 1 and rp + 8 <= len(rd):\n",
        "                                        val = struct.unpack('<d', rd[rp:rp+8])[0]\n",
        "                                        if rf == 1: qx = val\n",
        "                                        elif rf == 2: qy = val\n",
        "                                        elif rf == 3: qz = val\n",
        "                                        elif rf == 4: qw = val\n",
        "                                        rp += 8\n",
        "                                    else:\n",
        "                                        break\n",
        "                                except:\n",
        "                                    break\n",
        "                            f7_pos += rl\n",
        "\n",
        "                        elif f7_wt == 2:\n",
        "                            l, f7_pos = _DecodeVarint32(f7_data, f7_pos)\n",
        "                            f7_pos += l\n",
        "                        else:\n",
        "                            break\n",
        "                    except:\n",
        "                        break\n",
        "                pos += length\n",
        "\n",
        "            elif wt == 0:\n",
        "                _, pos = _DecodeVarint32(field5_data, pos)\n",
        "            elif wt == 1:\n",
        "                pos += 8\n",
        "            elif wt == 2:\n",
        "                l, pos = _DecodeVarint32(field5_data, pos)\n",
        "                pos += l\n",
        "            elif wt == 5:\n",
        "                pos += 4\n",
        "            else:\n",
        "                break\n",
        "        except:\n",
        "            break\n",
        "\n",
        "    return x, y, z, qx, qy, qz, qw, timestamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sZ47aQB8h4p"
      },
      "source": [
        "---\n",
        "# 3.4 TRAJECTORY EXTRACTION AND ANALYSIS\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "TPCZRxz18h4p",
        "outputId": "34d29633-e658-4db8-debc-29adafa6a2ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üõ§Ô∏è EXTRACTING TRAJECTORY DATA...\n",
            "\n",
            "‚úÖ Extracted: 1255 nodes\n",
            "\n",
            "üìù Timestamp format:\n",
            "   timestamp_secs: Unix timestamp (seconds since 1970-01-01)\n",
            "   timestamp_nsecs: Nanoseconds within that second (0-999,999,999)\n",
            "\n",
            "üìã First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   node_id  timestamp_secs  timestamp_nsecs       x_m       y_m  z_m  quat_x  \\\n",
              "0        0      1761175578        341865800 -0.001466  0.004393  0.0     0.0   \n",
              "1        1      1761175578        476540500 -0.003856  0.002816  0.0     0.0   \n",
              "2        2      1761175578        611894500  0.001183  0.002219  0.0     0.0   \n",
              "3        3      1761175578        867448600  0.041088  0.004711  0.0     0.0   \n",
              "4        4      1761175579          2461300  0.076415  0.010777  0.0     0.0   \n",
              "\n",
              "   quat_y    quat_z    quat_w  \n",
              "0     0.0  0.001625  0.999999  \n",
              "1     0.0  0.017387  0.999849  \n",
              "2     0.0  0.030296  0.999541  \n",
              "3     0.0  0.006010  0.999982  \n",
              "4     0.0 -0.005306  0.999986  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6714d165-0e37-4e45-a00a-82c91fb1379f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node_id</th>\n",
              "      <th>timestamp_secs</th>\n",
              "      <th>timestamp_nsecs</th>\n",
              "      <th>x_m</th>\n",
              "      <th>y_m</th>\n",
              "      <th>z_m</th>\n",
              "      <th>quat_x</th>\n",
              "      <th>quat_y</th>\n",
              "      <th>quat_z</th>\n",
              "      <th>quat_w</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1761175578</td>\n",
              "      <td>341865800</td>\n",
              "      <td>-0.001466</td>\n",
              "      <td>0.004393</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001625</td>\n",
              "      <td>0.999999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1761175578</td>\n",
              "      <td>476540500</td>\n",
              "      <td>-0.003856</td>\n",
              "      <td>0.002816</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.017387</td>\n",
              "      <td>0.999849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1761175578</td>\n",
              "      <td>611894500</td>\n",
              "      <td>0.001183</td>\n",
              "      <td>0.002219</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.030296</td>\n",
              "      <td>0.999541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1761175578</td>\n",
              "      <td>867448600</td>\n",
              "      <td>0.041088</td>\n",
              "      <td>0.004711</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.006010</td>\n",
              "      <td>0.999982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1761175579</td>\n",
              "      <td>2461300</td>\n",
              "      <td>0.076415</td>\n",
              "      <td>0.010777</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.005306</td>\n",
              "      <td>0.999986</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6714d165-0e37-4e45-a00a-82c91fb1379f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6714d165-0e37-4e45-a00a-82c91fb1379f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6714d165-0e37-4e45-a00a-82c91fb1379f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-64711ed1-9b41-44ad-aa60-d6ad98b077ce\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-64711ed1-9b41-44ad-aa60-d6ad98b077ce')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-64711ed1-9b41-44ad-aa60-d6ad98b077ce button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_trajectory\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"node_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1,\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_secs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1761175578,\n        \"max\": 1761175579,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1761175579,\n          1761175578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_nsecs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 321192010,\n        \"min\": 2461300,\n        \"max\": 867448600,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          476540500,\n          2461300\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03526876997185841,\n        \"min\": -0.003855959981005849,\n        \"max\": 0.07641458004158587,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.003855959981005849,\n          0.07641458004158587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0034034226982691757,\n        \"min\": 0.002219258704663245,\n        \"max\": 0.010777410793901158,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.0028156855755909404,\n          0.010777410793901158\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.01402528272892745,\n        \"min\": -0.005306045595611519,\n        \"max\": 0.030296182581440567,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.01738699182987\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00019444167215778915,\n        \"min\": 0.99954096530407,\n        \"max\": 0.9999986796051636,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9998488348321001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã Last 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      node_id  timestamp_secs  timestamp_nsecs       x_m       y_m  z_m  \\\n",
              "1250     1250      1761175962        839079300  2.844030  6.390513  0.0   \n",
              "1251     1251      1761175963        632571600  2.768131  6.164998  0.0   \n",
              "1252     1252      1761175963        902584000  2.712850  6.092377  0.0   \n",
              "1253     1253      1761175964        296024600  2.607575  6.054640  0.0   \n",
              "1254     1254      1761175964        946802100  2.464423  6.084261  0.0   \n",
              "\n",
              "      quat_x  quat_y    quat_z    quat_w  \n",
              "1250     0.0     0.0  0.876729 -0.480985  \n",
              "1251     0.0     0.0  0.879331 -0.476211  \n",
              "1252     0.0     0.0  0.885523 -0.464595  \n",
              "1253     0.0     0.0  0.891796 -0.452439  \n",
              "1254     0.0     0.0  0.897377 -0.441265  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8af4d3f8-7dc6-4c2f-80ed-29580887f7de\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node_id</th>\n",
              "      <th>timestamp_secs</th>\n",
              "      <th>timestamp_nsecs</th>\n",
              "      <th>x_m</th>\n",
              "      <th>y_m</th>\n",
              "      <th>z_m</th>\n",
              "      <th>quat_x</th>\n",
              "      <th>quat_y</th>\n",
              "      <th>quat_z</th>\n",
              "      <th>quat_w</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1250</th>\n",
              "      <td>1250</td>\n",
              "      <td>1761175962</td>\n",
              "      <td>839079300</td>\n",
              "      <td>2.844030</td>\n",
              "      <td>6.390513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.876729</td>\n",
              "      <td>-0.480985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>1251</td>\n",
              "      <td>1761175963</td>\n",
              "      <td>632571600</td>\n",
              "      <td>2.768131</td>\n",
              "      <td>6.164998</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.879331</td>\n",
              "      <td>-0.476211</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>1252</td>\n",
              "      <td>1761175963</td>\n",
              "      <td>902584000</td>\n",
              "      <td>2.712850</td>\n",
              "      <td>6.092377</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.885523</td>\n",
              "      <td>-0.464595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>1253</td>\n",
              "      <td>1761175964</td>\n",
              "      <td>296024600</td>\n",
              "      <td>2.607575</td>\n",
              "      <td>6.054640</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.891796</td>\n",
              "      <td>-0.452439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>1254</td>\n",
              "      <td>1761175964</td>\n",
              "      <td>946802100</td>\n",
              "      <td>2.464423</td>\n",
              "      <td>6.084261</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.897377</td>\n",
              "      <td>-0.441265</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8af4d3f8-7dc6-4c2f-80ed-29580887f7de')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8af4d3f8-7dc6-4c2f-80ed-29580887f7de button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8af4d3f8-7dc6-4c2f-80ed-29580887f7de');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cb53bcc7-3e23-494e-8623-bf50e07db483\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cb53bcc7-3e23-494e-8623-bf50e07db483')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cb53bcc7-3e23-494e-8623-bf50e07db483 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_trajectory\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"node_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1250,\n        \"max\": 1254,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1251,\n          1254,\n          1252\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_secs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1761175962,\n        \"max\": 1761175964,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1761175962,\n          1761175963,\n          1761175964\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp_nsecs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 267533472,\n        \"min\": 296024600,\n        \"max\": 946802100,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          632571600,\n          946802100,\n          902584000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"x_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14787565764898658,\n        \"min\": 2.4644230479259615,\n        \"max\": 2.844029716407354,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2.7681307742840606,\n          2.4644230479259615,\n          2.7128498726957018\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1365068138733213,\n        \"min\": 6.054639640839576,\n        \"max\": 6.390513055851235,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          6.164997553031453,\n          6.084260885963391,\n          6.092376858831328\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"z_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_x\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_z\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008567025435687724,\n        \"min\": 0.8767285559104284,\n        \"max\": 0.8973770737621771,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.8793308651657276\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quat_w\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.016465742759486826,\n        \"min\": -0.4809854875681956,\n        \"max\": -0.44126453232276924,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          -0.4762113286839082\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "PBSTREAM_FILE = os.path.join(BASE_PATH, \"map.pbstream\")\n",
        "print(f\"Pbstream file: {PBSTREAM_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn11nyTK8h4p",
        "outputId": "f7409257-f1d5-49f2-a0a8-113ab228e19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç TIMESTAMP VERIFICATION\n",
            "\n",
            "Sample node (first):\n",
            "   timestamp_secs: 1761175578.0 (type: float64)\n",
            "   timestamp_nsecs: 341865800.0 (type: float64)\n",
            "   Readable: 2025-10-22 23:26:18.341\n",
            "\n",
            "‚úÖ Timestamps correctly formatted as (seconds, nanoseconds)\n"
          ]
        }
      ],
      "source": [
        "# Verify timestamp format\n",
        "print(\"üîç TIMESTAMP VERIFICATION\\n\")\n",
        "sample = df_trajectory.iloc[0]\n",
        "print(f\"Sample node (first):\")\n",
        "print(f\"   timestamp_secs: {sample['timestamp_secs']} (type: {type(sample['timestamp_secs']).__name__})\")\n",
        "print(f\"   timestamp_nsecs: {sample['timestamp_nsecs']} (type: {type(sample['timestamp_nsecs']).__name__})\")\n",
        "\n",
        "if sample['timestamp_secs'] is not None:\n",
        "    import datetime\n",
        "    dt = datetime.datetime.fromtimestamp(int(sample['timestamp_secs']))\n",
        "    nsecs = int(sample['timestamp_nsecs']) if sample['timestamp_nsecs'] is not None else 0\n",
        "    print(f\"   Readable: {dt.strftime('%Y-%m-%d %H:%M:%S')}.{nsecs//1000000:03d}\")\n",
        "    print(f\"\\n‚úÖ Timestamps correctly formatted as (seconds, nanoseconds)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mqaT5Sn8h4q",
        "outputId": "ecde728f-6a71-4a3c-ce3c-d62e97204c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä TRAJECTORY PROFILING (CONSECUTIVE NODES)\n",
            "\n",
            "\n",
            "üìà DESCRIPTIVE STATISTICS\n",
            "\n",
            "Distance Between Consecutive Nodes (meters):\n",
            "   Count:  1254\n",
            "   Min:    0.000845 m\n",
            "   Max:    6.828017 m\n",
            "   Mean:   0.058617 m\n",
            "   Median: 0.034281 m\n",
            "   Std:    0.199323 m\n",
            "\n",
            "Time Between Consecutive Nodes (seconds):\n",
            "   Count:  1254\n",
            "   Min:    0.114630 s\n",
            "   Max:    48.649355 s\n",
            "   Mean:   0.308297 s\n",
            "   Median: 0.135182 s\n",
            "   Std:    1.420958 s\n",
            "\n",
            "Trajectory Velocity Profile:\n",
            "   Mean velocity:   0.214999 m/s\n",
            "   Median velocity: 0.239200 m/s\n",
            "   Max velocity:    0.460624 m/s\n"
          ]
        }
      ],
      "source": [
        "# Trajectory profiling - consecutive nodes\n",
        "print(\"\\nüìä TRAJECTORY PROFILING (CONSECUTIVE NODES)\\n\")\n",
        "\n",
        "\n",
        "# Calculate distances and time differences between consecutive nodes\n",
        "consecutive_distances = []\n",
        "consecutive_times = []\n",
        "\n",
        "for i in range(len(df_trajectory) - 1):\n",
        "    node1 = df_trajectory.iloc[i]\n",
        "    node2 = df_trajectory.iloc[i + 1]\n",
        "\n",
        "    # Distance\n",
        "    dist = np.sqrt((node2['x_m'] - node1['x_m'])**2 + (node2['y_m'] - node1['y_m'])**2)\n",
        "    consecutive_distances.append(dist)\n",
        "\n",
        "    # Time difference\n",
        "    if node1['timestamp_secs'] is not None and node2['timestamp_secs'] is not None:\n",
        "        time_diff_ns = (\n",
        "            (node2['timestamp_secs'] - node1['timestamp_secs']) * 1_000_000_000 +\n",
        "            (node2['timestamp_nsecs'] - node1['timestamp_nsecs'])\n",
        "        )\n",
        "        time_diff_secs = time_diff_ns / 1_000_000_000\n",
        "        consecutive_times.append(time_diff_secs)\n",
        "\n",
        "consecutive_distances = np.array(consecutive_distances)\n",
        "consecutive_times = np.array(consecutive_times)\n",
        "\n",
        "\n",
        "# Statistics table\n",
        "print(\"\\nüìà DESCRIPTIVE STATISTICS\\n\")\n",
        "print(\"Distance Between Consecutive Nodes (meters):\")\n",
        "print(f\"   Count:  {len(consecutive_distances)}\")\n",
        "print(f\"   Min:    {consecutive_distances.min():.6f} m\")\n",
        "print(f\"   Max:    {consecutive_distances.max():.6f} m\")\n",
        "print(f\"   Mean:   {consecutive_distances.mean():.6f} m\")\n",
        "print(f\"   Median: {np.median(consecutive_distances):.6f} m\")\n",
        "print(f\"   Std:    {consecutive_distances.std():.6f} m\")\n",
        "\n",
        "print(\"\\nTime Between Consecutive Nodes (seconds):\")\n",
        "print(f\"   Count:  {len(consecutive_times)}\")\n",
        "print(f\"   Min:    {consecutive_times.min():.6f} s\")\n",
        "print(f\"   Max:    {consecutive_times.max():.6f} s\")\n",
        "print(f\"   Mean:   {consecutive_times.mean():.6f} s\")\n",
        "print(f\"   Median: {np.median(consecutive_times):.6f} s\")\n",
        "print(f\"   Std:    {consecutive_times.std():.6f} s\")\n",
        "\n",
        "print(\"\\nTrajectory Velocity Profile:\")\n",
        "velocities = consecutive_distances / consecutive_times\n",
        "print(f\"   Mean velocity:   {velocities.mean():.6f} m/s\")\n",
        "print(f\"   Median velocity: {np.median(velocities):.6f} m/s\")\n",
        "print(f\"   Max velocity:    {velocities.max():.6f} m/s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUsdg8pyHu_V"
      },
      "source": [
        "---\n",
        "# 3.5 NODE PAIRING\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bnJp7q9i8h4q",
        "outputId": "ba0347c2-99bf-4776-c7de-e953e2237ca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîó CREATING ALL NODE PAIRS...\n",
            "\n",
            "‚ö†Ô∏è  Creating ~786,885 pairs. Please wait...\n",
            "\n",
            "   Processing node 0/1255...\n",
            "   Processing node 100/1255...\n",
            "   Processing node 200/1255...\n",
            "   Processing node 300/1255...\n",
            "   Processing node 400/1255...\n",
            "   Processing node 500/1255...\n",
            "   Processing node 600/1255...\n",
            "   Processing node 700/1255...\n",
            "   Processing node 800/1255...\n",
            "   Processing node 900/1255...\n",
            "   Processing node 1000/1255...\n",
            "   Processing node 1100/1255...\n",
            "   Processing node 1200/1255...\n",
            "\n",
            "‚úÖ Created: 786,885 pairs\n",
            "\n",
            "üìä Statistics:\n",
            "   Distance - Min: 0.000406 m\n",
            "   Distance - Max: 8.700595 m\n",
            "   Distance - Mean: 3.006543 m\n",
            "   Time - Min: 0.11463 s\n",
            "   Time - Max: 386.60494 s\n",
            "   Loop closures: 0 (will be marked after extraction)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nüîó CREATING ALL NODE PAIRS...\\n\")\n",
        "print(\"‚ö†Ô∏è  Creating ~786,885 pairs. Please wait...\\n\")\n",
        "\n",
        "node_pairs_data = []\n",
        "n_nodes = len(df_trajectory)\n",
        "\n",
        "for i in range(n_nodes):\n",
        "    if i % 100 == 0:\n",
        "        print(f\"   Processing node {i}/{n_nodes}...\")\n",
        "\n",
        "    node1 = df_trajectory.iloc[i]\n",
        "\n",
        "    for j in range(i + 1, n_nodes):\n",
        "        node2 = df_trajectory.iloc[j]\n",
        "\n",
        "        distance = np.sqrt((node2['x_m'] - node1['x_m'])**2 + (node2['y_m'] - node1['y_m'])**2)\n",
        "\n",
        "        time_diff_secs = 0.0\n",
        "        if node1['timestamp_secs'] is not None and node2['timestamp_secs'] is not None:\n",
        "            time_diff_ns = (\n",
        "                (node2['timestamp_secs'] - node1['timestamp_secs']) * 1_000_000_000 +\n",
        "                (node2['timestamp_nsecs'] - node1['timestamp_nsecs'])\n",
        "            )\n",
        "            time_diff_secs = round(time_diff_ns / 1_000_000_000, 5)\n",
        "\n",
        "        node_pairs_data.append({\n",
        "            'node1_id': i,\n",
        "            'node2_id': j,\n",
        "            'distance_between_nodes_m': distance,\n",
        "            'time_diff_secs': time_diff_secs,\n",
        "            'loop_closure': 0  # Initialize to 0, will be marked during loop closure extraction\n",
        "        })\n",
        "\n",
        "df_all_pairs = pd.DataFrame(node_pairs_data)\n",
        "\n",
        "print(f\"\\n‚úÖ Created: {len(df_all_pairs):,} pairs\\n\")\n",
        "print(f\"üìä Statistics:\")\n",
        "print(f\"   Distance - Min: {df_all_pairs['distance_between_nodes_m'].min():.6f} m\")\n",
        "print(f\"   Distance - Max: {df_all_pairs['distance_between_nodes_m'].max():.6f} m\")\n",
        "print(f\"   Distance - Mean: {df_all_pairs['distance_between_nodes_m'].mean():.6f} m\")\n",
        "print(f\"   Time - Min: {df_all_pairs['time_diff_secs'].min():.5f} s\")\n",
        "print(f\"   Time - Max: {df_all_pairs['time_diff_secs'].max():.5f} s\")\n",
        "print(f\"   Loop closures: 0 (will be marked after extraction)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdnNN-cP8h4r"
      },
      "source": [
        "---\n",
        "# 3.5 LOOP CLOSURE EXTRACTION AND ANALYSIS\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txL1YdOE8h4r",
        "outputId": "c411fc1a-df0f-43eb-93ba-fc78c63a628f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîó EXTRACTING LOOP CLOSURES (ORIGINAL ALGORITHM)...\n",
            "\n",
            "‚úÖ Loop closures extracted: 406 pairs\n",
            "   Total INTER_SUBMAP constraints: 805\n",
            "   Submaps tracked: 35\n",
            "   Trajectory nodes: 1255\n"
          ]
        }
      ],
      "source": [
        "PBSTREAM_FILE = os.path.join(BASE_PATH, \"map.pbstream\")\n",
        "print(f\"Pbstream file: {PBSTREAM_FILE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uNwd8xul8h4r",
        "outputId": "e6975a22-20b1-4348-9b39-f0b4862e2e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîó MARKING LOOP CLOSURES IN NODE PAIRS...\n",
            "\n",
            "‚úÖ Marked: 406 loop closure pairs in df_all_pairs\n",
            "   Total pairs: 786,885\n",
            "   Loop closures: 406 (0.052%)\n",
            "\n",
            "üìã First 50 loop closure pairs:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        node1_id  node2_id  distance_between_nodes_m  time_diff_secs\n",
              "45429         36       952                  0.025163       237.91770\n",
              "45434         36       957                  0.013182       244.09490\n",
              "50363         40      1024                  0.078557       262.64145\n",
              "51537         41       985                  0.067171       248.17507\n",
              "51547         41       995                  0.063022       249.76031\n",
              "51581         41      1029                  0.029172       262.91324\n",
              "60649         49       429                  0.094426        98.35462\n",
              "63671         51      1044                  0.360064       263.16983\n",
              "65657         53       627                  0.078664       146.90694\n",
              "67864         55       435                  0.094407        98.50267\n",
              "68874         56       247                  0.198422        49.07907\n",
              "73851         60       442                  0.069514        98.63810\n",
              "74044         60       635                  0.097650       147.16472\n",
              "75238         61       636                  0.096974       147.04208\n",
              "75239         61       637                  0.091625       147.17722\n",
              "77430         63       445                  0.024564        98.51538\n",
              "81001         66       449                  0.048437        98.64747\n",
              "82001         67       262                  0.037447        49.22663\n",
              "85557         70       263                  0.109919        48.97313\n",
              "85561         70       267                  0.133205        49.50153\n",
              "85742         70       448                  0.182286        97.85506\n",
              "85939         70       645                  0.010903       147.31727\n",
              "86353         70      1059                  0.717473       261.33261\n",
              "86745         71       268                  0.157575        49.50842\n",
              "88305         72       646                  0.011332       147.30623\n",
              "89296         73       456                  0.019861        98.65058\n",
              "89487         73       647                  0.015480       147.31240\n",
              "90477         74       457                  0.052301        98.52904\n",
              "92836         76       459                  0.070334        98.51378\n",
              "95002         78       272                  0.172128        48.98918\n",
              "95191         78       461                  0.076468        98.52379\n",
              "96559         79       654                  0.063418       147.44454\n",
              "97356         80       277                  0.166131        48.72458\n",
              "97545         80       466                  0.065700        98.39395\n",
              "97734         80       655                  0.066488       146.93325\n",
              "97735         80       656                  0.027588       147.19111\n",
              "97736         80       657                  0.118051       147.59638\n",
              "98148         80      1069                  0.820575       260.28510\n",
              "98151         80      1072                  0.882716       260.67824\n",
              "98531         81       279                  0.261199        49.00746\n",
              "98719         81       467                  0.130237        98.40661\n",
              "105250        86      1148                  5.202004       318.50042\n",
              "105931        87       662                  0.167478       147.06707\n",
              "109238        90       474                  0.149006        98.39252\n",
              "112532        93       282                  0.197458        48.62412\n",
              "112913        93       663                  0.144357       146.81109\n",
              "114852        95       283                  0.191332        48.76164\n",
              "118324        98       284                  0.108670        48.77454\n",
              "118517        98       477                  0.152905        98.39234\n",
              "119861        99       666                  0.183138       147.48421"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-17efc97a-db9d-4061-ae07-acb0706c6781\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node1_id</th>\n",
              "      <th>node2_id</th>\n",
              "      <th>distance_between_nodes_m</th>\n",
              "      <th>time_diff_secs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>45429</th>\n",
              "      <td>36</td>\n",
              "      <td>952</td>\n",
              "      <td>0.025163</td>\n",
              "      <td>237.91770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45434</th>\n",
              "      <td>36</td>\n",
              "      <td>957</td>\n",
              "      <td>0.013182</td>\n",
              "      <td>244.09490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50363</th>\n",
              "      <td>40</td>\n",
              "      <td>1024</td>\n",
              "      <td>0.078557</td>\n",
              "      <td>262.64145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51537</th>\n",
              "      <td>41</td>\n",
              "      <td>985</td>\n",
              "      <td>0.067171</td>\n",
              "      <td>248.17507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51547</th>\n",
              "      <td>41</td>\n",
              "      <td>995</td>\n",
              "      <td>0.063022</td>\n",
              "      <td>249.76031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51581</th>\n",
              "      <td>41</td>\n",
              "      <td>1029</td>\n",
              "      <td>0.029172</td>\n",
              "      <td>262.91324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60649</th>\n",
              "      <td>49</td>\n",
              "      <td>429</td>\n",
              "      <td>0.094426</td>\n",
              "      <td>98.35462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63671</th>\n",
              "      <td>51</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.360064</td>\n",
              "      <td>263.16983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65657</th>\n",
              "      <td>53</td>\n",
              "      <td>627</td>\n",
              "      <td>0.078664</td>\n",
              "      <td>146.90694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67864</th>\n",
              "      <td>55</td>\n",
              "      <td>435</td>\n",
              "      <td>0.094407</td>\n",
              "      <td>98.50267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68874</th>\n",
              "      <td>56</td>\n",
              "      <td>247</td>\n",
              "      <td>0.198422</td>\n",
              "      <td>49.07907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73851</th>\n",
              "      <td>60</td>\n",
              "      <td>442</td>\n",
              "      <td>0.069514</td>\n",
              "      <td>98.63810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74044</th>\n",
              "      <td>60</td>\n",
              "      <td>635</td>\n",
              "      <td>0.097650</td>\n",
              "      <td>147.16472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75238</th>\n",
              "      <td>61</td>\n",
              "      <td>636</td>\n",
              "      <td>0.096974</td>\n",
              "      <td>147.04208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75239</th>\n",
              "      <td>61</td>\n",
              "      <td>637</td>\n",
              "      <td>0.091625</td>\n",
              "      <td>147.17722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77430</th>\n",
              "      <td>63</td>\n",
              "      <td>445</td>\n",
              "      <td>0.024564</td>\n",
              "      <td>98.51538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81001</th>\n",
              "      <td>66</td>\n",
              "      <td>449</td>\n",
              "      <td>0.048437</td>\n",
              "      <td>98.64747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82001</th>\n",
              "      <td>67</td>\n",
              "      <td>262</td>\n",
              "      <td>0.037447</td>\n",
              "      <td>49.22663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85557</th>\n",
              "      <td>70</td>\n",
              "      <td>263</td>\n",
              "      <td>0.109919</td>\n",
              "      <td>48.97313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85561</th>\n",
              "      <td>70</td>\n",
              "      <td>267</td>\n",
              "      <td>0.133205</td>\n",
              "      <td>49.50153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85742</th>\n",
              "      <td>70</td>\n",
              "      <td>448</td>\n",
              "      <td>0.182286</td>\n",
              "      <td>97.85506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85939</th>\n",
              "      <td>70</td>\n",
              "      <td>645</td>\n",
              "      <td>0.010903</td>\n",
              "      <td>147.31727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86353</th>\n",
              "      <td>70</td>\n",
              "      <td>1059</td>\n",
              "      <td>0.717473</td>\n",
              "      <td>261.33261</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86745</th>\n",
              "      <td>71</td>\n",
              "      <td>268</td>\n",
              "      <td>0.157575</td>\n",
              "      <td>49.50842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88305</th>\n",
              "      <td>72</td>\n",
              "      <td>646</td>\n",
              "      <td>0.011332</td>\n",
              "      <td>147.30623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89296</th>\n",
              "      <td>73</td>\n",
              "      <td>456</td>\n",
              "      <td>0.019861</td>\n",
              "      <td>98.65058</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89487</th>\n",
              "      <td>73</td>\n",
              "      <td>647</td>\n",
              "      <td>0.015480</td>\n",
              "      <td>147.31240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90477</th>\n",
              "      <td>74</td>\n",
              "      <td>457</td>\n",
              "      <td>0.052301</td>\n",
              "      <td>98.52904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92836</th>\n",
              "      <td>76</td>\n",
              "      <td>459</td>\n",
              "      <td>0.070334</td>\n",
              "      <td>98.51378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95002</th>\n",
              "      <td>78</td>\n",
              "      <td>272</td>\n",
              "      <td>0.172128</td>\n",
              "      <td>48.98918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95191</th>\n",
              "      <td>78</td>\n",
              "      <td>461</td>\n",
              "      <td>0.076468</td>\n",
              "      <td>98.52379</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96559</th>\n",
              "      <td>79</td>\n",
              "      <td>654</td>\n",
              "      <td>0.063418</td>\n",
              "      <td>147.44454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97356</th>\n",
              "      <td>80</td>\n",
              "      <td>277</td>\n",
              "      <td>0.166131</td>\n",
              "      <td>48.72458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97545</th>\n",
              "      <td>80</td>\n",
              "      <td>466</td>\n",
              "      <td>0.065700</td>\n",
              "      <td>98.39395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97734</th>\n",
              "      <td>80</td>\n",
              "      <td>655</td>\n",
              "      <td>0.066488</td>\n",
              "      <td>146.93325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97735</th>\n",
              "      <td>80</td>\n",
              "      <td>656</td>\n",
              "      <td>0.027588</td>\n",
              "      <td>147.19111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97736</th>\n",
              "      <td>80</td>\n",
              "      <td>657</td>\n",
              "      <td>0.118051</td>\n",
              "      <td>147.59638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98148</th>\n",
              "      <td>80</td>\n",
              "      <td>1069</td>\n",
              "      <td>0.820575</td>\n",
              "      <td>260.28510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98151</th>\n",
              "      <td>80</td>\n",
              "      <td>1072</td>\n",
              "      <td>0.882716</td>\n",
              "      <td>260.67824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98531</th>\n",
              "      <td>81</td>\n",
              "      <td>279</td>\n",
              "      <td>0.261199</td>\n",
              "      <td>49.00746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98719</th>\n",
              "      <td>81</td>\n",
              "      <td>467</td>\n",
              "      <td>0.130237</td>\n",
              "      <td>98.40661</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105250</th>\n",
              "      <td>86</td>\n",
              "      <td>1148</td>\n",
              "      <td>5.202004</td>\n",
              "      <td>318.50042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105931</th>\n",
              "      <td>87</td>\n",
              "      <td>662</td>\n",
              "      <td>0.167478</td>\n",
              "      <td>147.06707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109238</th>\n",
              "      <td>90</td>\n",
              "      <td>474</td>\n",
              "      <td>0.149006</td>\n",
              "      <td>98.39252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112532</th>\n",
              "      <td>93</td>\n",
              "      <td>282</td>\n",
              "      <td>0.197458</td>\n",
              "      <td>48.62412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112913</th>\n",
              "      <td>93</td>\n",
              "      <td>663</td>\n",
              "      <td>0.144357</td>\n",
              "      <td>146.81109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114852</th>\n",
              "      <td>95</td>\n",
              "      <td>283</td>\n",
              "      <td>0.191332</td>\n",
              "      <td>48.76164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118324</th>\n",
              "      <td>98</td>\n",
              "      <td>284</td>\n",
              "      <td>0.108670</td>\n",
              "      <td>48.77454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118517</th>\n",
              "      <td>98</td>\n",
              "      <td>477</td>\n",
              "      <td>0.152905</td>\n",
              "      <td>98.39234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119861</th>\n",
              "      <td>99</td>\n",
              "      <td>666</td>\n",
              "      <td>0.183138</td>\n",
              "      <td>147.48421</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-17efc97a-db9d-4061-ae07-acb0706c6781')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-17efc97a-db9d-4061-ae07-acb0706c6781 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-17efc97a-db9d-4061-ae07-acb0706c6781');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b2d702af-91ca-4e37-800a-2cef836c3d5f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b2d702af-91ca-4e37-800a-2cef836c3d5f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b2d702af-91ca-4e37-800a-2cef836c3d5f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_loop_closures\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"node1_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16,\n        \"min\": 36,\n        \"max\": 99,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          95,\n          72,\n          86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node2_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 270,\n        \"min\": 247,\n        \"max\": 1148,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          636,\n          279,\n          461\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance_between_nodes_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7380101863015873,\n        \"min\": 0.010902883941023582,\n        \"max\": 5.202004362406658,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.09697376429439755,\n          0.26119877107035677,\n          0.07646784701744683\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_diff_secs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 75.67379064245299,\n        \"min\": 48.62412,\n        \"max\": 318.50042,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          147.04208,\n          49.00746,\n          98.52379\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìã Last 50 loop closure pairs:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        node1_id  node2_id  distance_between_nodes_m  time_diff_secs\n",
              "498333       494      1123                  0.648006       162.22162\n",
              "500166       497       682                  0.021054        48.61333\n",
              "506952       506       700                  0.079983        48.90823\n",
              "515861       518       711                  0.084424        48.42704\n",
              "516297       518      1147                  0.742233       158.84519\n",
              "521716       526       714                  0.008323        48.83842\n",
              "526070       532       721                  0.055232        48.95663\n",
              "528233       535       724                  0.048300        49.09719\n",
              "528952       536       725                  0.053394        49.10431\n",
              "531103       539       728                  0.098109        48.72318\n",
              "531818       540       729                  0.088507        49.12889\n",
              "533956       543       731                  0.084029        48.87088\n",
              "534667       544       732                  0.078900        48.87062\n",
              "545889       560       730                  0.699440        46.37508\n",
              "545897       560       738                  0.482160        47.44061\n",
              "546594       561       742                  0.081667        49.29675\n",
              "547287       562       743                  0.091015        49.28337\n",
              "550057       566       755                  0.100182        51.42576\n",
              "550058       566       756                  0.073827        52.47469\n",
              "552123       569       763                  0.090692        53.00424\n",
              "552808       570       764                  0.111626        53.01881\n",
              "557605       577       801                  0.370603        56.64059\n",
              "558292       578       812                  0.554819        57.84947\n",
              "558297       578       817                  0.531422        59.57777\n",
              "558302       578       822                  0.451463        63.02933\n",
              "558304       578       824                  0.447873        63.29949\n",
              "558974       579       819                  0.556349        59.85145\n",
              "558982       579       827                  0.560882        64.08821\n",
              "561690       583       845                  0.268263        64.53027\n",
              "561691       583       846                  0.283611        64.66540\n",
              "562362       584       847                  0.282977        64.00607\n",
              "567036       591       859                  0.127793        70.79493\n",
              "567771       592       932                  0.092415        90.35587\n",
              "567773       592       934                  0.058462        90.61523\n",
              "567775       592       936                  0.053986        91.00835\n",
              "569680       595       861                  0.604445        71.21203\n",
              "580825       612       956                  0.170523        92.44732\n",
              "587853       623       988                  0.093571       101.64717\n",
              "587864       623       999                  0.097097       107.70222\n",
              "588461       624       966                  0.139092        98.49131\n",
              "592283       630      1029                  0.866901       112.57608\n",
              "592298       630      1044                  0.559051       114.94716\n",
              "606478       653      1148                  5.319178       173.82006\n",
              "608796       657      1072                  0.822279       113.08187\n",
              "619421       675      1122                  0.725462       113.75736\n",
              "625733       686      1131                  0.634463       112.70115\n",
              "627444       689      1144                  0.706061       114.28548\n",
              "627445       689      1145                  0.731401       114.42087\n",
              "639624       711      1147                  0.724120       110.41815\n",
              "783794      1175      1245                  0.052230        23.12631"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c083a988-4de2-4be5-b630-953bc836ea1c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>node1_id</th>\n",
              "      <th>node2_id</th>\n",
              "      <th>distance_between_nodes_m</th>\n",
              "      <th>time_diff_secs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>498333</th>\n",
              "      <td>494</td>\n",
              "      <td>1123</td>\n",
              "      <td>0.648006</td>\n",
              "      <td>162.22162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500166</th>\n",
              "      <td>497</td>\n",
              "      <td>682</td>\n",
              "      <td>0.021054</td>\n",
              "      <td>48.61333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506952</th>\n",
              "      <td>506</td>\n",
              "      <td>700</td>\n",
              "      <td>0.079983</td>\n",
              "      <td>48.90823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515861</th>\n",
              "      <td>518</td>\n",
              "      <td>711</td>\n",
              "      <td>0.084424</td>\n",
              "      <td>48.42704</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516297</th>\n",
              "      <td>518</td>\n",
              "      <td>1147</td>\n",
              "      <td>0.742233</td>\n",
              "      <td>158.84519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521716</th>\n",
              "      <td>526</td>\n",
              "      <td>714</td>\n",
              "      <td>0.008323</td>\n",
              "      <td>48.83842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526070</th>\n",
              "      <td>532</td>\n",
              "      <td>721</td>\n",
              "      <td>0.055232</td>\n",
              "      <td>48.95663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528233</th>\n",
              "      <td>535</td>\n",
              "      <td>724</td>\n",
              "      <td>0.048300</td>\n",
              "      <td>49.09719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528952</th>\n",
              "      <td>536</td>\n",
              "      <td>725</td>\n",
              "      <td>0.053394</td>\n",
              "      <td>49.10431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531103</th>\n",
              "      <td>539</td>\n",
              "      <td>728</td>\n",
              "      <td>0.098109</td>\n",
              "      <td>48.72318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531818</th>\n",
              "      <td>540</td>\n",
              "      <td>729</td>\n",
              "      <td>0.088507</td>\n",
              "      <td>49.12889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533956</th>\n",
              "      <td>543</td>\n",
              "      <td>731</td>\n",
              "      <td>0.084029</td>\n",
              "      <td>48.87088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534667</th>\n",
              "      <td>544</td>\n",
              "      <td>732</td>\n",
              "      <td>0.078900</td>\n",
              "      <td>48.87062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545889</th>\n",
              "      <td>560</td>\n",
              "      <td>730</td>\n",
              "      <td>0.699440</td>\n",
              "      <td>46.37508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545897</th>\n",
              "      <td>560</td>\n",
              "      <td>738</td>\n",
              "      <td>0.482160</td>\n",
              "      <td>47.44061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546594</th>\n",
              "      <td>561</td>\n",
              "      <td>742</td>\n",
              "      <td>0.081667</td>\n",
              "      <td>49.29675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547287</th>\n",
              "      <td>562</td>\n",
              "      <td>743</td>\n",
              "      <td>0.091015</td>\n",
              "      <td>49.28337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550057</th>\n",
              "      <td>566</td>\n",
              "      <td>755</td>\n",
              "      <td>0.100182</td>\n",
              "      <td>51.42576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550058</th>\n",
              "      <td>566</td>\n",
              "      <td>756</td>\n",
              "      <td>0.073827</td>\n",
              "      <td>52.47469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552123</th>\n",
              "      <td>569</td>\n",
              "      <td>763</td>\n",
              "      <td>0.090692</td>\n",
              "      <td>53.00424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552808</th>\n",
              "      <td>570</td>\n",
              "      <td>764</td>\n",
              "      <td>0.111626</td>\n",
              "      <td>53.01881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557605</th>\n",
              "      <td>577</td>\n",
              "      <td>801</td>\n",
              "      <td>0.370603</td>\n",
              "      <td>56.64059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558292</th>\n",
              "      <td>578</td>\n",
              "      <td>812</td>\n",
              "      <td>0.554819</td>\n",
              "      <td>57.84947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558297</th>\n",
              "      <td>578</td>\n",
              "      <td>817</td>\n",
              "      <td>0.531422</td>\n",
              "      <td>59.57777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558302</th>\n",
              "      <td>578</td>\n",
              "      <td>822</td>\n",
              "      <td>0.451463</td>\n",
              "      <td>63.02933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558304</th>\n",
              "      <td>578</td>\n",
              "      <td>824</td>\n",
              "      <td>0.447873</td>\n",
              "      <td>63.29949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558974</th>\n",
              "      <td>579</td>\n",
              "      <td>819</td>\n",
              "      <td>0.556349</td>\n",
              "      <td>59.85145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558982</th>\n",
              "      <td>579</td>\n",
              "      <td>827</td>\n",
              "      <td>0.560882</td>\n",
              "      <td>64.08821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561690</th>\n",
              "      <td>583</td>\n",
              "      <td>845</td>\n",
              "      <td>0.268263</td>\n",
              "      <td>64.53027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561691</th>\n",
              "      <td>583</td>\n",
              "      <td>846</td>\n",
              "      <td>0.283611</td>\n",
              "      <td>64.66540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562362</th>\n",
              "      <td>584</td>\n",
              "      <td>847</td>\n",
              "      <td>0.282977</td>\n",
              "      <td>64.00607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567036</th>\n",
              "      <td>591</td>\n",
              "      <td>859</td>\n",
              "      <td>0.127793</td>\n",
              "      <td>70.79493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567771</th>\n",
              "      <td>592</td>\n",
              "      <td>932</td>\n",
              "      <td>0.092415</td>\n",
              "      <td>90.35587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567773</th>\n",
              "      <td>592</td>\n",
              "      <td>934</td>\n",
              "      <td>0.058462</td>\n",
              "      <td>90.61523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567775</th>\n",
              "      <td>592</td>\n",
              "      <td>936</td>\n",
              "      <td>0.053986</td>\n",
              "      <td>91.00835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>569680</th>\n",
              "      <td>595</td>\n",
              "      <td>861</td>\n",
              "      <td>0.604445</td>\n",
              "      <td>71.21203</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>580825</th>\n",
              "      <td>612</td>\n",
              "      <td>956</td>\n",
              "      <td>0.170523</td>\n",
              "      <td>92.44732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587853</th>\n",
              "      <td>623</td>\n",
              "      <td>988</td>\n",
              "      <td>0.093571</td>\n",
              "      <td>101.64717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>587864</th>\n",
              "      <td>623</td>\n",
              "      <td>999</td>\n",
              "      <td>0.097097</td>\n",
              "      <td>107.70222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>588461</th>\n",
              "      <td>624</td>\n",
              "      <td>966</td>\n",
              "      <td>0.139092</td>\n",
              "      <td>98.49131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592283</th>\n",
              "      <td>630</td>\n",
              "      <td>1029</td>\n",
              "      <td>0.866901</td>\n",
              "      <td>112.57608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>592298</th>\n",
              "      <td>630</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.559051</td>\n",
              "      <td>114.94716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606478</th>\n",
              "      <td>653</td>\n",
              "      <td>1148</td>\n",
              "      <td>5.319178</td>\n",
              "      <td>173.82006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608796</th>\n",
              "      <td>657</td>\n",
              "      <td>1072</td>\n",
              "      <td>0.822279</td>\n",
              "      <td>113.08187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>619421</th>\n",
              "      <td>675</td>\n",
              "      <td>1122</td>\n",
              "      <td>0.725462</td>\n",
              "      <td>113.75736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>625733</th>\n",
              "      <td>686</td>\n",
              "      <td>1131</td>\n",
              "      <td>0.634463</td>\n",
              "      <td>112.70115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627444</th>\n",
              "      <td>689</td>\n",
              "      <td>1144</td>\n",
              "      <td>0.706061</td>\n",
              "      <td>114.28548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627445</th>\n",
              "      <td>689</td>\n",
              "      <td>1145</td>\n",
              "      <td>0.731401</td>\n",
              "      <td>114.42087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>639624</th>\n",
              "      <td>711</td>\n",
              "      <td>1147</td>\n",
              "      <td>0.724120</td>\n",
              "      <td>110.41815</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>783794</th>\n",
              "      <td>1175</td>\n",
              "      <td>1245</td>\n",
              "      <td>0.052230</td>\n",
              "      <td>23.12631</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c083a988-4de2-4be5-b630-953bc836ea1c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c083a988-4de2-4be5-b630-953bc836ea1c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c083a988-4de2-4be5-b630-953bc836ea1c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a02b6c0e-087a-47e2-9aaf-fa7392f33cb5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a02b6c0e-087a-47e2-9aaf-fa7392f33cb5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a02b6c0e-087a-47e2-9aaf-fa7392f33cb5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_loop_closures\",\n  \"rows\": 50,\n  \"fields\": [\n    {\n      \"column\": \"node1_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 98,\n        \"min\": 494,\n        \"max\": 1175,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          570,\n          561,\n          526\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"node2_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 160,\n        \"min\": 682,\n        \"max\": 1245,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          730,\n          1131,\n          1145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance_between_nodes_m\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7585606984868654,\n        \"min\": 0.008322563607331183,\n        \"max\": 5.319177885442601,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          0.6994399644712201,\n          0.13909174537195537,\n          0.28297694320034056\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"time_diff_secs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 33.94700441111481,\n        \"min\": 23.12631,\n        \"max\": 173.82006,\n        \"num_unique_values\": 50,\n        \"samples\": [\n          46.37508,\n          98.49131,\n          64.00607\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Mark loop closures in df_all_pairs\n",
        "print(\"\\nüîó MARKING LOOP CLOSURES IN NODE PAIRS...\\n\")\n",
        "\n",
        "marked_count = 0\n",
        "\n",
        "for ref_idx, node_idx in loop_closure_pairs:\n",
        "    if ref_idx < len(df_trajectory) and node_idx < len(df_trajectory):\n",
        "        # Find the pair in df_all_pairs and mark it\n",
        "        mask = (df_all_pairs['node1_id'] == ref_idx) & (df_all_pairs['node2_id'] == node_idx)\n",
        "        if mask.any():\n",
        "            df_all_pairs.loc[mask, 'loop_closure'] = 1\n",
        "            marked_count += 1\n",
        "\n",
        "print(f\"‚úÖ Marked: {marked_count} loop closure pairs in df_all_pairs\")\n",
        "print(f\"   Total pairs: {len(df_all_pairs):,}\")\n",
        "print(f\"   Loop closures: {df_all_pairs['loop_closure'].sum()} ({100*df_all_pairs['loop_closure'].sum()/len(df_all_pairs):.3f}%)\")\n",
        "\n",
        "# Create filtered view for display\n",
        "df_loop_closures = df_all_pairs[df_all_pairs['loop_closure'] == 1][['node1_id', 'node2_id', 'distance_between_nodes_m', 'time_diff_secs']].copy()\n",
        "\n",
        "print(f\"\\nüìã First 50 loop closure pairs:\")\n",
        "display(df_loop_closures.head(50))\n",
        "print(f\"\\nüìã Last 50 loop closure pairs:\")\n",
        "display(df_loop_closures.tail(50))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_4"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 4: FEATURES LOADING & ANALYSIS\n",
        "\n",
        "HDF5 features validation.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_features"
      },
      "source": [
        "### 4.1 FILE LOADING AND VALIDATION\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load_features_code"
      },
      "outputs": [],
      "source": [
        "print(\"Loading extracted features from HDF5...\")\n",
        "\n",
        "with h5py.File(FEATURES_FILE, 'r') as f:\n",
        "    # Load camera features and split timestamps\n",
        "    camera_features = f['camera/features'][:]\n",
        "    camera_timestamps_sec = f['camera/timestamps_sec'][:].astype(np.int64)\n",
        "    camera_timestamps_nsec = f['camera/timestamps_nsec'][:].astype(np.int32)\n",
        "    camera_filenames = [fn.decode('utf-8') if isinstance(fn, bytes) else fn\n",
        "                       for fn in f['camera/filenames'][:]]\n",
        "\n",
        "    # Load LiDAR features and split timestamps\n",
        "    lidar_features = f['lidar/features'][:]\n",
        "    lidar_timestamps_sec = f['lidar/timestamps_sec'][:].astype(np.int64)\n",
        "    lidar_timestamps_nsec = f['lidar/timestamps_nsec'][:].astype(np.int32)\n",
        "    lidar_filenames = [fn.decode('utf-8') if isinstance(fn, bytes) else fn\n",
        "                      for fn in f['lidar/filenames'][:]]\n",
        "\n",
        "# Create float64 timestamps for convenience (temporal operations)\n",
        "# Note: float64 loses ~250ns precision, but this is negligible vs ¬±0.5s alignment threshold\n",
        "camera_timestamps = camera_timestamps_sec + camera_timestamps_nsec * 1e-9\n",
        "lidar_timestamps = lidar_timestamps_sec + lidar_timestamps_nsec * 1e-9\n",
        "\n",
        "print(f\"\\n‚úÖ Features loaded successfully:\")\n",
        "print(f\"   Camera: {len(camera_features)} frames, {camera_features.shape[1]}D features\")\n",
        "print(f\"   LiDAR: {len(lidar_features)} scans, {lidar_features.shape[1]}D features\")\n",
        "print(f\"   Time range: {min(min(camera_timestamps), min(lidar_timestamps)):.2f}s to {max(max(camera_timestamps), max(lidar_timestamps)):.2f}s\")\n",
        "\n",
        "# Verify L2 normalization\n",
        "camera_norms = np.linalg.norm(camera_features, axis=1)\n",
        "lidar_norms = np.linalg.norm(lidar_features, axis=1)\n",
        "print(f\"\\n Feature normalization check:\")\n",
        "print(f\"   Camera L2 norms: mean={camera_norms.mean():.4f}, std={camera_norms.std():.4f}\")\n",
        "print(f\"   LiDAR L2 norms: mean={lidar_norms.mean():.4f}, std={lidar_norms.std():.4f}\")\n",
        "\n",
        "if not (np.allclose(camera_norms, 1.0, atol=1e-5) and np.allclose(lidar_norms, 1.0, atol=1e-5)):\n",
        "    print(\"   ‚ö†Ô∏è WARNING: Features are not properly L2 normalized!\")\n",
        "else:\n",
        "    print(\"   ‚úÖ Features are properly L2 normalized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5_analysis_title"
      },
      "source": [
        "### 4.2 H5 DATA ANALYSIS\n",
        "\n",
        "**Purpose:** Deep analysis and validation of extracted features before proceeding with dataset generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5_analysis_code"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"COMPREHENSIVE HDF5 DATA ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# =======================================================================\n",
        "#  Basic Statistics\n",
        "# =======================================================================\n",
        "print(\"\\n BASIC FEATURE STATISTICS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\n Camera Features:\")\n",
        "print(f\"   Count: {len(camera_features)} frames\")\n",
        "print(f\"   Dimension: {camera_features.shape[1]}D\")\n",
        "print(f\"   Data type: {camera_features.dtype}\")\n",
        "print(f\"   Memory: {camera_features.nbytes / 1024 / 1024:.2f} MB\")\n",
        "print(f\"   Value range: [{camera_features.min():.4f}, {camera_features.max():.4f}]\")\n",
        "print(f\"   Mean: {camera_features.mean():.4f}, Std: {camera_features.std():.4f}\")\n",
        "\n",
        "print(f\"\\n LiDAR Features:\")\n",
        "print(f\"   Count: {len(lidar_features)} scans\")\n",
        "print(f\"   Dimension: {lidar_features.shape[1]}D\")\n",
        "print(f\"   Data type: {lidar_features.dtype}\")\n",
        "print(f\"   Memory: {lidar_features.nbytes / 1024 / 1024:.2f} MB\")\n",
        "print(f\"   Value range: [{lidar_features.min():.4f}, {lidar_features.max():.4f}]\")\n",
        "print(f\"   Mean: {lidar_features.mean():.4f}, Std: {lidar_features.std():.4f}\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Timestamp Analysis\n",
        "# =======================================================================\n",
        "print(f\"\\n\\n‚è±Ô∏è  TIMESTAMP ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\n Camera Timestamps:\")\n",
        "cam_duration = camera_timestamps[-1] - camera_timestamps[0]\n",
        "cam_intervals = np.diff(camera_timestamps)\n",
        "print(f\"   Time range: {camera_timestamps[0]:.3f}s to {camera_timestamps[-1]:.3f}s\")\n",
        "print(f\"   Duration: {cam_duration:.2f}s ({cam_duration/60:.2f} minutes)\")\n",
        "print(f\"   Intervals - Mean: {cam_intervals.mean():.3f}s, Std: {cam_intervals.std():.3f}s\")\n",
        "print(f\"   Intervals - Min: {cam_intervals.min():.3f}s, Max: {cam_intervals.max():.3f}s\")\n",
        "print(f\"   Effective rate: {len(camera_features) / cam_duration:.2f} Hz\")\n",
        "\n",
        "print(f\"\\n LiDAR Timestamps:\")\n",
        "lid_duration = lidar_timestamps[-1] - lidar_timestamps[0]\n",
        "lid_intervals = np.diff(lidar_timestamps)\n",
        "print(f\"   Time range: {lidar_timestamps[0]:.3f}s to {lidar_timestamps[-1]:.3f}s\")\n",
        "print(f\"   Duration: {lid_duration:.2f}s ({lid_duration/60:.2f} minutes)\")\n",
        "print(f\"   Intervals - Mean: {lid_intervals.mean():.3f}s, Std: {lid_intervals.std():.3f}s\")\n",
        "print(f\"   Intervals - Min: {lid_intervals.min():.3f}s, Max: {lid_intervals.max():.3f}s\")\n",
        "print(f\"   Effective rate: {len(lidar_features) / lid_duration:.2f} Hz\")\n",
        "\n",
        "# Temporal overlap\n",
        "cam_start, cam_end = camera_timestamps[0], camera_timestamps[-1]\n",
        "lid_start, lid_end = lidar_timestamps[0], lidar_timestamps[-1]\n",
        "overlap_start = max(cam_start, lid_start)\n",
        "overlap_end = min(cam_end, lid_end)\n",
        "overlap_duration = max(0, overlap_end - overlap_start)\n",
        "\n",
        "print(f\"\\n Cross-Modal Temporal Analysis:\")\n",
        "print(f\"   Camera starts: {cam_start:.3f}s, ends: {cam_end:.3f}s\")\n",
        "print(f\"   LiDAR starts: {lid_start:.3f}s, ends: {lid_end:.3f}s\")\n",
        "print(f\"   Temporal overlap: {overlap_duration:.2f}s ({overlap_duration/60:.2f} minutes)\")\n",
        "print(f\"   Overlap ratio: {overlap_duration/max(cam_duration, lid_duration):.1%}\")\n",
        "\n",
        "if overlap_duration < 10:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: Very short temporal overlap (<10s)!\")\n",
        "elif overlap_duration < 30:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: Short temporal overlap (<30s), dataset may be limited\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Good temporal overlap for dataset generation\")\n",
        "\n",
        "# Time offset detection\n",
        "time_offset = abs(cam_start - lid_start)\n",
        "if time_offset > 5.0:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: Large time offset between sensors: {time_offset:.2f}s\")\n",
        "    print(f\"       This may indicate sensor desynchronization\")\n",
        "\n",
        "# Gap detection\n",
        "print(f\"\\n Temporal Gap Detection:\")\n",
        "cam_gaps = np.where(cam_intervals > 10.0)[0]\n",
        "lid_gaps = np.where(lid_intervals > 10.0)[0]\n",
        "\n",
        "if len(cam_gaps) > 0:\n",
        "    print(f\"   Camera: Found {len(cam_gaps)} gaps >10s\")\n",
        "    for gap_idx in cam_gaps[:3]:  # Show first 3\n",
        "        print(f\"     ‚Ä¢ Gap at frame {gap_idx}: {cam_intervals[gap_idx]:.2f}s\")\n",
        "    if len(cam_gaps) > 3:\n",
        "        print(f\"     ‚Ä¢ ... and {len(cam_gaps)-3} more gaps\")\n",
        "else:\n",
        "    print(f\"   Camera: No significant gaps detected\")\n",
        "\n",
        "if len(lid_gaps) > 0:\n",
        "    print(f\"   LiDAR: Found {len(lid_gaps)} gaps >10s\")\n",
        "    for gap_idx in lid_gaps[:3]:\n",
        "        print(f\"     ‚Ä¢ Gap at scan {gap_idx}: {lid_intervals[gap_idx]:.2f}s\")\n",
        "    if len(lid_gaps) > 3:\n",
        "        print(f\"     ‚Ä¢ ... and {len(lid_gaps)-3} more gaps\")\n",
        "else:\n",
        "    print(f\"   LiDAR: No significant gaps detected\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Feature Quality Analysis\n",
        "# =======================================================================\n",
        "print(f\"\\n\\n FEATURE QUALITY ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Check for NaN/Inf\n",
        "cam_nan = np.isnan(camera_features).sum()\n",
        "cam_inf = np.isinf(camera_features).sum()\n",
        "lid_nan = np.isnan(lidar_features).sum()\n",
        "lid_inf = np.isinf(lidar_features).sum()\n",
        "\n",
        "print(f\"\\n Camera Feature Quality:\")\n",
        "print(f\"   NaN values: {cam_nan} ({cam_nan/camera_features.size:.2%})\")\n",
        "print(f\"   Inf values: {cam_inf} ({cam_inf/camera_features.size:.2%})\")\n",
        "if cam_nan > 0 or cam_inf > 0:\n",
        "    print(f\"   ‚ùå CRITICAL: Invalid values detected in camera features!\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ No invalid values detected\")\n",
        "\n",
        "# Check for zero features\n",
        "cam_zero_frames = np.sum(np.all(camera_features == 0, axis=1))\n",
        "print(f\"   All-zero frames: {cam_zero_frames} ({cam_zero_frames/len(camera_features):.1%})\")\n",
        "if cam_zero_frames > 0:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: {cam_zero_frames} frames have all-zero features\")\n",
        "\n",
        "print(f\"\\n LiDAR Feature Quality:\")\n",
        "print(f\"   NaN values: {lid_nan} ({lid_nan/lidar_features.size:.2%})\")\n",
        "print(f\"   Inf values: {lid_inf} ({lid_inf/lidar_features.size:.2%})\")\n",
        "if lid_nan > 0 or lid_inf > 0:\n",
        "    print(f\"   ‚ùå CRITICAL: Invalid values detected in LiDAR features!\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ No invalid values detected\")\n",
        "\n",
        "lid_zero_scans = np.sum(np.all(lidar_features == 0, axis=1))\n",
        "print(f\"   All-zero scans: {lid_zero_scans} ({lid_zero_scans/len(lidar_features):.1%})\")\n",
        "if lid_zero_scans > 0:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: {lid_zero_scans} scans have all-zero features\")\n",
        "\n",
        "# Normalization verification (already done, but detailed here)\n",
        "print(f\"\\n‚úÖ L2 Normalization Verification:\")\n",
        "cam_norm_errors = np.abs(camera_norms - 1.0)\n",
        "lid_norm_errors = np.abs(lidar_norms - 1.0)\n",
        "print(f\"   Camera - Max error: {cam_norm_errors.max():.2e}, Mean error: {cam_norm_errors.mean():.2e}\")\n",
        "print(f\"   LiDAR - Max error: {lid_norm_errors.max():.2e}, Mean error: {lid_norm_errors.mean():.2e}\")\n",
        "\n",
        "if cam_norm_errors.max() > 1e-4 or lid_norm_errors.max() > 1e-4:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: Some features deviate significantly from unit norm\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ All features properly normalized (error < 1e-4)\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Feature Distribution Analysis\n",
        "# =======================================================================\n",
        "print(f\"\\n\\n FEATURE DISTRIBUTION ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "# Sparsity analysis\n",
        "cam_sparsity = (camera_features == 0).sum() / camera_features.size\n",
        "lid_sparsity = (lidar_features == 0).sum() / lidar_features.size\n",
        "\n",
        "print(f\"\\n Camera Feature Distribution:\")\n",
        "print(f\"   Sparsity: {cam_sparsity:.1%} (fraction of zero values)\")\n",
        "print(f\"   Non-zero values per frame - Mean: {(camera_features != 0).sum(axis=1).mean():.0f}, Std: {(camera_features != 0).sum(axis=1).std():.0f}\")\n",
        "\n",
        "# Check for duplicate frames\n",
        "cam_unique = len(np.unique(camera_features, axis=0))\n",
        "cam_duplicates = len(camera_features) - cam_unique\n",
        "print(f\"   Unique frames: {cam_unique}/{len(camera_features)}\")\n",
        "if cam_duplicates > 0:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: {cam_duplicates} duplicate frames detected ({cam_duplicates/len(camera_features):.1%})\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ No duplicate frames detected\")\n",
        "\n",
        "print(f\"\\n LiDAR Feature Distribution:\")\n",
        "print(f\"   Sparsity: {lid_sparsity:.1%} (fraction of zero values)\")\n",
        "print(f\"   Non-zero values per scan - Mean: {(lidar_features != 0).sum(axis=1).mean():.0f}, Std: {(lidar_features != 0).sum(axis=1).std():.0f}\")\n",
        "\n",
        "lid_unique = len(np.unique(lidar_features, axis=0))\n",
        "lid_duplicates = len(lidar_features) - lid_unique\n",
        "print(f\"   Unique scans: {lid_unique}/{len(lidar_features)}\")\n",
        "if lid_duplicates > 0:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: {lid_duplicates} duplicate scans detected ({lid_duplicates/len(lidar_features):.1%})\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ No duplicate scans detected\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Timestamp Precision Analysis\n",
        "# =======================================================================\n",
        "print(f\"\\n\\n TIMESTAMP PRECISION ANALYSIS\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\n Split Timestamp Format:\")\n",
        "print(f\"   Storage format: timestamps_sec (int64) + timestamps_nsec (int32)\")\n",
        "print(f\"   Precision: Full nanosecond precision maintained\")\n",
        "print(f\"   Camera timestamps_sec range: [{camera_timestamps_sec.min()}, {camera_timestamps_sec.max()}]\")\n",
        "print(f\"   Camera timestamps_nsec range: [{camera_timestamps_nsec.min()}, {camera_timestamps_nsec.max()}]\")\n",
        "print(f\"   LiDAR timestamps_sec range: [{lidar_timestamps_sec.min()}, {lidar_timestamps_sec.max()}]\")\n",
        "print(f\"   LiDAR timestamps_nsec range: [{lidar_timestamps_nsec.min()}, {lidar_timestamps_nsec.max()}]\")\n",
        "\n",
        "# Reconstruct and compare\n",
        "cam_recon = camera_timestamps_sec + camera_timestamps_nsec * 1e-9\n",
        "lid_recon = lidar_timestamps_sec + lidar_timestamps_nsec * 1e-9\n",
        "cam_precision_loss = np.abs(cam_recon - camera_timestamps).max()\n",
        "lid_precision_loss = np.abs(lid_recon - lidar_timestamps).max()\n",
        "\n",
        "print(f\"\\n Float64 Conversion Analysis:\")\n",
        "print(f\"   Camera max precision loss: {cam_precision_loss*1e9:.2f} ns\")\n",
        "print(f\"   LiDAR max precision loss: {lid_precision_loss*1e9:.2f} ns\")\n",
        "print(f\"   Temporal alignment threshold: {MAX_TIME_OFFSET*1e9:.0f} ns ({MAX_TIME_OFFSET}s)\")\n",
        "print(f\"   Precision loss vs threshold: {cam_precision_loss/MAX_TIME_OFFSET:.2e}x\")\n",
        "\n",
        "if cam_precision_loss < 1e-6 and lid_precision_loss < 1e-6:\n",
        "    print(f\"   ‚úÖ Precision loss negligible (<1 microsecond)\")\n",
        "    print(f\"   ‚úÖ Float64 safe for all temporal operations in this notebook\")\n",
        "else:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: Precision loss > 1 microsecond detected\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Cross-Modal Synchronization Preview\n",
        "# =======================================================================\n",
        "print(f\"\\n\\n CROSS-MODAL SYNCHRONIZATION PREVIEW\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(f\"\\nEstimating potential aligned pairs (using ¬±{MAX_TIME_OFFSET}s threshold):\")\n",
        "\n",
        "# Count how many camera frames can be aligned\n",
        "aligned_count = 0\n",
        "for cam_t in camera_timestamps:\n",
        "    # Find closest LiDAR timestamp\n",
        "    time_diffs = np.abs(lidar_timestamps - cam_t)\n",
        "    min_diff = time_diffs.min()\n",
        "    if min_diff < MAX_TIME_OFFSET:\n",
        "        aligned_count += 1\n",
        "\n",
        "alignment_rate = aligned_count / len(camera_timestamps)\n",
        "print(f\"   Camera frames that can align with LiDAR: {aligned_count}/{len(camera_timestamps)} ({alignment_rate:.1%})\")\n",
        "\n",
        "if alignment_rate < 0.5:\n",
        "    print(f\"   ‚ùå CRITICAL: Low alignment rate (<50%)!\")\n",
        "    print(f\"      This suggests poor temporal synchronization between sensors.\")\n",
        "elif alignment_rate < 0.7:\n",
        "    print(f\"   ‚ö†Ô∏è  WARNING: Moderate alignment rate (<70%)\")\n",
        "    print(f\"      Some features may not be usable in multi-modal pairs.\")\n",
        "else:\n",
        "    print(f\"   ‚úÖ Good alignment rate (>70%)\")\n",
        "\n",
        "# =======================================================================\n",
        "#  Overall Quality Assessment\n",
        "# =======================================================================\n",
        "print(f\"\\n\\n‚úÖ OVERALL DATA QUALITY ASSESSMENT\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Quality checks\n",
        "checks = []\n",
        "\n",
        "# 1. Sufficient data\n",
        "min_frames = 50\n",
        "checks.append((\n",
        "    \"Sufficient frames\",\n",
        "    len(camera_features) >= min_frames and len(lidar_features) >= min_frames,\n",
        "    f\"Camera: {len(camera_features)}, LiDAR: {len(lidar_features)} (need ‚â•{min_frames})\"\n",
        "))\n",
        "\n",
        "# 2. No invalid values\n",
        "checks.append((\n",
        "    \"No NaN/Inf values\",\n",
        "    cam_nan == 0 and cam_inf == 0 and lid_nan == 0 and lid_inf == 0,\n",
        "    f\"Camera NaN: {cam_nan}, Inf: {cam_inf}; LiDAR NaN: {lid_nan}, Inf: {lid_inf}\"\n",
        "))\n",
        "\n",
        "# 3. Proper normalization\n",
        "checks.append((\n",
        "    \"Proper L2 normalization\",\n",
        "    cam_norm_errors.max() < 1e-4 and lid_norm_errors.max() < 1e-4,\n",
        "    f\"Max error: Camera {cam_norm_errors.max():.2e}, LiDAR {lid_norm_errors.max():.2e}\"\n",
        "))\n",
        "\n",
        "# 4. Temporal overlap\n",
        "checks.append((\n",
        "    \"Sufficient temporal overlap\",\n",
        "    overlap_duration > 30,\n",
        "    f\"{overlap_duration:.1f}s (need >30s)\"\n",
        "))\n",
        "\n",
        "# 5. Good alignment rate\n",
        "checks.append((\n",
        "    \"Good cross-modal alignment\",\n",
        "    alignment_rate > 0.7,\n",
        "    f\"{alignment_rate:.1%} (need >70%)\"\n",
        "))\n",
        "\n",
        "# 6. Not too many zeros\n",
        "checks.append((\n",
        "    \"Low all-zero frame rate\",\n",
        "    cam_zero_frames < len(camera_features) * 0.05 and lid_zero_scans < len(lidar_features) * 0.05,\n",
        "    f\"Camera: {cam_zero_frames}, LiDAR: {lid_zero_scans} (<5% threshold)\"\n",
        "))\n",
        "\n",
        "# 7. No excessive gaps\n",
        "checks.append((\n",
        "    \"Temporal continuity\",\n",
        "    len(cam_gaps) < 5 and len(lid_gaps) < 5,\n",
        "    f\"Camera gaps: {len(cam_gaps)}, LiDAR gaps: {len(lid_gaps)} (<5 threshold)\"\n",
        "))\n",
        "\n",
        "# 8. Reasonable durations\n",
        "checks.append((\n",
        "    \"Sufficient recording duration\",\n",
        "    cam_duration > 60 or lid_duration > 60,\n",
        "    f\"Camera: {cam_duration:.1f}s, LiDAR: {lid_duration:.1f}s (need >60s)\"\n",
        "))\n",
        "\n",
        "# Print results\n",
        "print(\"\\nQuality Checks:\")\n",
        "passed = 0\n",
        "for check_name, check_passed, check_details in checks:\n",
        "    status = \"‚úÖ PASS\" if check_passed else \"‚ùå FAIL\"\n",
        "    print(f\"  {status} - {check_name}\")\n",
        "    print(f\"         {check_details}\")\n",
        "    if check_passed:\n",
        "        passed += 1\n",
        "\n",
        "# Overall assessment\n",
        "print(f\"\\n\" + \"=\" * 80)\n",
        "print(f\"OVERALL ASSESSMENT: {passed}/{len(checks)} checks passed\")\n",
        "\n",
        "if passed == len(checks):\n",
        "    print(\" EXCELLENT: All quality checks passed! Data ready for dataset generation.\")\n",
        "elif passed >= len(checks) * 0.75:\n",
        "    print(\"‚úÖ GOOD: Most checks passed. Proceed with dataset generation.\")\n",
        "elif passed >= len(checks) * 0.5:\n",
        "    print(\"‚ö†Ô∏è  FAIR: Several issues detected. Dataset generation may proceed with limitations.\")\n",
        "else:\n",
        "    print(\"‚ùå POOR: Multiple critical issues detected. Review data quality before proceeding.\")\n",
        "\n",
        "print(\"=\" * 80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_6"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 6: TIME ALIGNMENT\n",
        "\n",
        "Feature-to-node matching.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "temporal_alignment_header"
      },
      "source": [
        "### Temporal Alignment: Features to Trajectory Nodes\n",
        "\n",
        "**Strategy:** Iterate through trajectory nodes and find the closest camera and LiDAR features within tolerance.\n",
        "\n",
        "**Process:**\n",
        "1. For each trajectory node timestamp\n",
        "2. Find nearest camera feature (within MAX_TIME_OFFSET)\n",
        "3. Find nearest LiDAR feature (within MAX_TIME_OFFSET)\n",
        "4. Create valid_nodes dataframe: [node_id, camera_feat_id, lidar_feat_id]\n",
        "5. Skip nodes where either modality is missing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "align_features"
      },
      "source": [
        "### 6.1 Align Features to Trajectory Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "align_features_code"
      },
      "outputs": [],
      "source": [
        "print(\"Aligning features to trajectory nodes...\")\n",
        "\n",
        "# Build KD-trees for temporal matching\n",
        "node_timestamps = np.array([node['timestamp'] for node in trajectory_nodes.values()])\n",
        "node_ids = list(trajectory_nodes.keys())\n",
        "node_kdtree = KDTree(node_timestamps.reshape(-1, 1))\n",
        "\n",
        "# Align camera features\n",
        "camera_aligned = 0\n",
        "for i, cam_t in enumerate(camera_timestamps):\n",
        "    dist, idx = node_kdtree.query([[cam_t]], k=1)\n",
        "    if dist[0][0] < MAX_TIME_OFFSET:\n",
        "        node_id = node_ids[idx[0][0]]\n",
        "        trajectory_nodes[node_id]['camera_feature'] = camera_features[i]\n",
        "        trajectory_nodes[node_id]['camera_idx'] = i\n",
        "        camera_aligned += 1\n",
        "\n",
        "# Align LiDAR features\n",
        "lidar_aligned = 0\n",
        "for i, lid_t in enumerate(lidar_timestamps):\n",
        "    dist, idx = node_kdtree.query([[lid_t]], k=1)\n",
        "    if dist[0][0] < MAX_TIME_OFFSET:\n",
        "        node_id = node_ids[idx[0][0]]\n",
        "        trajectory_nodes[node_id]['lidar_feature'] = lidar_features[i]\n",
        "        trajectory_nodes[node_id]['lidar_idx'] = i\n",
        "        lidar_aligned += 1\n",
        "\n",
        "# Filter to nodes with both modalities\n",
        "valid_nodes = {node_id: data for node_id, data in trajectory_nodes.items()\n",
        "               if data['camera_feature'] is not None and data['lidar_feature'] is not None}\n",
        "\n",
        "camera_alignment_rate = camera_aligned / len(camera_features)\n",
        "lidar_alignment_rate = lidar_aligned / len(lidar_features)\n",
        "\n",
        "print(f\"‚úÖ Alignment complete:\")\n",
        "print(f\"   Camera aligned: {camera_aligned}/{len(camera_features)} ({camera_alignment_rate:.1%})\")\n",
        "print(f\"   LiDAR aligned: {lidar_aligned}/{len(lidar_features)} ({lidar_alignment_rate:.1%})\")\n",
        "print(f\"   Valid nodes (both modalities): {len(valid_nodes)}\")\n",
        "\n",
        "# Concatenate features for each valid node\n",
        "for node_id in valid_nodes:\n",
        "    cam_feat = valid_nodes[node_id]['camera_feature']\n",
        "    lid_feat = valid_nodes[node_id]['lidar_feature']\n",
        "    valid_nodes[node_id]['combined_feature'] = np.concatenate([cam_feat, lid_feat])\n",
        "\n",
        "print(f\"   Combined feature dimension: {valid_nodes[list(valid_nodes.keys())[0]]['combined_feature'].shape[0]}D\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "temporal_alignment_code"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TEMPORAL ALIGNMENT: FEATURES TO TRAJECTORY NODES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Convert trajectory timestamps to seconds (they're in nanoseconds from pbstream)\n",
        "trajectory_times = df_trajectory['timestamp'].values / 1e9  # Convert ns to seconds\n",
        "\n",
        "# Combine feature timestamps (from split sec/nsec format)\n",
        "camera_times = camera_timestamps_sec + camera_timestamps_nsec * 1e-9\n",
        "lidar_times = lidar_timestamps_sec + lidar_timestamps_nsec * 1e-9\n",
        "\n",
        "print(f\"\\nInput data:\")\n",
        "print(f\"  Trajectory nodes: {len(df_trajectory)}\")\n",
        "print(f\"  Camera features: {len(camera_features)}\")\n",
        "print(f\"  LiDAR features: {len(lidar_features)}\")\n",
        "print(f\"  Tolerance: ¬±{MAX_TIME_OFFSET}s\")\n",
        "\n",
        "# Build valid nodes dataframe\n",
        "valid_nodes_data = []\n",
        "alignment_stats = {'camera_aligned': 0, 'lidar_aligned': 0, 'both_aligned': 0}\n",
        "\n",
        "for idx, row in df_trajectory.iterrows():\n",
        "    node_id = row['node_id']\n",
        "    node_time = row['timestamp'] / 1e9  # Convert to seconds\n",
        "\n",
        "    # Find closest camera feature\n",
        "    cam_time_diffs = np.abs(camera_times - node_time)\n",
        "    cam_min_diff = np.min(cam_time_diffs)\n",
        "    cam_feat_id = None\n",
        "\n",
        "    if cam_min_diff <= MAX_TIME_OFFSET:\n",
        "        cam_feat_id = np.argmin(cam_time_diffs)\n",
        "        alignment_stats['camera_aligned'] += 1\n",
        "\n",
        "    # Find closest LiDAR feature\n",
        "    lid_time_diffs = np.abs(lidar_times - node_time)\n",
        "    lid_min_diff = np.min(lid_time_diffs)\n",
        "    lid_feat_id = None\n",
        "\n",
        "    if lid_min_diff <= MAX_TIME_OFFSET:\n",
        "        lid_feat_id = np.argmin(lid_time_diffs)\n",
        "        alignment_stats['lidar_aligned'] += 1\n",
        "\n",
        "    # Only keep nodes with BOTH modalities\n",
        "    if cam_feat_id is not None and lid_feat_id is not None:\n",
        "        valid_nodes_data.append({\n",
        "            'node_id': node_id,\n",
        "            'camera_feat_id': cam_feat_id,\n",
        "            'lidar_feat_id': lid_feat_id,\n",
        "            'x': row['x'],\n",
        "            'y': row['y'],\n",
        "            'timestamp': row['timestamp']\n",
        "        })\n",
        "        alignment_stats['both_aligned'] += 1\n",
        "\n",
        "# Create valid nodes dataframe\n",
        "valid_nodes = pd.DataFrame(valid_nodes_data)\n",
        "\n",
        "print(f\"\\n‚úì Alignment Results:\")\n",
        "print(f\"  Camera aligned: {alignment_stats['camera_aligned']} / {len(df_trajectory)} ({100*alignment_stats['camera_aligned']/len(df_trajectory):.1f}%)\")\n",
        "print(f\"  LiDAR aligned: {alignment_stats['lidar_aligned']} / {len(df_trajectory)} ({100*alignment_stats['lidar_aligned']/len(df_trajectory):.1f}%)\")\n",
        "print(f\"  Valid nodes (both): {len(valid_nodes)} / {len(df_trajectory)} ({100*len(valid_nodes)/len(df_trajectory):.1f}%)\")\n",
        "\n",
        "if len(valid_nodes) == 0:\n",
        "    raise ValueError(\"‚ùå No valid nodes with both modalities! Check timestamp alignment.\")\n",
        "\n",
        "print(f\"\\n‚úì Valid nodes dataframe created: {len(valid_nodes)} nodes\")\n",
        "print(valid_nodes.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_7"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 7: PAIRING\n",
        "\n",
        "Positive and negative pair generation.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phase2_title"
      },
      "source": [
        "## INTELLIGENT PAIRING STRATEGY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "profiling_header"
      },
      "source": [
        "### 7.1 Data Profiling & Automatic Threshold Suggestion\n",
        "\n",
        "Before pairing, analyze the pairwise distance and time distributions to suggest optimal thresholds.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "profiling_code"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"DATA PROFILING & THRESHOLD SUGGESTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Filter df_all_pairs to only include valid nodes\n",
        "valid_node_ids = set(valid_nodes['node_id'].values)\n",
        "df_pairs_valid = df_all_pairs[\n",
        "    df_all_pairs['node1_id'].isin(valid_node_ids) &\n",
        "    df_all_pairs['node2_id'].isin(valid_node_ids)\n",
        "].copy()\n",
        "\n",
        "print(f\"\\nPairwise data:\")\n",
        "print(f\"  Total pairs: {len(df_all_pairs):,}\")\n",
        "print(f\"  Valid pairs (both nodes aligned): {len(df_pairs_valid):,}\")\n",
        "\n",
        "# Calculate statistics\n",
        "distances = df_pairs_valid['distance_between_nodes_m'].values\n",
        "time_diffs = df_pairs_valid['time_diff_secs'].values\n",
        "\n",
        "# Distance percentiles\n",
        "dist_percentiles = [5, 10, 25, 50, 75, 90, 95]\n",
        "dist_values = np.percentile(distances, dist_percentiles)\n",
        "\n",
        "print(f\"\\nüìä Distance Distribution (meters):\")\n",
        "for p, v in zip(dist_percentiles, dist_values):\n",
        "    print(f\"  {p:2d}th percentile: {v:.3f}m\")\n",
        "\n",
        "# Time percentiles\n",
        "time_percentiles = [5, 10, 25, 50, 75, 90, 95]\n",
        "time_values = np.percentile(time_diffs, time_percentiles)\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  Time Difference Distribution (seconds):\")\n",
        "for p, v in zip(time_percentiles, time_values):\n",
        "    print(f\"  {p:2d}th percentile: {v:.1f}s\")\n",
        "\n",
        "# Automatic threshold suggestions\n",
        "suggested_positive_dist = dist_values[1]  # 10th percentile\n",
        "suggested_easy_neg_dist = dist_values[5]  # 75th percentile\n",
        "\n",
        "# For time gap: analyze pairs with small distance\n",
        "close_pairs = df_pairs_valid[df_pairs_valid['distance_between_nodes_m'] < suggested_positive_dist]\n",
        "if len(close_pairs) > 0:\n",
        "    suggested_time_gap = np.percentile(close_pairs['time_diff_secs'].values, 75)\n",
        "else:\n",
        "    suggested_time_gap = 10.0  # Default\n",
        "\n",
        "print(f\"\\nüí° Suggested Thresholds:\")\n",
        "print(f\"  Positive distance: {suggested_positive_dist:.3f}m (10th percentile)\")\n",
        "print(f\"  Easy negative distance: {suggested_easy_neg_dist:.3f}m (75th percentile)\")\n",
        "print(f\"  Positive time gap: {suggested_time_gap:.1f}s (75th %ile of close pairs)\")\n",
        "\n",
        "print(f\"\\nüìù Current Configuration:\")\n",
        "print(f\"  Positive distance: {POSITIVE_DISTANCE_THRESHOLD:.3f}m\")\n",
        "print(f\"  Easy negative distance: {EASY_NEGATIVE_MIN_DISTANCE:.3f}m\")\n",
        "print(f\"  Positive time gap: {POSITIVE_TIME_GAP:.1f}s\")\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Distance histogram\n",
        "axes[0].hist(distances, bins=50, alpha=0.7, edgecolor='black')\n",
        "axes[0].axvline(POSITIVE_DISTANCE_THRESHOLD, color='green', linestyle='--', linewidth=2, label='Positive threshold')\n",
        "axes[0].axvline(EASY_NEGATIVE_MIN_DISTANCE, color='red', linestyle='--', linewidth=2, label='Easy neg threshold')\n",
        "axes[0].set_xlabel('Distance (m)')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "axes[0].set_title('Pairwise Distance Distribution')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Time vs Distance scatter\n",
        "axes[1].scatter(time_diffs, distances, alpha=0.3, s=1)\n",
        "axes[1].axhline(POSITIVE_DISTANCE_THRESHOLD, color='green', linestyle='--', linewidth=2, label='Positive dist')\n",
        "axes[1].axvline(POSITIVE_TIME_GAP, color='blue', linestyle='--', linewidth=2, label='Positive time gap')\n",
        "axes[1].set_xlabel('Time Difference (s)')\n",
        "axes[1].set_ylabel('Distance (m)')\n",
        "axes[1].set_title('Distance vs Time Difference')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n‚úì Profiling complete. Proceeding with configured thresholds.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phase2_intro"
      },
      "source": [
        "### 7.2 Strategy Overview\n",
        "\n",
        "We create three types of training pairs:\n",
        "\n",
        "1. **Positive Pairs (30%)** - Loop closures validated by Cartographer INTER_SUBMAP constraints\n",
        "2. **Easy Negative Pairs (35%)** - Spatially distant locations (>5m) with temporal gap\n",
        "3. **Hard Negative Pairs (35%)** - Perceptually similar but spatially distinct locations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_positives"
      },
      "source": [
        "### 7.3 Generate Positive Pairs from Loop Closures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_positives_code"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING POSITIVE PAIRS (LOOP CLOSURES)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Use df_pairs_valid filtered by distance and time thresholds\n",
        "positive_candidates = df_pairs_valid[\n",
        "    (df_pairs_valid['distance_between_nodes_m'] < POSITIVE_DISTANCE_THRESHOLD) &\n",
        "    (df_pairs_valid['time_diff_secs'] > POSITIVE_TIME_GAP)\n",
        "].copy()\n",
        "\n",
        "print(f\"\\nCriteria:\")\n",
        "print(f\"  Distance < {POSITIVE_DISTANCE_THRESHOLD}m\")\n",
        "print(f\"  Time difference > {POSITIVE_TIME_GAP}s\")\n",
        "print(f\"\\nCandidates: {len(positive_candidates)}\")\n",
        "\n",
        "# Generate positive pairs\n",
        "positive_pairs = []\n",
        "for _, row in positive_candidates.iterrows():\n",
        "    node1_id = row['node1_id']\n",
        "    node2_id = row['node2_id']\n",
        "\n",
        "    # Get valid node data\n",
        "    node1_data = valid_nodes[valid_nodes['node_id'] == node1_id].iloc[0]\n",
        "    node2_data = valid_nodes[valid_nodes['node_id'] == node2_id].iloc[0]\n",
        "\n",
        "    # Get features\n",
        "    cam1_idx = node1_data['camera_feat_id']\n",
        "    lid1_idx = node1_data['lidar_feat_id']\n",
        "    cam2_idx = node2_data['camera_feat_id']\n",
        "    lid2_idx = node2_data['lidar_feat_id']\n",
        "\n",
        "    # Concatenate features\n",
        "    feat1 = np.concatenate([camera_features[cam1_idx], lidar_features[lid1_idx]])\n",
        "    feat2 = np.concatenate([camera_features[cam2_idx], lidar_features[lid2_idx]])\n",
        "\n",
        "    # Create pairwise feature vector\n",
        "    pairwise_feat = np.concatenate([feat1, feat2])\n",
        "\n",
        "    positive_pairs.append({\n",
        "        'features': pairwise_feat,\n",
        "        'label': 1,\n",
        "        'node1_id': node1_id,\n",
        "        'node2_id': node2_id,\n",
        "        'distance': row['distance_between_nodes_m'],\n",
        "        'time_diff': row['time_diff_secs']\n",
        "    })\n",
        "\n",
        "print(f\"\\n‚úì Generated {len(positive_pairs)} positive pairs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_negatives"
      },
      "source": [
        "### 7.4 Generate Easy Negative Pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_negatives_code"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING EASY NEGATIVE PAIRS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Use df_pairs_valid filtered by distance threshold\n",
        "easy_neg_candidates = df_pairs_valid[\n",
        "    df_pairs_valid['distance_between_nodes_m'] > EASY_NEGATIVE_MIN_DISTANCE\n",
        "].copy()\n",
        "\n",
        "print(f\"\\nCriteria:\")\n",
        "print(f\"  Distance > {EASY_NEGATIVE_MIN_DISTANCE}m\")\n",
        "print(f\"\\nCandidates: {len(easy_neg_candidates)}\")\n",
        "\n",
        "# Sample to match number of positive pairs\n",
        "n_easy_neg = min(len(positive_pairs), len(easy_neg_candidates))\n",
        "easy_neg_sample = easy_neg_candidates.sample(n=n_easy_neg, random_state=RANDOM_SEED)\n",
        "\n",
        "# Generate easy negative pairs\n",
        "easy_negative_pairs = []\n",
        "for _, row in easy_neg_sample.iterrows():\n",
        "    node1_id = row['node1_id']\n",
        "    node2_id = row['node2_id']\n",
        "\n",
        "    # Get valid node data\n",
        "    node1_data = valid_nodes[valid_nodes['node_id'] == node1_id].iloc[0]\n",
        "    node2_data = valid_nodes[valid_nodes['node_id'] == node2_id].iloc[0]\n",
        "\n",
        "    # Get features\n",
        "    cam1_idx = node1_data['camera_feat_id']\n",
        "    lid1_idx = node1_data['lidar_feat_id']\n",
        "    cam2_idx = node2_data['camera_feat_id']\n",
        "    lid2_idx = node2_data['lidar_feat_id']\n",
        "\n",
        "    # Concatenate features\n",
        "    feat1 = np.concatenate([camera_features[cam1_idx], lidar_features[lid1_idx]])\n",
        "    feat2 = np.concatenate([camera_features[cam2_idx], lidar_features[lid2_idx]])\n",
        "\n",
        "    # Create pairwise feature vector\n",
        "    pairwise_feat = np.concatenate([feat1, feat2])\n",
        "\n",
        "    easy_negative_pairs.append({\n",
        "        'features': pairwise_feat,\n",
        "        'label': 0,\n",
        "        'node1_id': node1_id,\n",
        "        'node2_id': node2_id,\n",
        "        'distance': row['distance_between_nodes_m'],\n",
        "        'time_diff': row['time_diff_secs']\n",
        "    })\n",
        "\n",
        "print(f\"\\n‚úì Generated {len(easy_negative_pairs)} easy negative pairs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create_hard_negatives"
      },
      "source": [
        "### 7.5 Generate Hard Negative Pairs (Perceptual Aliasing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "create_hard_negatives_code"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"GENERATING HARD NEGATIVE PAIRS (PERCEPTUAL ALIASING)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Use df_pairs_valid filtered by distance (must be far apart)\n",
        "hard_neg_candidates = df_pairs_valid[\n",
        "    df_pairs_valid['distance_between_nodes_m'] > EASY_NEGATIVE_MIN_DISTANCE\n",
        "].copy()\n",
        "\n",
        "print(f\"\\nCriteria:\")\n",
        "print(f\"  Distance > {EASY_NEGATIVE_MIN_DISTANCE}m\")\n",
        "print(f\"  Cosine similarity > {HARD_NEGATIVE_SIMILARITY_THRESHOLD}\")\n",
        "print(f\"\\nCandidates: {len(hard_neg_candidates)}\")\n",
        "\n",
        "# Calculate cosine similarity for candidates\n",
        "hard_negative_pairs = []\n",
        "hard_negative_pairs_type_a = []\n",
        "\n",
        "print(\"\\nComputing feature similarities...\")\n",
        "for idx, row in hard_neg_candidates.iterrows():\n",
        "    node1_id = row['node1_id']\n",
        "    node2_id = row['node2_id']\n",
        "\n",
        "    # Get valid node data\n",
        "    node1_data = valid_nodes[valid_nodes['node_id'] == node1_id].iloc[0]\n",
        "    node2_data = valid_nodes[valid_nodes['node_id'] == node2_id].iloc[0]\n",
        "\n",
        "    # Get features\n",
        "    cam1_idx = node1_data['camera_feat_id']\n",
        "    lid1_idx = node1_data['lidar_feat_id']\n",
        "    cam2_idx = node2_data['camera_feat_id']\n",
        "    lid2_idx = node2_data['lidar_feat_id']\n",
        "\n",
        "    # Concatenate features\n",
        "    feat1 = np.concatenate([camera_features[cam1_idx], lidar_features[lid1_idx]])\n",
        "    feat2 = np.concatenate([camera_features[cam2_idx], lidar_features[lid2_idx]])\n",
        "\n",
        "    # Compute cosine similarity\n",
        "    similarity = np.dot(feat1, feat2) / (np.linalg.norm(feat1) * np.linalg.norm(feat2))\n",
        "\n",
        "    # Check if perceptually similar\n",
        "    if similarity > HARD_NEGATIVE_SIMILARITY_THRESHOLD:\n",
        "        # Create pairwise feature vector\n",
        "        pairwise_feat = np.concatenate([feat1, feat2])\n",
        "\n",
        "        pair_data = {\n",
        "            'features': pairwise_feat,\n",
        "            'label': 0,\n",
        "            'node1_id': node1_id,\n",
        "            'node2_id': node2_id,\n",
        "            'distance': row['distance_between_nodes_m'],\n",
        "            'time_diff': row['time_diff_secs'],\n",
        "            'similarity': similarity\n",
        "        }\n",
        "\n",
        "        hard_negative_pairs.append(pair_data)\n",
        "        hard_negative_pairs_type_a.append(pair_data)\n",
        "\n",
        "print(f\"\\n‚úì Generated {len(hard_negative_pairs)} hard negative pairs\")\n",
        "print(f\"  Type A (perceptual): {len(hard_negative_pairs_type_a)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "combine_dataset"
      },
      "source": [
        "### 7.6 Combine and Shuffle Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "combine_dataset_code"
      },
      "outputs": [],
      "source": [
        "print(\"Combining all pairs into dataset...\")\n",
        "\n",
        "# Combine all pairs\n",
        "dataset = positive_pairs + easy_negative_pairs + hard_negative_pairs\n",
        "\n",
        "# Shuffle dataset\n",
        "random.shuffle(dataset)\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset created:\")\n",
        "print(f\"   Total pairs: {len(dataset)}\")\n",
        "print(f\"   Positive: {len(positive_pairs)} ({100*len(positive_pairs)/len(dataset):.1f}%)\")\n",
        "print(f\"   Easy negative: {len(easy_negative_pairs)} ({100*len(easy_negative_pairs)/len(dataset):.1f}%)\")\n",
        "print(f\"   Hard negative: {len(hard_negative_pairs)} ({100*len(hard_negative_pairs)/len(dataset):.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_9"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 8: VALIDATIONS\n",
        "\n",
        "Split, validate, visualize, report.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stratified_split"
      },
      "source": [
        "### 8.1 Stratified Train/Val/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stratified_split_code"
      },
      "outputs": [],
      "source": [
        "print(\"Creating stratified train/val/test splits...\")\n",
        "\n",
        "# Separate by label\n",
        "positive_samples = [d for d in dataset if d['label'] == 1]\n",
        "negative_samples = [d for d in dataset if d['label'] == 0]\n",
        "\n",
        "# Shuffle each class\n",
        "random.shuffle(positive_samples)\n",
        "random.shuffle(negative_samples)\n",
        "\n",
        "# Split each class\n",
        "def split_class(samples, train_ratio, val_ratio, test_ratio):\n",
        "    n = len(samples)\n",
        "    train_end = int(n * train_ratio)\n",
        "    val_end = train_end + int(n * val_ratio)\n",
        "    return samples[:train_end], samples[train_end:val_end], samples[val_end:]\n",
        "\n",
        "pos_train, pos_val, pos_test = split_class(positive_samples, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
        "neg_train, neg_val, neg_test = split_class(negative_samples, TRAIN_RATIO, VAL_RATIO, TEST_RATIO)\n",
        "\n",
        "# Combine and shuffle within each split\n",
        "train_dataset = pos_train + neg_train\n",
        "val_dataset = pos_val + neg_val\n",
        "test_dataset = pos_test + neg_test\n",
        "\n",
        "random.shuffle(train_dataset)\n",
        "random.shuffle(val_dataset)\n",
        "random.shuffle(test_dataset)\n",
        "\n",
        "# Compute class balance\n",
        "train_pos_ratio = sum(d['label'] for d in train_dataset) / len(train_dataset)\n",
        "val_pos_ratio = sum(d['label'] for d in val_dataset) / len(val_dataset)\n",
        "test_pos_ratio = sum(d['label'] for d in test_dataset) / len(test_dataset)\n",
        "\n",
        "print(f\"\\n‚úÖ Stratified splits created:\")\n",
        "print(f\"   Train: {len(train_dataset)} pairs (Pos: {train_pos_ratio:.1%})\")\n",
        "print(f\"   Val: {len(val_dataset)} pairs (Pos: {val_pos_ratio:.1%})\")\n",
        "print(f\"   Test: {len(test_dataset)} pairs (Pos: {test_pos_ratio:.1%})\")\n",
        "\n",
        "# Check stratification quality\n",
        "target_ratio = len(positive_samples) / len(dataset)\n",
        "max_deviation = max(abs(train_pos_ratio - target_ratio),\n",
        "                   abs(val_pos_ratio - target_ratio),\n",
        "                   abs(test_pos_ratio - target_ratio))\n",
        "\n",
        "if max_deviation < 0.05:\n",
        "    print(f\"\\n  ‚úÖ Stratification quality: excellent (max deviation: {max_deviation:.3f})\")\n",
        "else:\n",
        "    print(f\"\\n  ‚ö†Ô∏è  Stratification quality: acceptable (max deviation: {max_deviation:.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "validation"
      },
      "source": [
        "### 8.2 Dataset Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "validation_code"
      },
      "outputs": [],
      "source": [
        "print(\"Validating dataset quality...\")\n",
        "\n",
        "# Extract features and labels\n",
        "X = np.array([d['features'] for d in dataset])\n",
        "y = np.array([d['label'] for d in dataset])\n",
        "\n",
        "validation_checks = []\n",
        "\n",
        "# Check 1: Dataset size\n",
        "min_size = 100\n",
        "check_1 = len(dataset) >= min_size\n",
        "validation_checks.append((f\"Dataset size >= {min_size}\", check_1))\n",
        "\n",
        "# Check 2: Class balance\n",
        "pos_ratio = np.sum(y) / len(y)\n",
        "check_2 = 0.2 <= pos_ratio <= 0.4\n",
        "validation_checks.append((f\"Class balance (20-40% positive): {pos_ratio:.1%}\", check_2))\n",
        "\n",
        "# Check 3: Feature dimension\n",
        "expected_dim = 1536  # 1280 (camera) + 256 (lidar) concatenated twice\n",
        "check_3 = X.shape[1] == expected_dim\n",
        "validation_checks.append((f\"Feature dimension == {expected_dim}D\", check_3))\n",
        "\n",
        "# Check 4: No NaN values\n",
        "check_4 = not np.any(np.isnan(X))\n",
        "validation_checks.append((\"No NaN values in features\", check_4))\n",
        "\n",
        "# Check 5: No infinite values\n",
        "check_5 = not np.any(np.isinf(X))\n",
        "validation_checks.append((\"No infinite values in features\", check_5))\n",
        "\n",
        "# Check 6: Feature range reasonable\n",
        "check_6 = np.abs(X).max() < 10.0\n",
        "validation_checks.append((\"Feature values in reasonable range\", check_6))\n",
        "\n",
        "# Check 7: Positive pairs from loop closures\n",
        "check_7 = len(positive_pairs) > 0\n",
        "validation_checks.append((\"Positive pairs from Cartographer loop closures\", check_7))\n",
        "\n",
        "# Check 8: Sufficient hard negatives\n",
        "check_8 = len(hard_negative_pairs) >= len(positive_pairs) * 0.5\n",
        "validation_checks.append((\"Sufficient hard negative pairs\", check_8))\n",
        "\n",
        "# Critical checks (must pass)\n",
        "critical_checks = [check_18, check_3, check_4, check_5, check_7]\n",
        "critical_passed = all(critical_checks)\n",
        "all_passed = all(c[1] for c in validation_checks)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"VALIDATION RESULTS\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "for check_name, result in validation_checks:\n",
        "    status = \"‚úÖ\" if result else \"‚ùå\"\n",
        "    print(f\"{status} {check_name}\")\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "if all_passed:\n",
        "    print(\"‚úÖ ALL CHECKS PASSED - Dataset is ready for training\")\n",
        "elif critical_passed:\n",
        "    print(\"‚ö†Ô∏è  CRITICAL CHECKS PASSED - Dataset is usable but review warnings\")\n",
        "else:\n",
        "    print(\"‚ùå CRITICAL CHECKS FAILED - Dataset quality issues detected\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize"
      },
      "source": [
        "### 8.3 Diagnostic Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "visualize_code"
      },
      "outputs": [],
      "source": [
        "print(\"Generating diagnostic visualizations...\")\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle(f'Loop Closure Dataset Diagnostics - {SESSION_ID}', fontsize=16, fontweight='bold')\n",
        "\n",
        "# Plot 1: Trajectory with loop closures\n",
        "ax = axes[0, 0]\n",
        "valid_positions = np.array([[valid_nodes[nid]['pose']['x'], valid_nodes[nid]['pose']['y']]\n",
        "                           for nid in valid_node_ids])\n",
        "ax.plot(valid_positions[:, 0], valid_positions[:, 1], 'b-', alpha=0.3, linewidth=1, label='Trajectory')\n",
        "ax.scatter(valid_positions[:, 0], valid_positions[:, 1], c='blue', s=10, alpha=0.5, label='Nodes')\n",
        "\n",
        "# Plot loop closures\n",
        "for pair in positive_pairs[:50]:  # Plot first 50\n",
        "    n1 = valid_nodes[pair['node1_id']]\n",
        "    n2 = valid_nodes[pair['node2_id']]\n",
        "    ax.plot([n1['pose']['x'], n2['pose']['x']],\n",
        "           [n1['pose']['y'], n2['pose']['y']],\n",
        "           'r-', alpha=0.2, linewidth=0.5)\n",
        "\n",
        "ax.set_xlabel('X (meters)')\n",
        "ax.set_ylabel('Y (meters)')\n",
        "ax.set_title('Trajectory with Loop Closures')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.axis('equal')\n",
        "\n",
        "# Plot 2: Class distribution\n",
        "ax = axes[0, 1]\n",
        "pair_types = ['Positive', 'Easy Neg', 'Hard Neg']\n",
        "pair_counts = [len(positive_pairs), len(easy_negative_pairs), len(hard_negative_pairs)]\n",
        "colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "bars = ax.bar(pair_types, pair_counts, color=colors, alpha=0.7)\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Pair Type Distribution')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "for bar, count in zip(bars, pair_counts):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "           f'{count}\\n({100*count/len(dataset):.1f}%)',\n",
        "           ha='center', va='bottom')\n",
        "\n",
        "# Plot 3: Spatial distance distribution\n",
        "ax = axes[0, 2]\n",
        "pos_dists = [p['spatial_distance'] for p in positive_pairs]\n",
        "easy_neg_dists = [p['spatial_distance'] for p in easy_negative_pairs]\n",
        "hard_neg_dists = [p['spatial_distance'] for p in hard_negative_pairs]\n",
        "\n",
        "ax.hist(pos_dists, bins=20, alpha=0.6, label='Positive', color='#2ecc71')\n",
        "ax.hist(easy_neg_dists, bins=20, alpha=0.6, label='Easy Neg', color='#3498db')\n",
        "ax.hist(hard_neg_dists, bins=20, alpha=0.6, label='Hard Neg', color='#e74c3c')\n",
        "ax.set_xlabel('Spatial Distance (m)')\n",
        "ax.set_ylabel('Count')\n",
        "ax.set_title('Spatial Distance Distribution')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 4: Split distribution\n",
        "ax = axes[1, 0]\n",
        "splits = ['Train', 'Val', 'Test']\n",
        "split_sizes = [len(train_dataset), len(val_dataset), len(test_dataset)]\n",
        "split_colors = ['#2ecc71', '#f39c12', '#e74c3c']\n",
        "bars = ax.bar(splits, split_sizes, color=split_colors, alpha=0.7)\n",
        "ax.set_ylabel('Pairs')\n",
        "ax.set_title('Train/Val/Test Splits')\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "for bar, size, ratio in zip(bars, split_sizes, [train_pos_ratio, val_pos_ratio, test_pos_ratio]):\n",
        "    height = bar.get_height()\n",
        "    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "           f'{size}\\nPos: {ratio:.1%}',\n",
        "           ha='center', va='bottom')\n",
        "\n",
        "# Plot 5: Feature statistics\n",
        "ax = axes[1, 1]\n",
        "feature_means = X.mean(axis=0)\n",
        "ax.plot(feature_means, alpha=0.7, linewidth=0.5)\n",
        "ax.axvline(x=1280, color='r', linestyle='--', alpha=0.5, label='Camera|LiDAR (1st pair)')\n",
        "ax.axvline(x=1536, color='g', linestyle='--', alpha=0.5, label='1st pair|2nd pair')\n",
        "ax.set_xlabel('Feature Index')\n",
        "ax.set_ylabel('Mean Value')\n",
        "ax.set_title('Feature Statistics (Mean across dataset)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 6: Validation summary\n",
        "ax = axes[1, 2]\n",
        "ax.axis('off')\n",
        "summary_text = f\"\"\"VALIDATION SUMMARY\n",
        "\n",
        "Dataset Size: {len(dataset)} pairs\n",
        "  ‚Ä¢ Positive: {len(positive_pairs)} ({100*len(positive_pairs)/len(dataset):.1f}%)\n",
        "  ‚Ä¢ Negative: {len(easy_negative_pairs) + len(hard_negative_pairs)} ({100*(len(easy_negative_pairs)+len(hard_negative_pairs))/len(dataset):.1f}%)\n",
        "\n",
        "Splits:\n",
        "  ‚Ä¢ Train: {len(train_dataset)} ({100*len(train_dataset)/len(dataset):.1f}%)\n",
        "  ‚Ä¢ Val: {len(val_dataset)} ({100*len(val_dataset)/len(dataset):.1f}%)\n",
        "  ‚Ä¢ Test: {len(test_dataset)} ({100*len(test_dataset)/len(dataset):.1f}%)\n",
        "\n",
        "Quality Checks:\n",
        "  ‚Ä¢ Validation: {'‚úÖ PASSED' if all_passed else '‚ö†Ô∏è  WARNINGS' if critical_passed else '‚ùå FAILED'}\n",
        "  ‚Ä¢ Feature Dim: {X.shape[1]}D\n",
        "  ‚Ä¢ Loop Closures: {len(inter_submap_constraints)}\n",
        "  ‚Ä¢ Class Balance: {pos_ratio:.1%}\n",
        "\"\"\"\n",
        "ax.text(0.1, 0.5, summary_text, transform=ax.transAxes,\n",
        "       fontsize=11, verticalalignment='center', family='monospace',\n",
        "       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(DIAGNOSTICS_FILE, dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n‚úÖ Diagnostics saved: {DIAGNOSTICS_FILE}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "section_8"
      },
      "source": [
        "---\n",
        "\n",
        "## SECTION 9: OUTPUT\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save_dataset"
      },
      "source": [
        "### 9.1 Dataset saving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save_dataset_code"
      },
      "outputs": [],
      "source": [
        "print(\"Saving dataset...\")\n",
        "\n",
        "# Package dataset\n",
        "dataset_package = {\n",
        "    'train': train_dataset,\n",
        "    'val': val_dataset,\n",
        "    'test': test_dataset,\n",
        "    'metadata': {\n",
        "        'session_id': SESSION_ID,\n",
        "        'creation_date': str(np.datetime64('today')),\n",
        "        'num_trajectory_nodes': len(trajectory_nodes),\n",
        "        'num_valid_nodes': len(valid_nodes),\n",
        "        'num_constraints': len(inter_submap_constraints),\n",
        "        'feature_dim': X.shape[1],\n",
        "        'random_seed': RANDOM_SEED,\n",
        "        'config': {\n",
        "            'max_time_offset': MAX_TIME_OFFSET,\n",
        "            'positive_distance_threshold': POSITIVE_DISTANCE_THRESHOLD,\n",
        "            'easy_negative_min_distance': EASY_NEGATIVE_MIN_DISTANCE,\n",
        "            'hard_negative_min_distance': HARD_NEGATIVE_MIN_DISTANCE,\n",
        "            'hard_negative_similarity_threshold': HARD_NEGATIVE_SIMILARITY_THRESHOLD,\n",
        "            'max_constraint_residual': MAX_CONSTRAINT_RESIDUAL,\n",
        "            'max_angular_distance': MAX_ANGULAR_DISTANCE\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save to pickle\n",
        "with open(DATASET_FILE, 'wb') as f:\n",
        "    pickle.dump(dataset_package, f)\n",
        "\n",
        "file_size_mb = os.path.getsize(DATASET_FILE) / (1024 * 1024)\n",
        "print(f\"\\n‚úÖ Dataset saved: {DATASET_FILE}\")\n",
        "print(f\"   File size: {file_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generate_report"
      },
      "source": [
        "### 9.2 Text Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "generate_report_code"
      },
      "outputs": [],
      "source": [
        "print(\"Generating final report...\")\n",
        "\n",
        "output_filename = os.path.basename(DATASET_FILE)\n",
        "\n",
        "report = f\"\"\"\n",
        "{'='*70}\n",
        "LOOP CLOSURE DATASET GENERATION REPORT\n",
        "{'='*70}\n",
        "\n",
        "SESSION INFORMATION:\n",
        "  ‚Ä¢ Session ID: {SESSION_ID}\n",
        "  ‚Ä¢ Generation date: {np.datetime64('today')}\n",
        "  ‚Ä¢ Pipeline version: 6.2\n",
        "  ‚Ä¢ Random seed: {RANDOM_SEED}\n",
        "\n",
        "INPUT DATA:\n",
        "  ‚Ä¢ Trajectory nodes: {len(trajectory_nodes)}\n",
        "  ‚Ä¢ Valid nodes (both modalities): {len(valid_nodes)}\n",
        "  ‚Ä¢ Camera features: {len(camera_features)} (aligned: {camera_aligned}, {100*camera_alignment_rate:.1f}%)\n",
        "  ‚Ä¢ LiDAR features: {len(lidar_features)} (aligned: {lidar_aligned}, {100*lidar_alignment_rate:.1f}%)\n",
        "  ‚Ä¢ INTER_SUBMAP constraints: {len(constraint_metadata)} (validated: {len(inter_submap_constraints)})\n",
        "\n",
        "DATASET COMPOSITION:\n",
        "  ‚Ä¢ Total pairs: {len(dataset)}\n",
        "  ‚Ä¢ Positive pairs: {len(positive_pairs)} ({100*len(positive_pairs)/len(dataset):.1f}%)\n",
        "  ‚Ä¢ Easy negative pairs: {len(easy_negative_pairs)} ({100*len(easy_negative_pairs)/len(dataset):.1f}%)\n",
        "  ‚Ä¢ Hard negative pairs: {len(hard_negative_pairs)} ({100*len(hard_negative_pairs)/len(dataset):.1f}%)\n",
        "      ‚Üí Type A (perceptual): {len(hard_negative_pairs_type_a)}\n",
        "\n",
        "TRAIN/VAL/TEST SPLITS (STRATIFIED RANDOM):\n",
        "  ‚Ä¢ Train: {len(train_dataset)} pairs ({100*len(train_dataset)/len(dataset):.1f}%)\n",
        "      ‚Üí Positive: {sum(d['label'] for d in train_dataset)} ({100*train_pos_ratio:.1f}%)\n",
        "  ‚Ä¢ Validation: {len(val_dataset)} pairs ({len(val_dataset)/len(dataset):.1%})\n",
        "      ‚Üí Positive: {sum(d['label'] for d in val_dataset)} ({100*val_pos_ratio:.1f}%)\n",
        "  ‚Ä¢ Test: {len(test_dataset)} pairs ({100*len(test_dataset)/len(dataset):.1f}%)\n",
        "      ‚Üí Positive: {sum(d['label'] for d in test_dataset)} ({100*test_pos_ratio:.1f}%)\n",
        "  ‚Ä¢ Stratification quality: {max_deviation:.3f} max deviation (< 0.05 is good)\n",
        "\n",
        "FEATURE STATISTICS:\n",
        "  ‚Ä¢ Pairwise feature dimension: {X.shape[1]}D\n",
        "  ‚Ä¢ Mean: {np.mean(X):.4f}\n",
        "  ‚Ä¢ Std: {np.std(X):.4f}\n",
        "  ‚Ä¢ Range: [{np.min(X):.4f}, {np.max(X):.4f}]\n",
        "\n",
        "VALIDATION STATUS:\n",
        "  {'‚úÖ' if all_passed else '‚ö†Ô∏è ' if critical_passed else '‚ùå'} Overall: {'PASSED' if all_passed else 'PASSED WITH WARNINGS' if critical_passed else 'FAILED'}\n",
        "\"\"\"\n",
        "\n",
        "for check_name, check_result in validation_checks:\n",
        "    report += f\"  {'‚úÖ' if check_result else '‚ùå'} {check_name}\\n\"\n",
        "\n",
        "report += f\"\"\"\n",
        "OUTPUT FILES:\n",
        "  ‚Ä¢ Dataset: {output_filename} ({file_size_mb:.2f} MB)\n",
        "  ‚Ä¢ Diagnostics: dataset_diagnostics.png\n",
        "\n",
        "NEXT STEPS:\n",
        "  1. Load dataset with: pickle.load(open('{output_filename}', 'rb'))\n",
        "  2. Train Fusion MLP (Phase 2): 1536‚Üí512‚Üí128‚Üí1 architecture\n",
        "  3. Use BCE loss + hard negative mining\n",
        "  4. Monitor validation performance\n",
        "  5. Export to ONNX/TensorRT for Jetson Nano deployment\n",
        "\n",
        "\n",
        "{'='*70}\n",
        "\"\"\"\n",
        "\n",
        "print(report)\n",
        "\n",
        "# Save report\n",
        "with open(REPORT_FILE, 'w') as f:\n",
        "    f.write(report)\n",
        "\n",
        "print(\"\\n‚úÖ Final report saved to: dataset_generation_report.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "if all_passed:\n",
        "    print(\" DATASET GENERATION COMPLETE - READY FOR TRAINING!\")\n",
        "elif critical_passed:\n",
        "    print(\"‚úÖ DATASET GENERATION COMPLETE - USABLE WITH WARNINGS\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  DATASET GENERATION COMPLETE - REVIEW VALIDATION ISSUES\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "version_control"
      },
      "source": [
        "---\n",
        "\n",
        "## VERSION CONTROL\n",
        "\n",
        "**Version:** 7.0 (Major Refactor)\n",
        "**Date:** 2025-11-12\n",
        "**Changes:**\n",
        "\n",
        "### MAJOR ARCHITECTURAL CHANGES\n",
        "\n",
        "**1. Pbstream-First Approach:**\n",
        "- Made `.pbstream` file REQUIRED (no longer optional)\n",
        "- Removed bag-based trajectory extraction fallback\n",
        "- Integrated full pbstream extraction pipeline from standalone notebook\n",
        "- Direct access to SLAM graph with full fidelity\n",
        "\n",
        "**2. New Temporal Alignment Strategy:**\n",
        "- Changed from feature-first to node-first iteration\n",
        "- For each trajectory node ‚Üí find closest camera + LiDAR features\n",
        "- Creates explicit mapping: [node_id, camera_feat_id, lidar_feat_id]\n",
        "- Clearer data flow and validation\n",
        "\n",
        "**3. Pairwise Table-Based Pairing:**\n",
        "- Generate complete pairwise distance/time table from pbstream\n",
        "- Use table filtering for all pair types (positive, easy neg, hard neg)\n",
        "- Eliminated manual constraint parsing from bag\n",
        "- More efficient and consistent approach\n",
        "\n",
        "**4. Data-Driven Threshold Selection:**\n",
        "- Added automatic profiling section\n",
        "- Analyzes distance and time distributions\n",
        "- Suggests optimal thresholds based on data percentiles\n",
        "- Visualization of distributions with threshold overlays\n",
        "\n",
        "**5. Environment-Specific Calibration:**\n",
        "- Updated thresholds for small indoor environment (3m √ó 2m)\n",
        "- Positive distance: 2.0m ‚Üí 0.3m\n",
        "- Easy negative distance: 5.0m ‚Üí 1.0m\n",
        "- Added positive time gap: 10.0s (prevents sequential pairing)\n",
        "\n",
        "**6. Code Integration:**\n",
        "- Merged pbstream extraction functions (extract_xy, extract_timestamp, etc.)\n",
        "- Added Google Drive mount for Colab compatibility\n",
        "- Unified path structure using SESSION_ID\n",
        "- Preserved all validation and diagnostic sections\n",
        "\n",
        "---\n",
        "\n",
        "**Previous changes (v6.10):**\n",
        "- Fixed critical parsing bug in trajectory extraction\n",
        "- Implemented two-tier pbstream/bag approach\n",
        "- Reorganized notebook structure\n",
        "\n",
        "**Previous changes (v6.6):**\n",
        "- Added trajectory topic structure verification\n",
        "- Identified correct data source\n",
        "\n",
        "---\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}